2025-03-31 22:26:58,566 - utils - INFO - Using device: cuda
2025-03-31 22:26:59,076 - speechbrain.utils.quirks - INFO - Applied quirks (see `speechbrain.utils.quirks`): [disable_jit_profiling, allow_tf32]
2025-03-31 22:26:59,077 - speechbrain.utils.quirks - INFO - Excluded quirks specified by the `SB_DISABLE_QUIRKS` environment (comma-separated list): []
C:\Users\SQREAM\Desktop\semester_six\speech_understanding_assignment_02\src\speech_enhancement\sepformer.py:12: UserWarning: Module 'speechbrain.pretrained' was deprecated, redirecting to 'speechbrain.inference'. Please update your script. This is a change from SpeechBrain 1.0. See: https://github.com/speechbrain/speechbrain/releases/tag/v1.0.0
  from speechbrain.pretrained import SepformerSeparation
2025-03-31 22:27:19,570 - speaker_verification.pretrained_eval - INFO - Initial pretrained_eval device setting: cuda
2025-03-31 22:27:20,498 - speaker_verification.finetune - INFO - Using device: cuda
2025-03-31 22:27:20,499 - __main__ - INFO - PESQ module is available for evaluation
2025-03-31 22:27:20,500 - speaker_verification.pretrained_eval - INFO - Using device for model loading: cuda
2025-03-31 22:27:20,501 - speaker_verification.pretrained_eval - INFO - CUDA is available. Device count: 1
2025-03-31 22:27:20,501 - speaker_verification.pretrained_eval - INFO - Loading pretrained model: microsoft/wavlm-base-plus
2025-03-31 22:27:23,182 - speaker_verification.pretrained_eval - INFO - Model moved to cuda
2025-03-31 22:27:23,184 - __main__ - INFO - Loading speaker model weights from models/speaker_verification/wavlm_ft/best_model.pt
2025-03-31 22:27:23,715 - __main__ - INFO - Direct loading failed, attempting to load with LoRA...
2025-03-31 22:27:23,867 - speaker_verification.finetune - INFO - Explicitly initialized base_model.model.backbone.encoder.layers.0.attention.k_proj.lora_B.default.weight with random values
2025-03-31 22:27:23,867 - speaker_verification.finetune - INFO - Explicitly initialized base_model.model.backbone.encoder.layers.0.attention.v_proj.lora_B.default.weight with random values
2025-03-31 22:27:23,867 - speaker_verification.finetune - INFO - Explicitly initialized base_model.model.backbone.encoder.layers.0.attention.q_proj.lora_B.default.weight with random values
2025-03-31 22:27:23,867 - speaker_verification.finetune - INFO - Explicitly initialized base_model.model.backbone.encoder.layers.0.attention.out_proj.lora_B.default.weight with random values
2025-03-31 22:27:23,868 - speaker_verification.finetune - INFO - Explicitly initialized base_model.model.backbone.encoder.layers.1.attention.k_proj.lora_B.default.weight with random values
2025-03-31 22:27:23,868 - speaker_verification.finetune - INFO - Explicitly initialized base_model.model.backbone.encoder.layers.1.attention.v_proj.lora_B.default.weight with random values
2025-03-31 22:27:23,868 - speaker_verification.finetune - INFO - Explicitly initialized base_model.model.backbone.encoder.layers.1.attention.q_proj.lora_B.default.weight with random values
2025-03-31 22:27:23,868 - speaker_verification.finetune - INFO - Explicitly initialized base_model.model.backbone.encoder.layers.1.attention.out_proj.lora_B.default.weight with random values
2025-03-31 22:27:23,868 - speaker_verification.finetune - INFO - Explicitly initialized base_model.model.backbone.encoder.layers.2.attention.k_proj.lora_B.default.weight with random values
2025-03-31 22:27:23,868 - speaker_verification.finetune - INFO - Explicitly initialized base_model.model.backbone.encoder.layers.2.attention.v_proj.lora_B.default.weight with random values
2025-03-31 22:27:23,868 - speaker_verification.finetune - INFO - Explicitly initialized base_model.model.backbone.encoder.layers.2.attention.q_proj.lora_B.default.weight with random values
2025-03-31 22:27:23,868 - speaker_verification.finetune - INFO - Explicitly initialized base_model.model.backbone.encoder.layers.2.attention.out_proj.lora_B.default.weight with random values
2025-03-31 22:27:23,868 - speaker_verification.finetune - INFO - Explicitly initialized base_model.model.backbone.encoder.layers.3.attention.k_proj.lora_B.default.weight with random values
2025-03-31 22:27:23,869 - speaker_verification.finetune - INFO - Explicitly initialized base_model.model.backbone.encoder.layers.3.attention.v_proj.lora_B.default.weight with random values
2025-03-31 22:27:23,869 - speaker_verification.finetune - INFO - Explicitly initialized base_model.model.backbone.encoder.layers.3.attention.q_proj.lora_B.default.weight with random values
2025-03-31 22:27:23,869 - speaker_verification.finetune - INFO - Explicitly initialized base_model.model.backbone.encoder.layers.3.attention.out_proj.lora_B.default.weight with random values
2025-03-31 22:27:23,869 - speaker_verification.finetune - INFO - Explicitly initialized base_model.model.backbone.encoder.layers.4.attention.k_proj.lora_B.default.weight with random values
2025-03-31 22:27:23,869 - speaker_verification.finetune - INFO - Explicitly initialized base_model.model.backbone.encoder.layers.4.attention.v_proj.lora_B.default.weight with random values
2025-03-31 22:27:23,869 - speaker_verification.finetune - INFO - Explicitly initialized base_model.model.backbone.encoder.layers.4.attention.q_proj.lora_B.default.weight with random values
2025-03-31 22:27:23,869 - speaker_verification.finetune - INFO - Explicitly initialized base_model.model.backbone.encoder.layers.4.attention.out_proj.lora_B.default.weight with random values
2025-03-31 22:27:23,869 - speaker_verification.finetune - INFO - Explicitly initialized base_model.model.backbone.encoder.layers.5.attention.k_proj.lora_B.default.weight with random values
2025-03-31 22:27:23,870 - speaker_verification.finetune - INFO - Explicitly initialized base_model.model.backbone.encoder.layers.5.attention.v_proj.lora_B.default.weight with random values
2025-03-31 22:27:23,870 - speaker_verification.finetune - INFO - Explicitly initialized base_model.model.backbone.encoder.layers.5.attention.q_proj.lora_B.default.weight with random values
2025-03-31 22:27:23,870 - speaker_verification.finetune - INFO - Explicitly initialized base_model.model.backbone.encoder.layers.5.attention.out_proj.lora_B.default.weight with random values
2025-03-31 22:27:23,870 - speaker_verification.finetune - INFO - Explicitly initialized base_model.model.backbone.encoder.layers.6.attention.k_proj.lora_B.default.weight with random values
2025-03-31 22:27:23,870 - speaker_verification.finetune - INFO - Explicitly initialized base_model.model.backbone.encoder.layers.6.attention.v_proj.lora_B.default.weight with random values
2025-03-31 22:27:23,870 - speaker_verification.finetune - INFO - Explicitly initialized base_model.model.backbone.encoder.layers.6.attention.q_proj.lora_B.default.weight with random values
2025-03-31 22:27:23,870 - speaker_verification.finetune - INFO - Explicitly initialized base_model.model.backbone.encoder.layers.6.attention.out_proj.lora_B.default.weight with random values
2025-03-31 22:27:23,870 - speaker_verification.finetune - INFO - Explicitly initialized base_model.model.backbone.encoder.layers.7.attention.k_proj.lora_B.default.weight with random values
2025-03-31 22:27:23,870 - speaker_verification.finetune - INFO - Explicitly initialized base_model.model.backbone.encoder.layers.7.attention.v_proj.lora_B.default.weight with random values
2025-03-31 22:27:23,871 - speaker_verification.finetune - INFO - Explicitly initialized base_model.model.backbone.encoder.layers.7.attention.q_proj.lora_B.default.weight with random values
2025-03-31 22:27:23,871 - speaker_verification.finetune - INFO - Explicitly initialized base_model.model.backbone.encoder.layers.7.attention.out_proj.lora_B.default.weight with random values
2025-03-31 22:27:23,871 - speaker_verification.finetune - INFO - Explicitly initialized base_model.model.backbone.encoder.layers.8.attention.k_proj.lora_B.default.weight with random values
2025-03-31 22:27:23,871 - speaker_verification.finetune - INFO - Explicitly initialized base_model.model.backbone.encoder.layers.8.attention.v_proj.lora_B.default.weight with random values
2025-03-31 22:27:23,871 - speaker_verification.finetune - INFO - Explicitly initialized base_model.model.backbone.encoder.layers.8.attention.q_proj.lora_B.default.weight with random values
2025-03-31 22:27:23,871 - speaker_verification.finetune - INFO - Explicitly initialized base_model.model.backbone.encoder.layers.8.attention.out_proj.lora_B.default.weight with random values
2025-03-31 22:27:23,871 - speaker_verification.finetune - INFO - Explicitly initialized base_model.model.backbone.encoder.layers.9.attention.k_proj.lora_B.default.weight with random values
2025-03-31 22:27:23,871 - speaker_verification.finetune - INFO - Explicitly initialized base_model.model.backbone.encoder.layers.9.attention.v_proj.lora_B.default.weight with random values
2025-03-31 22:27:23,871 - speaker_verification.finetune - INFO - Explicitly initialized base_model.model.backbone.encoder.layers.9.attention.q_proj.lora_B.default.weight with random values
2025-03-31 22:27:23,872 - speaker_verification.finetune - INFO - Explicitly initialized base_model.model.backbone.encoder.layers.9.attention.out_proj.lora_B.default.weight with random values
2025-03-31 22:27:23,872 - speaker_verification.finetune - INFO - Explicitly initialized base_model.model.backbone.encoder.layers.10.attention.k_proj.lora_B.default.weight with random values
2025-03-31 22:27:23,872 - speaker_verification.finetune - INFO - Explicitly initialized base_model.model.backbone.encoder.layers.10.attention.v_proj.lora_B.default.weight with random values
2025-03-31 22:27:23,872 - speaker_verification.finetune - INFO - Explicitly initialized base_model.model.backbone.encoder.layers.10.attention.q_proj.lora_B.default.weight with random values
2025-03-31 22:27:23,872 - speaker_verification.finetune - INFO - Explicitly initialized base_model.model.backbone.encoder.layers.10.attention.out_proj.lora_B.default.weight with random values
2025-03-31 22:27:23,872 - speaker_verification.finetune - INFO - Explicitly initialized base_model.model.backbone.encoder.layers.11.attention.k_proj.lora_B.default.weight with random values
2025-03-31 22:27:23,872 - speaker_verification.finetune - INFO - Explicitly initialized base_model.model.backbone.encoder.layers.11.attention.v_proj.lora_B.default.weight with random values
2025-03-31 22:27:23,872 - speaker_verification.finetune - INFO - Explicitly initialized base_model.model.backbone.encoder.layers.11.attention.q_proj.lora_B.default.weight with random values
2025-03-31 22:27:23,872 - speaker_verification.finetune - INFO - Explicitly initialized base_model.model.backbone.encoder.layers.11.attention.out_proj.lora_B.default.weight with random values
2025-03-31 22:27:23,875 - speaker_verification.finetune - INFO - Trainable params: 1179648 || All params: 95638384 || Trainable%: 1.2334%
2025-03-31 22:27:24,214 - speech_enhancement.sepformer - INFO - Loading SepFormer model...
2025-03-31 22:27:24,214 - speech_enhancement.sepformer - INFO - Downloading model files from speechbrain/sepformer-wham
2025-03-31 22:27:24,215 - speechbrain.utils.fetching - INFO - Fetch hyperparams.yaml: Fetching from HuggingFace Hub 'speechbrain/sepformer-wham' if not cached
C:\Users\SQREAM\Desktop\semester_six\speech_understanding_assignment_02\speech\lib\site-packages\speechbrain\utils\fetching.py:151: UserWarning: Using SYMLINK strategy on Windows for fetching potentially requires elevated privileges and is not recommended. See `LocalStrategy` documentation.
  warnings.warn(
2025-03-31 22:27:24,841 - speechbrain.utils.fetching - INFO - Fetch custom.py: Fetching from HuggingFace Hub 'speechbrain/sepformer-wham' if not cached
C:\Users\SQREAM\Desktop\semester_six\speech_understanding_assignment_02\speech\lib\site-packages\speechbrain\utils\parameter_transfer.py:234: UserWarning: Requested Pretrainer collection using symlinks on Windows. This might not work; see `LocalStrategy` documentation. Consider unsetting `collect_in` in Pretrainer to avoid symlinking altogether.
  warnings.warn(
2025-03-31 22:27:25,453 - speechbrain.utils.fetching - INFO - Fetch masknet.ckpt: Fetching from HuggingFace Hub 'speechbrain/sepformer-wham' if not cached
2025-03-31 22:27:25,737 - speechbrain.utils.fetching - INFO - Fetch encoder.ckpt: Fetching from HuggingFace Hub 'speechbrain/sepformer-wham' if not cached
2025-03-31 22:27:26,023 - speechbrain.utils.fetching - INFO - Fetch decoder.ckpt: Fetching from HuggingFace Hub 'speechbrain/sepformer-wham' if not cached
2025-03-31 22:27:26,324 - speech_enhancement.sepformer - INFO - Loading the model into memory
2025-03-31 22:27:26,324 - speechbrain.utils.fetching - INFO - Fetch hyperparams.yaml: Fetching from HuggingFace Hub 'speechbrain/sepformer-wham' if not cached
2025-03-31 22:27:26,588 - speechbrain.utils.fetching - INFO - Fetch custom.py: Fetching from HuggingFace Hub 'speechbrain/sepformer-wham' if not cached
2025-03-31 22:27:26,992 - speechbrain.utils.fetching - INFO - Fetch masknet.ckpt: Fetching from HuggingFace Hub 'speechbrain/sepformer-wham' if not cached
2025-03-31 22:27:27,294 - speechbrain.utils.fetching - INFO - Fetch encoder.ckpt: Fetching from HuggingFace Hub 'speechbrain/sepformer-wham' if not cached
2025-03-31 22:27:27,599 - speechbrain.utils.fetching - INFO - Fetch decoder.ckpt: Fetching from HuggingFace Hub 'speechbrain/sepformer-wham' if not cached
2025-03-31 22:27:27,898 - speechbrain.utils.parameter_transfer - INFO - Loading pretrained files for: masknet, encoder, decoder
2025-03-31 22:27:28,304 - speech_enhancement.sepformer - INFO - Testing if model is loaded properly
2025-03-31 22:27:28,304 - speech_enhancement.sepformer - INFO - SepFormer model loaded successfully
2025-03-31 22:27:28,347 - __main__ - INFO - Loaded dataset with 500 mixtures
2025-03-31 22:27:28,362 - __main__ - INFO - Loaded dataset with 200 mixtures
2025-03-31 22:27:28,364 - __main__ - INFO - Training with 20 parameters
Epoch 1/1 [Train]:   0%|          | 0/250 [00:00<?, ?it/s]2025-03-31 22:27:28,525 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:27:29,947 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:27:29,947 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:27:29,992 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:27:30,058 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:27:30,058 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:27:30,503 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:27:30,503 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:27:30,503 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:   0%|          | 0/250 [00:03<?, ?it/s, loss=0.263]Epoch 1/1 [Train]:   0%|          | 1/250 [00:03<13:16,  3.20s/it, loss=0.263]2025-03-31 22:27:31,642 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:27:31,683 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:27:31,683 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:27:32,163 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:27:32,202 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:27:32,202 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:27:32,674 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:27:32,674 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:27:32,674 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:   0%|          | 1/250 [00:04<13:16,  3.20s/it, loss=0.259]Epoch 1/1 [Train]:   1%|          | 2/250 [00:04<08:39,  2.09s/it, loss=0.259]2025-03-31 22:27:32,972 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:27:33,016 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:27:33,016 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:27:33,498 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:27:33,540 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:27:33,540 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:27:34,010 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:27:34,010 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:27:34,010 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:   1%|          | 2/250 [00:05<08:39,  2.09s/it, loss=0.203]Epoch 1/1 [Train]:   1%|1         | 3/250 [00:05<07:11,  1.75s/it, loss=0.203]2025-03-31 22:27:34,319 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:27:34,362 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:27:34,362 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:27:34,847 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:27:34,902 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:27:34,902 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:27:35,359 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:27:35,359 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:27:35,360 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:   1%|1         | 3/250 [00:07<07:11,  1.75s/it, loss=0.226]Epoch 1/1 [Train]:   2%|1         | 4/250 [00:07<06:31,  1.59s/it, loss=0.226]2025-03-31 22:27:35,678 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:27:35,723 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:27:35,723 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:27:36,204 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:27:36,248 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:27:36,248 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:27:36,716 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:27:36,717 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:27:36,717 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:   2%|1         | 4/250 [00:08<06:31,  1.59s/it, loss=0.205]Epoch 1/1 [Train]:   2%|2         | 5/250 [00:08<06:08,  1.50s/it, loss=0.205]2025-03-31 22:27:37,034 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:27:37,082 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:27:37,083 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:27:37,561 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:27:37,608 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:27:37,608 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:27:38,073 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:27:38,073 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:27:38,073 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:   2%|2         | 5/250 [00:09<06:08,  1.50s/it, loss=0.227]Epoch 1/1 [Train]:   2%|2         | 6/250 [00:09<05:54,  1.45s/it, loss=0.227]2025-03-31 22:27:38,383 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:27:38,430 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:27:38,430 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:27:38,909 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:27:38,946 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:27:38,946 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:27:39,420 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:27:39,420 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:27:39,420 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:   2%|2         | 6/250 [00:11<05:54,  1.45s/it, loss=0.205]Epoch 1/1 [Train]:   3%|2         | 7/250 [00:11<05:45,  1.42s/it, loss=0.205]2025-03-31 22:27:39,720 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:27:39,763 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:27:39,763 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:27:40,246 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:27:40,287 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:27:40,287 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:27:40,757 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:27:40,757 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:27:40,757 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:   3%|2         | 7/250 [00:12<05:45,  1.42s/it, loss=0.215]Epoch 1/1 [Train]:   3%|3         | 8/250 [00:12<05:36,  1.39s/it, loss=0.215]2025-03-31 22:27:41,036 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:27:41,077 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:27:41,077 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:27:41,563 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:27:41,608 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:27:41,608 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:27:42,074 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:27:42,074 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:27:42,074 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:   3%|3         | 8/250 [00:13<05:36,  1.39s/it, loss=0.215]Epoch 1/1 [Train]:   4%|3         | 9/250 [00:13<05:30,  1.37s/it, loss=0.215]2025-03-31 22:27:42,372 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:27:42,416 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:27:42,416 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:27:42,900 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:27:42,944 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:27:42,945 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:27:43,414 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:27:43,414 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:27:43,414 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:   4%|3         | 9/250 [00:15<05:30,  1.37s/it, loss=0.207]Epoch 1/1 [Train]:   4%|4         | 10/250 [00:15<05:25,  1.36s/it, loss=0.207]2025-03-31 22:27:43,686 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:27:43,733 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:27:43,733 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:27:44,212 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:27:44,250 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:27:44,250 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:27:44,725 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:27:44,725 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:27:44,725 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:   4%|4         | 10/250 [00:16<05:25,  1.36s/it, loss=0.16] Epoch 1/1 [Train]:   4%|4         | 11/250 [00:16<05:21,  1.34s/it, loss=0.16]2025-03-31 22:27:45,015 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:27:45,061 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:27:45,061 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:27:45,544 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:27:45,587 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:27:45,588 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:27:46,058 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:27:46,058 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:27:46,058 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:   4%|4         | 11/250 [00:17<05:21,  1.34s/it, loss=0.175]Epoch 1/1 [Train]:   5%|4         | 12/250 [00:17<05:18,  1.34s/it, loss=0.175]2025-03-31 22:27:46,339 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:27:46,383 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:27:46,383 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:27:46,871 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:27:46,921 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:27:46,921 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:27:47,384 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:27:47,384 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:27:47,384 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:   5%|4         | 12/250 [00:19<05:18,  1.34s/it, loss=0.185]Epoch 1/1 [Train]:   5%|5         | 13/250 [00:19<05:17,  1.34s/it, loss=0.185]2025-03-31 22:27:47,670 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:27:47,713 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:27:47,713 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:27:48,204 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:27:48,256 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:27:48,256 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:27:48,718 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:27:48,719 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:27:48,719 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:   5%|5         | 13/250 [00:20<05:17,  1.34s/it, loss=0.161]Epoch 1/1 [Train]:   6%|5         | 14/250 [00:20<05:15,  1.34s/it, loss=0.161]2025-03-31 22:27:49,020 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:27:49,065 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:27:49,065 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:27:49,547 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:27:49,588 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:27:49,588 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:27:50,060 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:27:50,061 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:27:50,061 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:   6%|5         | 14/250 [00:21<05:15,  1.34s/it, loss=0.193]Epoch 1/1 [Train]:   6%|6         | 15/250 [00:21<05:14,  1.34s/it, loss=0.193]2025-03-31 22:27:50,365 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:27:50,412 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:27:50,412 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:27:50,897 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:27:50,939 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:27:50,939 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:27:51,409 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:27:51,409 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:27:51,409 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:   6%|6         | 15/250 [00:23<05:14,  1.34s/it, loss=0.163]Epoch 1/1 [Train]:   6%|6         | 16/250 [00:23<05:14,  1.34s/it, loss=0.163]2025-03-31 22:27:51,695 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:27:51,736 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:27:51,736 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:27:52,226 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:27:52,268 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:27:52,268 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:27:52,739 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:27:52,740 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:27:52,740 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:   6%|6         | 16/250 [00:24<05:14,  1.34s/it, loss=0.176]Epoch 1/1 [Train]:   7%|6         | 17/250 [00:24<05:10,  1.33s/it, loss=0.176]2025-03-31 22:27:53,015 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:27:53,060 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:27:53,060 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:27:53,545 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:27:53,587 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:27:53,587 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:27:54,058 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:27:54,059 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:27:54,059 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:   7%|6         | 17/250 [00:25<05:10,  1.33s/it, loss=0.133]Epoch 1/1 [Train]:   7%|7         | 18/250 [00:25<05:09,  1.33s/it, loss=0.133]2025-03-31 22:27:54,344 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:27:54,388 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:27:54,388 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:27:54,872 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:27:54,913 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:27:54,913 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:27:55,385 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:27:55,385 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:27:55,385 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:   7%|7         | 18/250 [00:27<05:09,  1.33s/it, loss=0.139]Epoch 1/1 [Train]:   8%|7         | 19/250 [00:27<05:07,  1.33s/it, loss=0.139]2025-03-31 22:27:55,690 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:27:55,732 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:27:55,732 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:27:56,217 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:27:56,259 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:27:56,259 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:27:56,730 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:27:56,730 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:27:56,730 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:   8%|7         | 19/250 [00:28<05:07,  1.33s/it, loss=0.165]Epoch 1/1 [Train]:   8%|8         | 20/250 [00:28<05:07,  1.34s/it, loss=0.165]2025-03-31 22:27:57,006 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:27:57,047 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:27:57,047 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:27:57,532 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:27:57,570 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:27:57,570 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:27:58,047 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:27:58,047 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:27:58,047 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:   8%|8         | 20/250 [00:29<05:07,  1.34s/it, loss=0.117]Epoch 1/1 [Train]:   8%|8         | 21/250 [00:29<05:04,  1.33s/it, loss=0.117]2025-03-31 22:27:58,381 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:27:58,436 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:27:58,436 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:27:58,910 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:27:58,953 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:27:58,953 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:27:59,425 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:27:59,425 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:27:59,425 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:   8%|8         | 21/250 [00:31<05:04,  1.33s/it, loss=0.138]Epoch 1/1 [Train]:   9%|8         | 22/250 [00:31<05:06,  1.34s/it, loss=0.138]2025-03-31 22:27:59,709 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:27:59,750 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:27:59,751 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:28:00,237 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:28:00,280 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:28:00,281 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:28:00,752 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:28:00,753 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:28:00,753 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:   9%|8         | 22/250 [00:32<05:06,  1.34s/it, loss=0.159]Epoch 1/1 [Train]:   9%|9         | 23/250 [00:32<05:03,  1.34s/it, loss=0.159]2025-03-31 22:28:01,050 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:28:01,095 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:28:01,095 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:28:01,580 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:28:01,619 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:28:01,619 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:28:02,094 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:28:02,094 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:28:02,094 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:   9%|9         | 23/250 [00:33<05:03,  1.34s/it, loss=0.155]Epoch 1/1 [Train]:  10%|9         | 24/250 [00:33<05:01,  1.34s/it, loss=0.155]2025-03-31 22:28:02,383 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:28:02,426 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:28:02,426 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:28:02,917 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:28:02,964 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:28:02,964 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:28:03,435 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:28:03,436 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:28:03,436 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  10%|9         | 24/250 [00:35<05:01,  1.34s/it, loss=0.137]Epoch 1/1 [Train]:  10%|#         | 25/250 [00:35<05:01,  1.34s/it, loss=0.137]2025-03-31 22:28:03,712 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:28:03,752 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:28:03,752 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:28:04,242 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:28:04,280 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:28:04,280 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:28:04,756 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:28:04,757 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:28:04,757 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  10%|#         | 25/250 [00:36<05:01,  1.34s/it, loss=0.148]Epoch 1/1 [Train]:  10%|#         | 26/250 [00:36<04:59,  1.34s/it, loss=0.148]2025-03-31 22:28:05,057 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:28:05,106 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:28:05,107 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:28:05,586 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:28:05,625 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:28:05,625 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:28:06,101 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:28:06,101 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:28:06,101 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  10%|#         | 26/250 [00:37<04:59,  1.34s/it, loss=0.133]Epoch 1/1 [Train]:  11%|#         | 27/250 [00:37<04:58,  1.34s/it, loss=0.133]2025-03-31 22:28:06,385 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:28:06,425 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:28:06,426 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:28:06,921 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:28:06,971 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:28:06,971 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:28:07,436 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:28:07,436 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:28:07,436 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  11%|#         | 27/250 [00:39<04:58,  1.34s/it, loss=0.151]Epoch 1/1 [Train]:  11%|#1        | 28/250 [00:39<04:57,  1.34s/it, loss=0.151]2025-03-31 22:28:07,740 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:28:07,783 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:28:07,783 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:28:08,268 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:28:08,309 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:28:08,310 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:28:08,783 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:28:08,783 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:28:08,783 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  11%|#1        | 28/250 [00:40<04:57,  1.34s/it, loss=0.136]Epoch 1/1 [Train]:  12%|#1        | 29/250 [00:40<04:56,  1.34s/it, loss=0.136]2025-03-31 22:28:09,073 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:28:09,113 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:28:09,113 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:28:09,603 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:28:09,647 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:28:09,647 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:28:10,118 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:28:10,119 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:28:10,119 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  12%|#1        | 29/250 [00:41<04:56,  1.34s/it, loss=0.131]Epoch 1/1 [Train]:  12%|#2        | 30/250 [00:41<04:53,  1.34s/it, loss=0.131]2025-03-31 22:28:10,406 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:28:10,450 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:28:10,450 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:28:10,936 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:28:10,982 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:28:10,983 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:28:11,450 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:28:11,450 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:28:11,450 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  12%|#2        | 30/250 [00:43<04:53,  1.34s/it, loss=0.116]Epoch 1/1 [Train]:  12%|#2        | 31/250 [00:43<04:53,  1.34s/it, loss=0.116]2025-03-31 22:28:11,759 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:28:11,802 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:28:11,802 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:28:12,288 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:28:12,324 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:28:12,325 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:28:12,802 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:28:12,802 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:28:12,802 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  12%|#2        | 31/250 [00:44<04:53,  1.34s/it, loss=0.118]Epoch 1/1 [Train]:  13%|#2        | 32/250 [00:44<04:51,  1.34s/it, loss=0.118]2025-03-31 22:28:13,087 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:28:13,130 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:28:13,130 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:28:13,615 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:28:13,656 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:28:13,656 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:28:14,130 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:28:14,131 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:28:14,131 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  13%|#2        | 32/250 [00:45<04:51,  1.34s/it, loss=0.117]Epoch 1/1 [Train]:  13%|#3        | 33/250 [00:45<04:49,  1.34s/it, loss=0.117]2025-03-31 22:28:14,417 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:28:14,460 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:28:14,461 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:28:14,945 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:28:14,988 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:28:14,988 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:28:15,459 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:28:15,459 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:28:15,459 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  13%|#3        | 33/250 [00:47<04:49,  1.34s/it, loss=0.12] Epoch 1/1 [Train]:  14%|#3        | 34/250 [00:47<04:49,  1.34s/it, loss=0.12]2025-03-31 22:28:15,743 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:28:15,783 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:28:15,784 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:28:16,271 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:28:16,315 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:28:16,315 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:28:16,785 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:28:16,785 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:28:16,785 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  14%|#3        | 34/250 [00:48<04:49,  1.34s/it, loss=0.131]Epoch 1/1 [Train]:  14%|#4        | 35/250 [00:48<04:46,  1.33s/it, loss=0.131]2025-03-31 22:28:17,073 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:28:17,118 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:28:17,118 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:28:17,604 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:28:17,647 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:28:17,647 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:28:18,120 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:28:18,120 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:28:18,120 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  14%|#4        | 35/250 [00:49<04:46,  1.33s/it, loss=0.136]Epoch 1/1 [Train]:  14%|#4        | 36/250 [00:49<04:45,  1.33s/it, loss=0.136]2025-03-31 22:28:18,417 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:28:18,465 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:28:18,465 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:28:18,950 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:28:18,989 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:28:18,989 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:28:19,467 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:28:19,468 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:28:19,468 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  14%|#4        | 36/250 [00:51<04:45,  1.33s/it, loss=0.0996]Epoch 1/1 [Train]:  15%|#4        | 37/250 [00:51<04:44,  1.33s/it, loss=0.0996]2025-03-31 22:28:19,751 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:28:19,791 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:28:19,791 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:28:20,289 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:28:20,335 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:28:20,335 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:28:20,806 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:28:20,806 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:28:20,806 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  15%|#4        | 37/250 [00:52<04:44,  1.33s/it, loss=0.119] Epoch 1/1 [Train]:  15%|#5        | 38/250 [00:52<04:43,  1.34s/it, loss=0.119]2025-03-31 22:28:21,122 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:28:21,170 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:28:21,171 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:28:21,655 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:28:21,695 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:28:21,695 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:28:22,171 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:28:22,171 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:28:22,171 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  15%|#5        | 38/250 [00:54<04:43,  1.34s/it, loss=0.104]Epoch 1/1 [Train]:  16%|#5        | 39/250 [00:54<04:44,  1.35s/it, loss=0.104]2025-03-31 22:28:22,462 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:28:22,507 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:28:22,508 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:28:22,995 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:28:23,037 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:28:23,037 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:28:23,512 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:28:23,512 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:28:23,512 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  16%|#5        | 39/250 [00:55<04:44,  1.35s/it, loss=0.106]Epoch 1/1 [Train]:  16%|#6        | 40/250 [00:55<04:42,  1.35s/it, loss=0.106]2025-03-31 22:28:23,802 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:28:23,844 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:28:23,844 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:28:24,334 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:28:24,372 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:28:24,372 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:28:24,849 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:28:24,849 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:28:24,849 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  16%|#6        | 40/250 [00:56<04:42,  1.35s/it, loss=0.116]Epoch 1/1 [Train]:  16%|#6        | 41/250 [00:56<04:40,  1.34s/it, loss=0.116]2025-03-31 22:28:25,182 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:28:25,236 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:28:25,236 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:28:25,720 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:28:25,764 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:28:25,764 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:28:26,237 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:28:26,237 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:28:26,237 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  16%|#6        | 41/250 [00:58<04:40,  1.34s/it, loss=0.109]Epoch 1/1 [Train]:  17%|#6        | 42/250 [00:58<04:42,  1.36s/it, loss=0.109]2025-03-31 22:28:26,522 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:28:26,565 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:28:26,565 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:28:27,051 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:28:27,095 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:28:27,095 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:28:27,568 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:28:27,568 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:28:27,568 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  17%|#6        | 42/250 [00:59<04:42,  1.36s/it, loss=0.112]Epoch 1/1 [Train]:  17%|#7        | 43/250 [00:59<04:38,  1.35s/it, loss=0.112]2025-03-31 22:28:27,861 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:28:27,907 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:28:27,907 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:28:28,395 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:28:28,433 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:28:28,434 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:28:28,913 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:28:28,913 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:28:28,913 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  17%|#7        | 43/250 [01:00<04:38,  1.35s/it, loss=0.131]Epoch 1/1 [Train]:  18%|#7        | 44/250 [01:00<04:37,  1.35s/it, loss=0.131]2025-03-31 22:28:29,196 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:28:29,239 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:28:29,239 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:28:29,737 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:28:29,782 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:28:29,782 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:28:30,256 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:28:30,257 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:28:30,257 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  18%|#7        | 44/250 [01:02<04:37,  1.35s/it, loss=0.125]Epoch 1/1 [Train]:  18%|#8        | 45/250 [01:02<04:36,  1.35s/it, loss=0.125]2025-03-31 22:28:30,548 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:28:30,590 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:28:30,590 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:28:31,080 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:28:31,121 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:28:31,121 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:28:31,601 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:28:31,601 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:28:31,601 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  18%|#8        | 45/250 [01:03<04:36,  1.35s/it, loss=0.129]Epoch 1/1 [Train]:  18%|#8        | 46/250 [01:03<04:35,  1.35s/it, loss=0.129]2025-03-31 22:28:31,912 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:28:31,968 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:28:31,968 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:28:32,446 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:28:32,496 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:28:32,496 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:28:32,968 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:28:32,968 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:28:32,968 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  18%|#8        | 46/250 [01:04<04:35,  1.35s/it, loss=0.1]  Epoch 1/1 [Train]:  19%|#8        | 47/250 [01:04<04:34,  1.35s/it, loss=0.1]2025-03-31 22:28:33,260 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:28:33,301 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:28:33,301 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:28:33,797 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:28:33,839 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:28:33,839 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:28:34,324 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:28:34,324 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:28:34,324 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  19%|#8        | 47/250 [01:06<04:34,  1.35s/it, loss=0.0974]Epoch 1/1 [Train]:  19%|#9        | 48/250 [01:06<04:33,  1.36s/it, loss=0.0974]2025-03-31 22:28:34,647 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:28:34,702 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:28:34,702 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:28:35,188 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:28:35,231 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:28:35,231 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:28:35,711 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:28:35,712 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:28:35,712 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  19%|#9        | 48/250 [01:07<04:33,  1.36s/it, loss=0.107] Epoch 1/1 [Train]:  20%|#9        | 49/250 [01:07<04:34,  1.36s/it, loss=0.107]2025-03-31 22:28:36,010 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:28:36,052 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:28:36,052 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:28:36,552 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:28:36,603 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:28:36,603 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:28:37,080 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:28:37,080 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:28:37,080 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  20%|#9        | 49/250 [01:08<04:34,  1.36s/it, loss=0.0982]Epoch 1/1 [Train]:  20%|##        | 50/250 [01:08<04:33,  1.37s/it, loss=0.0982]2025-03-31 22:28:37,374 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:28:37,420 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:28:37,420 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:28:37,913 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:28:37,958 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:28:37,958 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:28:38,439 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:28:38,439 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:28:38,439 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  20%|##        | 50/250 [01:10<04:33,  1.37s/it, loss=0.123] Epoch 1/1 [Train]:  20%|##        | 51/250 [01:10<04:31,  1.36s/it, loss=0.123]2025-03-31 22:28:38,745 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:28:38,794 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:28:38,794 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:28:39,294 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:28:39,362 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:28:39,362 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:28:39,820 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:28:39,821 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:28:39,821 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  20%|##        | 51/250 [01:11<04:31,  1.36s/it, loss=0.0862]Epoch 1/1 [Train]:  21%|##        | 52/250 [01:11<04:30,  1.37s/it, loss=0.0862]2025-03-31 22:28:40,098 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:28:40,141 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:28:40,142 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:28:40,632 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:28:40,675 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:28:40,675 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:28:41,166 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:28:41,166 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:28:41,166 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  21%|##        | 52/250 [01:13<04:30,  1.37s/it, loss=0.121] Epoch 1/1 [Train]:  21%|##1       | 53/250 [01:13<04:28,  1.36s/it, loss=0.121]2025-03-31 22:28:41,465 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:28:41,510 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:28:41,510 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:28:42,011 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:28:42,064 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:28:42,064 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:28:42,543 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:28:42,543 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:28:42,543 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  21%|##1       | 53/250 [01:14<04:28,  1.36s/it, loss=0.139]Epoch 1/1 [Train]:  22%|##1       | 54/250 [01:14<04:28,  1.37s/it, loss=0.139]2025-03-31 22:28:42,835 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:28:42,878 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:28:42,878 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:28:43,383 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:28:43,432 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:28:43,432 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:28:43,916 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:28:43,916 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:28:43,916 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  22%|##1       | 54/250 [01:15<04:28,  1.37s/it, loss=0.112]Epoch 1/1 [Train]:  22%|##2       | 55/250 [01:15<04:27,  1.37s/it, loss=0.112]2025-03-31 22:28:44,226 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:28:44,268 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:28:44,269 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:28:44,767 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:28:44,807 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:28:44,808 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:28:45,301 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:28:45,301 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:28:45,301 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  22%|##2       | 55/250 [01:17<04:27,  1.37s/it, loss=0.0996]Epoch 1/1 [Train]:  22%|##2       | 56/250 [01:17<04:26,  1.37s/it, loss=0.0996]2025-03-31 22:28:45,603 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:28:45,649 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:28:45,649 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:28:46,169 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:28:46,230 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:28:46,230 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:28:46,706 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:28:46,706 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:28:46,706 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  22%|##2       | 56/250 [01:18<04:26,  1.37s/it, loss=0.113] Epoch 1/1 [Train]:  23%|##2       | 57/250 [01:18<04:26,  1.38s/it, loss=0.113]2025-03-31 22:28:46,987 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:28:47,028 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:28:47,028 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:28:47,536 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:28:47,578 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:28:47,578 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:28:48,073 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:28:48,073 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:28:48,074 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  23%|##2       | 57/250 [01:19<04:26,  1.38s/it, loss=0.097]Epoch 1/1 [Train]:  23%|##3       | 58/250 [01:19<04:24,  1.38s/it, loss=0.097]2025-03-31 22:28:48,352 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:28:48,390 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:28:48,390 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:28:48,906 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:28:48,957 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:28:48,957 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:28:49,443 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:28:49,444 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:28:49,444 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  23%|##3       | 58/250 [01:21<04:24,  1.38s/it, loss=0.105]Epoch 1/1 [Train]:  24%|##3       | 59/250 [01:21<04:22,  1.37s/it, loss=0.105]2025-03-31 22:28:49,739 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:28:49,785 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:28:49,786 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:28:50,288 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:28:50,339 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:28:50,340 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:28:50,825 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:28:50,825 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:28:50,825 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  24%|##3       | 59/250 [01:22<04:22,  1.37s/it, loss=0.101]Epoch 1/1 [Train]:  24%|##4       | 60/250 [01:22<04:21,  1.38s/it, loss=0.101]2025-03-31 22:28:51,123 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:28:51,172 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:28:51,172 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:28:51,691 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:28:51,735 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:28:51,736 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:28:52,235 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:28:52,236 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:28:52,236 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  24%|##4       | 60/250 [01:24<04:21,  1.38s/it, loss=0.0879]Epoch 1/1 [Train]:  24%|##4       | 61/250 [01:24<04:22,  1.39s/it, loss=0.0879]2025-03-31 22:28:52,558 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:28:52,612 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:28:52,612 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:28:53,113 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:28:53,165 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:28:53,166 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:28:53,649 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:28:53,650 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:28:53,650 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  24%|##4       | 61/250 [01:25<04:22,  1.39s/it, loss=0.0911]Epoch 1/1 [Train]:  25%|##4       | 62/250 [01:25<04:22,  1.40s/it, loss=0.0911]2025-03-31 22:28:53,964 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:28:54,015 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:28:54,015 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:28:54,524 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:28:54,572 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:28:54,572 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:28:55,068 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:28:55,069 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:28:55,069 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  25%|##4       | 62/250 [01:26<04:22,  1.40s/it, loss=0.0853]Epoch 1/1 [Train]:  25%|##5       | 63/250 [01:26<04:22,  1.41s/it, loss=0.0853]2025-03-31 22:28:55,362 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:28:55,405 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:28:55,407 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:28:55,922 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:28:55,965 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:28:55,966 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:28:56,467 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:28:56,467 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:28:56,467 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  25%|##5       | 63/250 [01:28<04:22,  1.41s/it, loss=0.101] Epoch 1/1 [Train]:  26%|##5       | 64/250 [01:28<04:20,  1.40s/it, loss=0.101]2025-03-31 22:28:56,754 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:28:56,797 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:28:56,797 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:28:57,311 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:28:57,358 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:28:57,358 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:28:57,861 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:28:57,861 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:28:57,861 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  26%|##5       | 64/250 [01:29<04:20,  1.40s/it, loss=0.121]Epoch 1/1 [Train]:  26%|##6       | 65/250 [01:29<04:19,  1.40s/it, loss=0.121]2025-03-31 22:28:58,180 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:28:58,229 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:28:58,229 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:28:58,738 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:28:58,782 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:28:58,782 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:28:59,289 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:28:59,289 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:28:59,289 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  26%|##6       | 65/250 [01:31<04:19,  1.40s/it, loss=0.0702]Epoch 1/1 [Train]:  26%|##6       | 66/250 [01:31<04:18,  1.41s/it, loss=0.0702]2025-03-31 22:28:59,593 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:28:59,647 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:28:59,647 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:29:00,169 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:29:00,220 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:29:00,220 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:29:00,712 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:29:00,712 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:29:00,712 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  26%|##6       | 66/250 [01:32<04:18,  1.41s/it, loss=0.1]   Epoch 1/1 [Train]:  27%|##6       | 67/250 [01:32<04:18,  1.41s/it, loss=0.1]2025-03-31 22:29:01,029 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:29:01,079 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:29:01,079 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:29:01,588 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:29:01,634 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:29:01,634 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:29:02,139 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:29:02,139 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:29:02,139 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  27%|##6       | 67/250 [01:33<04:18,  1.41s/it, loss=0.112]Epoch 1/1 [Train]:  27%|##7       | 68/250 [01:33<04:18,  1.42s/it, loss=0.112]2025-03-31 22:29:02,480 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:29:02,534 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:29:02,534 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:29:03,040 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:29:03,088 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:29:03,088 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:29:03,586 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:29:03,586 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:29:03,587 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  27%|##7       | 68/250 [01:35<04:18,  1.42s/it, loss=0.115]Epoch 1/1 [Train]:  28%|##7       | 69/250 [01:35<04:17,  1.42s/it, loss=0.115]2025-03-31 22:29:03,895 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:29:03,960 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:29:03,960 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:29:04,455 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:29:04,502 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:29:04,503 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:29:05,001 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:29:05,001 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:29:05,002 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  28%|##7       | 69/250 [01:36<04:17,  1.42s/it, loss=0.0963]Epoch 1/1 [Train]:  28%|##8       | 70/250 [01:36<04:16,  1.43s/it, loss=0.0963]2025-03-31 22:29:05,322 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:29:05,365 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:29:05,365 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:29:05,885 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:29:05,932 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:29:05,932 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:29:06,431 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:29:06,432 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:29:06,432 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  28%|##8       | 70/250 [01:38<04:16,  1.43s/it, loss=0.107] Epoch 1/1 [Train]:  28%|##8       | 71/250 [01:38<04:15,  1.43s/it, loss=0.107]2025-03-31 22:29:06,758 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:29:06,802 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:29:06,802 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:29:07,328 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:29:07,374 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:29:07,374 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:29:07,874 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:29:07,874 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:29:07,874 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  28%|##8       | 71/250 [01:39<04:15,  1.43s/it, loss=0.0777]Epoch 1/1 [Train]:  29%|##8       | 72/250 [01:39<04:14,  1.43s/it, loss=0.0777]2025-03-31 22:29:08,200 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:29:08,252 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:29:08,253 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:29:08,773 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:29:08,836 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:29:08,836 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:29:09,324 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:29:09,325 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:29:09,325 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  29%|##8       | 72/250 [01:41<04:14,  1.43s/it, loss=0.0664]Epoch 1/1 [Train]:  29%|##9       | 73/250 [01:41<04:13,  1.43s/it, loss=0.0664]2025-03-31 22:29:09,612 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:29:09,666 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:29:09,666 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:29:10,166 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:29:10,212 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:29:10,212 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:29:10,722 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:29:10,722 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:29:10,722 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  29%|##9       | 73/250 [01:42<04:13,  1.43s/it, loss=0.112] Epoch 1/1 [Train]:  30%|##9       | 74/250 [01:42<04:10,  1.42s/it, loss=0.112]2025-03-31 22:29:11,038 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:29:11,091 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:29:11,092 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:29:11,605 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:29:11,659 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:29:11,659 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:29:12,166 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:29:12,166 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:29:12,166 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  30%|##9       | 74/250 [01:44<04:10,  1.42s/it, loss=0.0927]Epoch 1/1 [Train]:  30%|###       | 75/250 [01:44<04:10,  1.43s/it, loss=0.0927]2025-03-31 22:29:12,515 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:29:12,576 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:29:12,577 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:29:13,088 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:29:13,148 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:29:13,148 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:29:13,647 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:29:13,647 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:29:13,647 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  30%|###       | 75/250 [01:45<04:10,  1.43s/it, loss=0.0821]Epoch 1/1 [Train]:  30%|###       | 76/250 [01:45<04:10,  1.44s/it, loss=0.0821]2025-03-31 22:29:14,026 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:29:14,079 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:29:14,080 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:29:14,594 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:29:14,643 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:29:14,643 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:29:15,155 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:29:15,155 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:29:15,155 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  30%|###       | 76/250 [01:47<04:10,  1.44s/it, loss=0.0633]Epoch 1/1 [Train]:  31%|###       | 77/250 [01:47<04:13,  1.47s/it, loss=0.0633]2025-03-31 22:29:15,473 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:29:15,529 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:29:15,529 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:29:16,045 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:29:16,085 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:29:16,085 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:29:16,605 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:29:16,605 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:29:16,606 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  31%|###       | 77/250 [01:48<04:13,  1.47s/it, loss=0.0601]Epoch 1/1 [Train]:  31%|###1      | 78/250 [01:48<04:11,  1.46s/it, loss=0.0601]2025-03-31 22:29:16,943 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:29:16,991 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:29:16,991 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:29:17,513 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:29:17,554 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:29:17,555 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:29:18,075 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:29:18,075 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:29:18,076 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  31%|###1      | 78/250 [01:49<04:11,  1.46s/it, loss=0.0723]Epoch 1/1 [Train]:  32%|###1      | 79/250 [01:49<04:10,  1.46s/it, loss=0.0723]2025-03-31 22:29:18,376 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:29:18,419 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:29:18,419 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:29:18,946 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:29:18,993 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:29:18,993 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:29:19,506 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:29:19,507 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:29:19,507 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  32%|###1      | 79/250 [01:51<04:10,  1.46s/it, loss=0.0739]Epoch 1/1 [Train]:  32%|###2      | 80/250 [01:51<04:07,  1.46s/it, loss=0.0739]2025-03-31 22:29:19,817 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:29:19,867 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:29:19,867 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:29:20,384 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:29:20,429 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:29:20,429 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:29:20,938 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:29:20,938 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:29:20,938 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  32%|###2      | 80/250 [01:52<04:07,  1.46s/it, loss=0.0727]Epoch 1/1 [Train]:  32%|###2      | 81/250 [01:52<04:04,  1.45s/it, loss=0.0727]2025-03-31 22:29:21,230 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:29:21,276 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:29:21,276 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:29:21,821 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:29:21,862 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:29:21,862 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:29:22,397 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:29:22,397 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:29:22,398 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  32%|###2      | 81/250 [01:54<04:04,  1.45s/it, loss=0.0897]Epoch 1/1 [Train]:  33%|###2      | 82/250 [01:54<04:03,  1.45s/it, loss=0.0897]2025-03-31 22:29:22,688 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:29:22,733 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:29:22,733 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:29:23,268 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:29:23,321 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:29:23,321 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:29:23,829 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:29:23,830 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:29:23,830 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  33%|###2      | 82/250 [01:55<04:03,  1.45s/it, loss=0.0742]Epoch 1/1 [Train]:  33%|###3      | 83/250 [01:55<04:01,  1.45s/it, loss=0.0742]2025-03-31 22:29:24,175 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:29:24,228 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:29:24,228 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:29:24,742 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:29:24,789 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:29:24,789 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:29:25,303 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:29:25,303 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:29:25,303 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  33%|###3      | 83/250 [01:57<04:01,  1.45s/it, loss=0.0691]Epoch 1/1 [Train]:  34%|###3      | 84/250 [01:57<04:01,  1.45s/it, loss=0.0691]2025-03-31 22:29:25,619 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:29:25,664 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:29:25,664 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:29:26,198 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:29:26,252 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:29:26,252 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:29:26,778 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:29:26,778 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:29:26,778 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  34%|###3      | 84/250 [01:58<04:01,  1.45s/it, loss=0.073] Epoch 1/1 [Train]:  34%|###4      | 85/250 [01:58<04:01,  1.46s/it, loss=0.073]2025-03-31 22:29:27,108 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:29:27,164 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:29:27,164 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:29:27,689 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:29:27,741 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:29:27,741 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:29:28,251 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:29:28,251 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:29:28,251 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  34%|###4      | 85/250 [02:00<04:01,  1.46s/it, loss=0.118]Epoch 1/1 [Train]:  34%|###4      | 86/250 [02:00<04:00,  1.46s/it, loss=0.118]2025-03-31 22:29:28,586 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:29:28,645 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:29:28,645 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:29:29,166 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:29:29,217 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:29:29,217 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:29:29,729 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:29:29,729 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:29:29,729 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  34%|###4      | 86/250 [02:01<04:00,  1.46s/it, loss=0.0823]Epoch 1/1 [Train]:  35%|###4      | 87/250 [02:01<03:59,  1.47s/it, loss=0.0823]2025-03-31 22:29:30,077 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:29:30,133 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:29:30,134 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:29:30,650 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:29:30,701 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:29:30,701 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:29:31,220 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:29:31,221 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:29:31,221 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  35%|###4      | 87/250 [02:03<03:59,  1.47s/it, loss=0.0847]Epoch 1/1 [Train]:  35%|###5      | 88/250 [02:03<03:59,  1.48s/it, loss=0.0847]2025-03-31 22:29:31,552 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:29:31,602 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:29:31,602 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:29:32,126 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:29:32,175 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:29:32,176 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:29:32,689 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:29:32,690 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:29:32,690 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  35%|###5      | 88/250 [02:04<03:59,  1.48s/it, loss=0.0862]Epoch 1/1 [Train]:  36%|###5      | 89/250 [02:04<03:57,  1.47s/it, loss=0.0862]2025-03-31 22:29:33,000 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:29:33,047 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:29:33,047 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:29:33,595 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:29:33,643 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:29:33,643 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:29:34,175 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:29:34,175 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:29:34,175 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  36%|###5      | 89/250 [02:06<03:57,  1.47s/it, loss=0.108] Epoch 1/1 [Train]:  36%|###6      | 90/250 [02:06<03:55,  1.47s/it, loss=0.108]2025-03-31 22:29:34,493 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:29:34,548 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:29:34,548 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:29:35,089 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:29:35,141 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:29:35,141 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:29:35,667 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:29:35,667 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:29:35,667 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  36%|###6      | 90/250 [02:07<03:55,  1.47s/it, loss=0.0853]Epoch 1/1 [Train]:  36%|###6      | 91/250 [02:07<03:55,  1.48s/it, loss=0.0853]2025-03-31 22:29:35,973 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:29:36,021 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:29:36,021 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:29:36,552 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:29:36,602 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:29:36,602 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:29:37,114 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:29:37,114 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:29:37,114 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  36%|###6      | 91/250 [02:08<03:55,  1.48s/it, loss=0.0652]Epoch 1/1 [Train]:  37%|###6      | 92/250 [02:08<03:53,  1.47s/it, loss=0.0652]2025-03-31 22:29:37,457 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:29:37,510 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:29:37,510 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:29:38,035 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:29:38,085 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:29:38,085 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:29:38,598 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:29:38,599 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:29:38,599 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  37%|###6      | 92/250 [02:10<03:53,  1.47s/it, loss=0.068] Epoch 1/1 [Train]:  37%|###7      | 93/250 [02:10<03:51,  1.47s/it, loss=0.068]2025-03-31 22:29:38,898 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:29:38,942 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:29:38,943 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:29:39,473 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:29:39,516 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:29:39,516 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:29:40,050 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:29:40,050 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:29:40,050 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  37%|###7      | 93/250 [02:11<03:51,  1.47s/it, loss=0.0646]Epoch 1/1 [Train]:  38%|###7      | 94/250 [02:11<03:50,  1.48s/it, loss=0.0646]2025-03-31 22:29:40,426 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:29:40,485 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:29:40,485 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:29:41,014 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:29:41,056 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:29:41,057 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:29:41,589 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:29:41,590 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:29:41,590 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  38%|###7      | 94/250 [02:13<03:50,  1.48s/it, loss=0.102] Epoch 1/1 [Train]:  38%|###8      | 95/250 [02:13<03:50,  1.49s/it, loss=0.102]2025-03-31 22:29:41,904 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:29:41,953 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:29:41,953 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:29:42,497 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:29:42,542 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:29:42,542 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:29:43,073 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:29:43,073 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:29:43,073 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  38%|###8      | 95/250 [02:14<03:50,  1.49s/it, loss=0.086]Epoch 1/1 [Train]:  38%|###8      | 96/250 [02:14<03:48,  1.49s/it, loss=0.086]2025-03-31 22:29:43,427 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:29:43,478 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:29:43,479 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:29:44,001 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:29:44,045 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:29:44,045 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:29:44,569 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:29:44,569 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:29:44,569 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  38%|###8      | 96/250 [02:16<03:48,  1.49s/it, loss=0.0674]Epoch 1/1 [Train]:  39%|###8      | 97/250 [02:16<03:48,  1.49s/it, loss=0.0674]2025-03-31 22:29:44,897 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:29:44,946 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:29:44,946 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:29:45,487 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:29:45,534 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:29:45,534 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:29:46,061 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:29:46,061 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:29:46,061 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  39%|###8      | 97/250 [02:17<03:48,  1.49s/it, loss=0.0809]Epoch 1/1 [Train]:  39%|###9      | 98/250 [02:17<03:46,  1.49s/it, loss=0.0809]2025-03-31 22:29:46,388 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:29:46,445 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:29:46,445 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:29:46,984 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:29:47,041 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:29:47,041 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:29:47,557 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:29:47,557 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:29:47,558 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  39%|###9      | 98/250 [02:19<03:46,  1.49s/it, loss=0.0699]Epoch 1/1 [Train]:  40%|###9      | 99/250 [02:19<03:45,  1.49s/it, loss=0.0699]2025-03-31 22:29:47,884 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:29:47,934 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:29:47,934 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:29:48,459 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:29:48,499 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:29:48,499 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:29:49,027 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:29:49,028 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:29:49,028 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  40%|###9      | 99/250 [02:20<03:45,  1.49s/it, loss=0.103] Epoch 1/1 [Train]:  40%|####      | 100/250 [02:20<03:43,  1.49s/it, loss=0.103]2025-03-31 22:29:49,408 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:29:49,467 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:29:49,468 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:29:50,014 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:29:50,064 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:29:50,064 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:29:50,597 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:29:50,598 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:29:50,598 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  40%|####      | 100/250 [02:22<03:43,  1.49s/it, loss=0.105]Epoch 1/1 [Train]:  40%|####      | 101/250 [02:22<03:44,  1.51s/it, loss=0.105]2025-03-31 22:29:50,911 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:29:50,954 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:29:50,954 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:29:51,509 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:29:51,559 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:29:51,559 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:29:52,094 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:29:52,094 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:29:52,094 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  40%|####      | 101/250 [02:23<03:44,  1.51s/it, loss=0.0858]Epoch 1/1 [Train]:  41%|####      | 102/250 [02:23<03:42,  1.50s/it, loss=0.0858]2025-03-31 22:29:52,415 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:29:52,462 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:29:52,462 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:29:53,000 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:29:53,044 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:29:53,044 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:29:53,568 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:29:53,569 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:29:53,569 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  41%|####      | 102/250 [02:25<03:42,  1.50s/it, loss=0.0679]Epoch 1/1 [Train]:  41%|####1     | 103/250 [02:25<03:39,  1.49s/it, loss=0.0679]2025-03-31 22:29:53,871 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:29:53,932 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:29:53,932 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:29:54,457 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:29:54,504 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:29:54,505 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:29:55,046 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:29:55,047 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:29:55,047 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  41%|####1     | 103/250 [02:26<03:39,  1.49s/it, loss=0.087] Epoch 1/1 [Train]:  42%|####1     | 104/250 [02:26<03:38,  1.50s/it, loss=0.087]2025-03-31 22:29:55,398 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:29:55,465 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:29:55,465 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:29:56,009 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:29:56,061 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:29:56,061 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:29:56,598 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:29:56,598 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:29:56,598 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  42%|####1     | 104/250 [02:28<03:38,  1.50s/it, loss=0.063]Epoch 1/1 [Train]:  42%|####2     | 105/250 [02:28<03:38,  1.50s/it, loss=0.063]2025-03-31 22:29:56,912 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:29:56,962 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:29:56,962 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:29:57,498 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:29:57,546 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:29:57,546 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:29:58,067 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:29:58,067 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:29:58,068 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  42%|####2     | 105/250 [02:29<03:38,  1.50s/it, loss=0.0839]Epoch 1/1 [Train]:  42%|####2     | 106/250 [02:29<03:35,  1.50s/it, loss=0.0839]2025-03-31 22:29:58,355 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:29:58,399 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:29:58,399 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:29:58,938 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:29:58,986 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:29:58,986 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:29:59,523 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:29:59,523 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:29:59,523 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  42%|####2     | 106/250 [02:31<03:35,  1.50s/it, loss=0.0567]Epoch 1/1 [Train]:  43%|####2     | 107/250 [02:31<03:32,  1.48s/it, loss=0.0567]2025-03-31 22:29:59,830 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:29:59,878 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:29:59,879 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:30:00,412 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:30:00,457 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:30:00,457 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:30:01,019 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:30:01,019 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:30:01,019 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  43%|####2     | 107/250 [02:32<03:32,  1.48s/it, loss=0.0612]Epoch 1/1 [Train]:  43%|####3     | 108/250 [02:32<03:31,  1.49s/it, loss=0.0612]2025-03-31 22:30:01,332 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:30:01,379 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:30:01,379 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:30:01,932 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:30:01,974 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:30:01,974 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:30:02,518 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:30:02,518 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:30:02,518 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  43%|####3     | 108/250 [02:34<03:31,  1.49s/it, loss=0.0664]Epoch 1/1 [Train]:  44%|####3     | 109/250 [02:34<03:30,  1.49s/it, loss=0.0664]2025-03-31 22:30:02,820 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:30:02,869 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:30:02,869 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:30:03,403 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:30:03,454 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:30:03,454 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:30:03,958 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:30:03,958 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:30:03,958 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  44%|####3     | 109/250 [02:35<03:30,  1.49s/it, loss=0.0834]Epoch 1/1 [Train]:  44%|####4     | 110/250 [02:35<03:26,  1.47s/it, loss=0.0834]2025-03-31 22:30:04,248 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:30:04,292 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:30:04,292 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:30:04,833 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:30:04,875 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:30:04,875 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:30:05,411 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:30:05,411 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:30:05,411 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  44%|####4     | 110/250 [02:37<03:26,  1.47s/it, loss=0.107] Epoch 1/1 [Train]:  44%|####4     | 111/250 [02:37<03:23,  1.47s/it, loss=0.107]2025-03-31 22:30:05,712 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:30:05,755 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:30:05,756 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:30:06,292 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:30:06,332 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:30:06,332 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:30:06,881 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:30:06,881 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:30:06,881 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  44%|####4     | 111/250 [02:38<03:23,  1.47s/it, loss=0.0686]Epoch 1/1 [Train]:  45%|####4     | 112/250 [02:38<03:23,  1.47s/it, loss=0.0686]2025-03-31 22:30:07,192 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:30:07,240 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:30:07,240 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:30:07,777 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:30:07,819 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:30:07,819 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:30:08,353 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:30:08,354 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:30:08,354 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  45%|####4     | 112/250 [02:40<03:23,  1.47s/it, loss=0.0532]Epoch 1/1 [Train]:  45%|####5     | 113/250 [02:40<03:21,  1.47s/it, loss=0.0532]2025-03-31 22:30:08,665 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:30:08,715 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:30:08,715 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:30:09,275 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:30:09,323 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:30:09,323 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:30:09,868 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:30:09,868 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:30:09,868 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  45%|####5     | 113/250 [02:41<03:21,  1.47s/it, loss=0.0593]Epoch 1/1 [Train]:  46%|####5     | 114/250 [02:41<03:21,  1.48s/it, loss=0.0593]2025-03-31 22:30:10,196 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:30:10,245 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:30:10,246 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:30:10,789 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:30:10,839 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:30:10,839 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:30:11,373 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:30:11,373 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:30:11,373 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  46%|####5     | 114/250 [02:43<03:21,  1.48s/it, loss=0.1]   Epoch 1/1 [Train]:  46%|####6     | 115/250 [02:43<03:22,  1.50s/it, loss=0.1]2025-03-31 22:30:11,710 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:30:11,759 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:30:11,759 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:30:12,323 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:30:12,368 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:30:12,368 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:30:12,921 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:30:12,921 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:30:12,921 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  46%|####6     | 115/250 [02:44<03:22,  1.50s/it, loss=0.0615]Epoch 1/1 [Train]:  46%|####6     | 116/250 [02:44<03:22,  1.51s/it, loss=0.0615]2025-03-31 22:30:13,345 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:30:13,403 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:30:13,403 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:30:13,941 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:30:13,996 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:30:13,996 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:30:14,516 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:30:14,516 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:30:14,516 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  46%|####6     | 116/250 [02:46<03:22,  1.51s/it, loss=0.102] Epoch 1/1 [Train]:  47%|####6     | 117/250 [02:46<03:23,  1.53s/it, loss=0.102]2025-03-31 22:30:14,843 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:30:14,901 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:30:14,901 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:30:15,443 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:30:15,502 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:30:15,503 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:30:16,019 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:30:16,019 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:30:16,019 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  47%|####6     | 117/250 [02:47<03:23,  1.53s/it, loss=0.0764]Epoch 1/1 [Train]:  47%|####7     | 118/250 [02:47<03:21,  1.53s/it, loss=0.0764]2025-03-31 22:30:16,343 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:30:16,392 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:30:16,392 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:30:16,923 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:30:16,972 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:30:16,973 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:30:17,502 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:30:17,502 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:30:17,502 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  47%|####7     | 118/250 [02:49<03:21,  1.53s/it, loss=0.0629]Epoch 1/1 [Train]:  48%|####7     | 119/250 [02:49<03:17,  1.51s/it, loss=0.0629]2025-03-31 22:30:17,799 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:30:17,845 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:30:17,845 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:30:18,396 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:30:18,446 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:30:18,446 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:30:18,979 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:30:18,979 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:30:18,979 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  48%|####7     | 119/250 [02:50<03:17,  1.51s/it, loss=0.0882]Epoch 1/1 [Train]:  48%|####8     | 120/250 [02:50<03:15,  1.50s/it, loss=0.0882]2025-03-31 22:30:19,327 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:30:19,382 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:30:19,383 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:30:19,914 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:30:19,958 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:30:19,959 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:30:20,497 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:30:20,498 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:30:20,498 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  48%|####8     | 120/250 [02:52<03:15,  1.50s/it, loss=0.109] Epoch 1/1 [Train]:  48%|####8     | 121/250 [02:52<03:13,  1.50s/it, loss=0.109]2025-03-31 22:30:20,808 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:30:20,859 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:30:20,859 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:30:21,417 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:30:21,457 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:30:21,457 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:30:22,011 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:30:22,011 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:30:22,012 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  48%|####8     | 121/250 [02:53<03:13,  1.50s/it, loss=0.13] Epoch 1/1 [Train]:  49%|####8     | 122/250 [02:53<03:12,  1.50s/it, loss=0.13]2025-03-31 22:30:22,311 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:30:22,356 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:30:22,356 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:30:22,904 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:30:22,950 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:30:22,950 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:30:23,480 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:30:23,480 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:30:23,480 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  49%|####8     | 122/250 [02:55<03:12,  1.50s/it, loss=0.0761]Epoch 1/1 [Train]:  49%|####9     | 123/250 [02:55<03:09,  1.50s/it, loss=0.0761]2025-03-31 22:30:23,770 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:30:23,813 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:30:23,813 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:30:24,377 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:30:24,427 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:30:24,428 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:30:24,977 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:30:24,978 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:30:24,978 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  49%|####9     | 123/250 [02:56<03:09,  1.50s/it, loss=0.073] Epoch 1/1 [Train]:  50%|####9     | 124/250 [02:56<03:08,  1.50s/it, loss=0.073]2025-03-31 22:30:25,271 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:30:25,317 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:30:25,317 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:30:25,886 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:30:25,936 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:30:25,936 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:30:26,486 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:30:26,486 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:30:26,486 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  50%|####9     | 124/250 [02:58<03:08,  1.50s/it, loss=0.0988]Epoch 1/1 [Train]:  50%|#####     | 125/250 [02:58<03:08,  1.51s/it, loss=0.0988]2025-03-31 22:30:26,843 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:30:26,902 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:30:26,903 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:30:27,431 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:30:27,477 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:30:27,478 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:30:28,008 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:30:28,008 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:30:28,008 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  50%|#####     | 125/250 [02:59<03:08,  1.51s/it, loss=0.112] Epoch 1/1 [Train]:  50%|#####     | 126/250 [02:59<03:06,  1.51s/it, loss=0.112]2025-03-31 22:30:28,322 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:30:28,370 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:30:28,370 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:30:28,970 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:30:29,025 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:30:29,026 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:30:29,577 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:30:29,577 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:30:29,577 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  50%|#####     | 126/250 [03:01<03:06,  1.51s/it, loss=0.0556]Epoch 1/1 [Train]:  51%|#####     | 127/250 [03:01<03:08,  1.53s/it, loss=0.0556]2025-03-31 22:30:29,913 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:30:29,958 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:30:29,959 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:30:30,505 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:30:30,553 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:30:30,554 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:30:31,086 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:30:31,086 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:30:31,086 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  51%|#####     | 127/250 [03:02<03:08,  1.53s/it, loss=0.0809]Epoch 1/1 [Train]:  51%|#####1    | 128/250 [03:02<03:05,  1.52s/it, loss=0.0809]2025-03-31 22:30:31,397 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:30:31,438 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:30:31,438 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:30:31,991 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:30:32,032 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:30:32,032 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:30:32,572 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:30:32,572 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:30:32,572 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  51%|#####1    | 128/250 [03:04<03:05,  1.52s/it, loss=0.0686]Epoch 1/1 [Train]:  52%|#####1    | 129/250 [03:04<03:01,  1.50s/it, loss=0.0686]2025-03-31 22:30:32,863 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:30:32,920 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:30:32,921 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:30:33,460 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:30:33,509 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:30:33,509 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:30:34,041 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:30:34,041 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:30:34,041 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  52%|#####1    | 129/250 [03:05<03:01,  1.50s/it, loss=0.0683]Epoch 1/1 [Train]:  52%|#####2    | 130/250 [03:05<02:59,  1.49s/it, loss=0.0683]2025-03-31 22:30:34,335 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:30:34,377 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:30:34,377 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:30:34,894 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:30:34,958 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:30:34,959 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:30:35,478 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:30:35,478 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:30:35,478 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  52%|#####2    | 130/250 [03:07<02:59,  1.49s/it, loss=0.0523]Epoch 1/1 [Train]:  52%|#####2    | 131/250 [03:07<02:56,  1.48s/it, loss=0.0523]2025-03-31 22:30:35,824 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:30:35,875 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:30:35,875 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:30:36,421 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:30:36,472 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:30:36,473 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:30:37,010 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:30:37,010 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:30:37,010 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  52%|#####2    | 131/250 [03:08<02:56,  1.48s/it, loss=0.0597]Epoch 1/1 [Train]:  53%|#####2    | 132/250 [03:08<02:56,  1.50s/it, loss=0.0597]2025-03-31 22:30:37,313 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:30:37,353 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:30:37,353 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:30:37,913 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:30:37,956 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:30:37,956 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:30:38,501 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:30:38,501 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:30:38,501 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  53%|#####2    | 132/250 [03:10<02:56,  1.50s/it, loss=0.0914]Epoch 1/1 [Train]:  53%|#####3    | 133/250 [03:10<02:54,  1.49s/it, loss=0.0914]2025-03-31 22:30:38,803 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:30:38,847 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:30:38,847 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:30:39,405 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:30:39,449 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:30:39,449 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:30:39,992 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:30:39,992 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:30:39,993 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  53%|#####3    | 133/250 [03:11<02:54,  1.49s/it, loss=0.0772]Epoch 1/1 [Train]:  54%|#####3    | 134/250 [03:11<02:53,  1.50s/it, loss=0.0772]2025-03-31 22:30:40,314 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:30:40,362 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:30:40,362 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:30:40,904 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:30:40,947 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:30:40,948 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:30:41,488 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:30:41,488 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:30:41,489 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  54%|#####3    | 134/250 [03:13<02:53,  1.50s/it, loss=0.0996]Epoch 1/1 [Train]:  54%|#####4    | 135/250 [03:13<02:51,  1.49s/it, loss=0.0996]2025-03-31 22:30:41,800 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:30:41,851 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:30:41,852 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:30:42,393 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:30:42,446 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:30:42,447 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:30:42,978 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:30:42,978 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:30:42,978 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  54%|#####4    | 135/250 [03:14<02:51,  1.49s/it, loss=0.0937]Epoch 1/1 [Train]:  54%|#####4    | 136/250 [03:14<02:50,  1.49s/it, loss=0.0937]2025-03-31 22:30:43,298 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:30:43,346 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:30:43,346 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:30:43,894 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:30:43,939 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:30:43,939 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:30:44,478 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:30:44,478 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:30:44,478 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  54%|#####4    | 136/250 [03:16<02:50,  1.49s/it, loss=0.0736]Epoch 1/1 [Train]:  55%|#####4    | 137/250 [03:16<02:48,  1.49s/it, loss=0.0736]2025-03-31 22:30:44,796 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:30:44,845 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:30:44,845 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:30:45,397 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:30:45,447 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:30:45,447 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:30:45,980 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:30:45,980 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:30:45,981 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  55%|#####4    | 137/250 [03:17<02:48,  1.49s/it, loss=0.0685]Epoch 1/1 [Train]:  55%|#####5    | 138/250 [03:17<02:47,  1.50s/it, loss=0.0685]2025-03-31 22:30:46,320 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:30:46,378 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:30:46,378 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:30:46,918 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:30:46,966 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:30:46,966 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:30:47,507 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:30:47,507 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:30:47,507 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  55%|#####5    | 138/250 [03:19<02:47,  1.50s/it, loss=0.0795]Epoch 1/1 [Train]:  56%|#####5    | 139/250 [03:19<02:46,  1.50s/it, loss=0.0795]2025-03-31 22:30:47,796 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:30:47,840 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:30:47,840 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:30:48,400 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:30:48,447 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:30:48,447 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:30:48,990 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:30:48,990 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:30:48,990 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  56%|#####5    | 139/250 [03:20<02:46,  1.50s/it, loss=0.0635]Epoch 1/1 [Train]:  56%|#####6    | 140/250 [03:20<02:45,  1.50s/it, loss=0.0635]2025-03-31 22:30:49,311 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:30:49,358 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:30:49,358 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:30:49,906 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:30:49,952 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:30:49,952 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:30:50,482 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:30:50,483 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:30:50,483 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  56%|#####6    | 140/250 [03:22<02:45,  1.50s/it, loss=0.0895]Epoch 1/1 [Train]:  56%|#####6    | 141/250 [03:22<02:42,  1.49s/it, loss=0.0895]2025-03-31 22:30:50,779 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:30:50,826 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:30:50,826 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:30:51,381 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:30:51,428 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:30:51,429 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:30:51,971 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:30:51,971 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:30:51,971 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  56%|#####6    | 141/250 [03:23<02:42,  1.49s/it, loss=0.0996]Epoch 1/1 [Train]:  57%|#####6    | 142/250 [03:23<02:43,  1.51s/it, loss=0.0996]2025-03-31 22:30:52,406 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:30:52,463 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:30:52,463 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:30:52,975 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:30:53,025 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:30:53,025 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:30:53,581 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:30:53,582 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:30:53,582 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  57%|#####6    | 142/250 [03:25<02:43,  1.51s/it, loss=0.06]  Epoch 1/1 [Train]:  57%|#####7    | 143/250 [03:25<02:43,  1.53s/it, loss=0.06]2025-03-31 22:30:53,919 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:30:53,967 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:30:53,967 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:30:54,542 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:30:54,591 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:30:54,591 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:30:55,147 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:30:55,147 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:30:55,148 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  57%|#####7    | 143/250 [03:27<02:43,  1.53s/it, loss=0.0529]Epoch 1/1 [Train]:  58%|#####7    | 144/250 [03:27<02:43,  1.54s/it, loss=0.0529]2025-03-31 22:30:55,485 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:30:55,533 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:30:55,533 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:30:56,095 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:30:56,146 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:30:56,146 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:30:56,698 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:30:56,698 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:30:56,698 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  58%|#####7    | 144/250 [03:28<02:43,  1.54s/it, loss=0.0648]Epoch 1/1 [Train]:  58%|#####8    | 145/250 [03:28<02:41,  1.54s/it, loss=0.0648]2025-03-31 22:30:57,026 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:30:57,096 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:30:57,096 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:30:57,646 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:30:57,705 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:30:57,705 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:30:58,249 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:30:58,249 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:30:58,249 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  58%|#####8    | 145/250 [03:30<02:41,  1.54s/it, loss=0.0813]Epoch 1/1 [Train]:  58%|#####8    | 146/250 [03:30<02:40,  1.54s/it, loss=0.0813]2025-03-31 22:30:58,563 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:30:58,609 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:30:58,610 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:30:59,162 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:30:59,209 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:30:59,209 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:30:59,759 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:30:59,759 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:30:59,759 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  58%|#####8    | 146/250 [03:31<02:40,  1.54s/it, loss=0.0703]Epoch 1/1 [Train]:  59%|#####8    | 147/250 [03:31<02:37,  1.53s/it, loss=0.0703]2025-03-31 22:31:00,100 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:31:00,154 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:31:00,154 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:31:00,716 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:31:00,765 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:31:00,766 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:31:01,315 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:31:01,315 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:31:01,315 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  59%|#####8    | 147/250 [03:33<02:37,  1.53s/it, loss=0.0734]Epoch 1/1 [Train]:  59%|#####9    | 148/250 [03:33<02:36,  1.54s/it, loss=0.0734]2025-03-31 22:31:01,624 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:31:01,674 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:31:01,675 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:31:02,223 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:31:02,272 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:31:02,272 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:31:02,812 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:31:02,812 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:31:02,812 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  59%|#####9    | 148/250 [03:34<02:36,  1.54s/it, loss=0.0617]Epoch 1/1 [Train]:  60%|#####9    | 149/250 [03:34<02:34,  1.53s/it, loss=0.0617]2025-03-31 22:31:03,127 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:31:03,173 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:31:03,173 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:31:03,768 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:31:03,817 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:31:03,817 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:31:04,394 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:31:04,395 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:31:04,395 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  60%|#####9    | 149/250 [03:36<02:34,  1.53s/it, loss=0.0543]Epoch 1/1 [Train]:  60%|######    | 150/250 [03:36<02:34,  1.55s/it, loss=0.0543]2025-03-31 22:31:04,735 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:31:04,796 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:31:04,796 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:31:05,346 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:31:05,394 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:31:05,394 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:31:05,936 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:31:05,936 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:31:05,936 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  60%|######    | 150/250 [03:37<02:34,  1.55s/it, loss=0.0589]Epoch 1/1 [Train]:  60%|######    | 151/250 [03:37<02:32,  1.54s/it, loss=0.0589]2025-03-31 22:31:06,268 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:31:06,322 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:31:06,322 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:31:06,903 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:31:06,948 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:31:06,948 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:31:07,499 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:31:07,499 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:31:07,499 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  60%|######    | 151/250 [03:39<02:32,  1.54s/it, loss=0.0577]Epoch 1/1 [Train]:  61%|######    | 152/250 [03:39<02:32,  1.55s/it, loss=0.0577]2025-03-31 22:31:07,824 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:31:07,872 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:31:07,872 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:31:08,424 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:31:08,478 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:31:08,478 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:31:09,011 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:31:09,011 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:31:09,011 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  61%|######    | 152/250 [03:40<02:32,  1.55s/it, loss=0.0445]Epoch 1/1 [Train]:  61%|######1   | 153/250 [03:40<02:28,  1.53s/it, loss=0.0445]2025-03-31 22:31:09,346 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:31:09,400 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:31:09,400 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:31:09,986 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:31:10,034 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:31:10,034 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:31:10,604 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:31:10,605 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:31:10,605 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  61%|######1   | 153/250 [03:42<02:28,  1.53s/it, loss=0.052] Epoch 1/1 [Train]:  62%|######1   | 154/250 [03:42<02:29,  1.56s/it, loss=0.052]2025-03-31 22:31:10,933 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:31:10,985 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:31:10,985 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:31:11,573 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:31:11,625 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:31:11,625 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:31:12,193 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:31:12,193 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:31:12,193 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  62%|######1   | 154/250 [03:44<02:29,  1.56s/it, loss=0.0692]Epoch 1/1 [Train]:  62%|######2   | 155/250 [03:44<02:28,  1.56s/it, loss=0.0692]2025-03-31 22:31:12,527 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:31:12,586 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:31:12,586 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:31:13,128 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:31:13,181 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:31:13,182 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:31:13,716 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:31:13,716 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:31:13,716 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  62%|######2   | 155/250 [03:45<02:28,  1.56s/it, loss=0.074] Epoch 1/1 [Train]:  62%|######2   | 156/250 [03:45<02:25,  1.55s/it, loss=0.074]2025-03-31 22:31:14,035 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:31:14,079 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:31:14,079 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:31:14,668 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:31:14,722 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:31:14,722 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:31:15,284 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:31:15,285 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:31:15,285 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  62%|######2   | 156/250 [03:47<02:25,  1.55s/it, loss=0.0739]Epoch 1/1 [Train]:  63%|######2   | 157/250 [03:47<02:24,  1.56s/it, loss=0.0739]2025-03-31 22:31:15,636 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:31:15,687 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:31:15,688 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:31:16,235 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:31:16,277 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:31:16,277 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:31:16,821 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:31:16,821 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:31:16,821 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  63%|######2   | 157/250 [03:48<02:24,  1.56s/it, loss=0.0611]Epoch 1/1 [Train]:  63%|######3   | 158/250 [03:48<02:22,  1.55s/it, loss=0.0611]2025-03-31 22:31:17,153 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:31:17,207 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:31:17,208 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:31:17,801 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:31:17,861 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:31:17,861 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:31:18,428 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:31:18,428 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:31:18,429 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  63%|######3   | 158/250 [03:50<02:22,  1.55s/it, loss=0.067] Epoch 1/1 [Train]:  64%|######3   | 159/250 [03:50<02:22,  1.57s/it, loss=0.067]2025-03-31 22:31:18,747 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:31:18,793 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:31:18,793 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:31:19,387 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:31:19,436 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:31:19,436 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:31:20,014 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:31:20,015 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:31:20,015 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  64%|######3   | 159/250 [03:51<02:22,  1.57s/it, loss=0.0961]Epoch 1/1 [Train]:  64%|######4   | 160/250 [03:51<02:22,  1.58s/it, loss=0.0961]2025-03-31 22:31:20,365 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:31:20,413 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:31:20,413 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:31:21,007 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:31:21,054 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:31:21,054 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:31:21,634 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:31:21,634 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:31:21,635 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  64%|######4   | 160/250 [03:53<02:22,  1.58s/it, loss=0.065] Epoch 1/1 [Train]:  64%|######4   | 161/250 [03:53<02:21,  1.59s/it, loss=0.065]2025-03-31 22:31:21,978 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:31:22,031 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:31:22,031 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:31:22,580 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:31:22,627 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:31:22,627 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:31:23,171 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:31:23,171 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:31:23,171 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  64%|######4   | 161/250 [03:55<02:21,  1.59s/it, loss=0.0895]Epoch 1/1 [Train]:  65%|######4   | 162/250 [03:55<02:18,  1.57s/it, loss=0.0895]2025-03-31 22:31:23,517 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:31:23,569 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:31:23,570 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:31:24,120 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:31:24,172 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:31:24,172 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:31:24,735 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:31:24,735 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:31:24,735 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  65%|######4   | 162/250 [03:56<02:18,  1.57s/it, loss=0.0512]Epoch 1/1 [Train]:  65%|######5   | 163/250 [03:56<02:16,  1.57s/it, loss=0.0512]2025-03-31 22:31:25,081 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:31:25,134 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:31:25,134 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:31:25,709 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:31:25,767 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:31:25,767 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:31:26,323 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:31:26,324 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:31:26,327 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  65%|######5   | 163/250 [03:58<02:16,  1.57s/it, loss=0.0682]Epoch 1/1 [Train]:  66%|######5   | 164/250 [03:58<02:16,  1.58s/it, loss=0.0682]2025-03-31 22:31:26,711 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:31:26,765 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:31:26,765 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:31:27,312 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:31:27,371 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:31:27,371 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:31:27,916 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:31:27,916 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:31:27,916 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  66%|######5   | 164/250 [03:59<02:16,  1.58s/it, loss=0.0492]Epoch 1/1 [Train]:  66%|######6   | 165/250 [03:59<02:14,  1.58s/it, loss=0.0492]2025-03-31 22:31:28,253 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:31:28,303 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:31:28,303 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:31:28,851 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:31:28,893 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:31:28,893 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:31:29,452 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:31:29,452 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:31:29,452 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  66%|######6   | 165/250 [04:01<02:14,  1.58s/it, loss=0.0854]Epoch 1/1 [Train]:  66%|######6   | 166/250 [04:01<02:11,  1.57s/it, loss=0.0854]2025-03-31 22:31:29,787 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:31:29,830 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:31:29,830 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:31:30,402 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:31:30,446 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:31:30,446 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:31:31,004 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:31:31,004 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:31:31,004 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  66%|######6   | 166/250 [04:02<02:11,  1.57s/it, loss=0.0773]Epoch 1/1 [Train]:  67%|######6   | 167/250 [04:02<02:09,  1.57s/it, loss=0.0773]2025-03-31 22:31:31,395 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:31:31,455 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:31:31,455 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:31:32,013 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:31:32,072 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:31:32,072 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:31:32,619 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:31:32,619 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:31:32,620 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  67%|######6   | 167/250 [04:04<02:09,  1.57s/it, loss=0.0441]Epoch 1/1 [Train]:  67%|######7   | 168/250 [04:04<02:09,  1.58s/it, loss=0.0441]2025-03-31 22:31:32,954 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:31:33,009 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:31:33,010 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:31:33,560 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:31:33,613 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:31:33,613 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:31:34,157 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:31:34,157 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:31:34,157 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  67%|######7   | 168/250 [04:06<02:09,  1.58s/it, loss=0.0482]Epoch 1/1 [Train]:  68%|######7   | 169/250 [04:06<02:06,  1.56s/it, loss=0.0482]2025-03-31 22:31:34,486 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:31:34,540 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:31:34,540 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:31:35,099 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:31:35,146 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:31:35,146 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:31:35,696 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:31:35,696 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:31:35,696 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  68%|######7   | 169/250 [04:07<02:06,  1.56s/it, loss=0.0575]Epoch 1/1 [Train]:  68%|######8   | 170/250 [04:07<02:04,  1.56s/it, loss=0.0575]2025-03-31 22:31:36,020 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:31:36,066 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:31:36,067 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:31:36,653 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:31:36,710 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:31:36,710 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:31:37,269 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:31:37,270 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:31:37,270 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  68%|######8   | 170/250 [04:09<02:04,  1.56s/it, loss=0.0948]Epoch 1/1 [Train]:  68%|######8   | 171/250 [04:09<02:03,  1.56s/it, loss=0.0948]2025-03-31 22:31:37,598 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:31:37,645 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:31:37,645 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:31:38,208 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:31:38,254 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:31:38,254 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:31:38,819 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:31:38,819 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:31:38,819 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  68%|######8   | 171/250 [04:10<02:03,  1.56s/it, loss=0.0742]Epoch 1/1 [Train]:  69%|######8   | 172/250 [04:10<02:01,  1.56s/it, loss=0.0742]2025-03-31 22:31:39,193 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:31:39,239 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:31:39,240 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:31:39,788 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:31:39,831 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:31:39,831 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:31:40,389 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:31:40,389 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:31:40,389 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  69%|######8   | 172/250 [04:12<02:01,  1.56s/it, loss=0.0574]Epoch 1/1 [Train]:  69%|######9   | 173/250 [04:12<02:00,  1.56s/it, loss=0.0574]2025-03-31 22:31:40,715 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:31:40,768 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:31:40,768 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:31:41,329 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:31:41,380 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:31:41,381 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:31:41,931 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:31:41,931 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:31:41,931 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  69%|######9   | 173/250 [04:13<02:00,  1.56s/it, loss=0.0543]Epoch 1/1 [Train]:  70%|######9   | 174/250 [04:13<01:58,  1.56s/it, loss=0.0543]2025-03-31 22:31:42,257 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:31:42,305 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:31:42,305 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:31:42,874 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:31:42,918 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:31:42,918 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:31:43,477 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:31:43,477 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:31:43,477 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  70%|######9   | 174/250 [04:15<01:58,  1.56s/it, loss=0.0865]Epoch 1/1 [Train]:  70%|#######   | 175/250 [04:15<01:56,  1.55s/it, loss=0.0865]2025-03-31 22:31:43,824 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:31:43,880 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:31:43,880 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:31:44,428 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:31:44,474 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:31:44,475 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:31:45,025 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:31:45,025 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:31:45,025 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  70%|#######   | 175/250 [04:16<01:56,  1.55s/it, loss=0.053] Epoch 1/1 [Train]:  70%|#######   | 176/250 [04:16<01:54,  1.55s/it, loss=0.053]2025-03-31 22:31:45,337 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:31:45,386 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:31:45,387 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:31:46,002 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:31:46,050 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:31:46,050 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:31:46,653 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:31:46,653 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:31:46,653 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  70%|#######   | 176/250 [04:18<01:54,  1.55s/it, loss=0.051]Epoch 1/1 [Train]:  71%|#######   | 177/250 [04:18<01:54,  1.57s/it, loss=0.051]2025-03-31 22:31:46,966 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:31:47,015 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:31:47,015 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:31:47,584 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:31:47,626 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:31:47,626 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:31:48,190 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:31:48,190 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:31:48,190 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  71%|#######   | 177/250 [04:20<01:54,  1.57s/it, loss=0.0606]Epoch 1/1 [Train]:  71%|#######1  | 178/250 [04:20<01:52,  1.56s/it, loss=0.0606]2025-03-31 22:31:48,523 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:31:48,572 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:31:48,572 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:31:49,132 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:31:49,181 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:31:49,181 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:31:49,724 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:31:49,724 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:31:49,724 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  71%|#######1  | 178/250 [04:21<01:52,  1.56s/it, loss=0.0453]Epoch 1/1 [Train]:  72%|#######1  | 179/250 [04:21<01:50,  1.55s/it, loss=0.0453]2025-03-31 22:31:50,043 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:31:50,098 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:31:50,098 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:31:50,677 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:31:50,730 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:31:50,730 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:31:51,292 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:31:51,292 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:31:51,292 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  72%|#######1  | 179/250 [04:23<01:50,  1.55s/it, loss=0.0926]Epoch 1/1 [Train]:  72%|#######2  | 180/250 [04:23<01:49,  1.56s/it, loss=0.0926]2025-03-31 22:31:51,641 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:31:51,694 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:31:51,694 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:31:52,251 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:31:52,297 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:31:52,298 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:31:52,860 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:31:52,860 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:31:52,860 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  72%|#######2  | 180/250 [04:24<01:49,  1.56s/it, loss=0.0859]Epoch 1/1 [Train]:  72%|#######2  | 181/250 [04:24<01:47,  1.56s/it, loss=0.0859]2025-03-31 22:31:53,244 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:31:53,301 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:31:53,301 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:31:53,884 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:31:53,940 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:31:53,941 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:31:54,526 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:31:54,527 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:31:54,527 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  72%|#######2  | 181/250 [04:26<01:47,  1.56s/it, loss=0.071] Epoch 1/1 [Train]:  73%|#######2  | 182/250 [04:26<01:47,  1.59s/it, loss=0.071]2025-03-31 22:31:54,843 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:31:54,889 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:31:54,890 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:31:55,504 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:31:55,550 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:31:55,551 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:31:56,143 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:31:56,143 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:31:56,143 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  73%|#######2  | 182/250 [04:28<01:47,  1.59s/it, loss=0.0862]Epoch 1/1 [Train]:  73%|#######3  | 183/250 [04:28<01:47,  1.60s/it, loss=0.0862]2025-03-31 22:31:56,474 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:31:56,518 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:31:56,518 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:31:57,077 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:31:57,128 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:31:57,128 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:31:57,672 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:31:57,672 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:31:57,672 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  73%|#######3  | 183/250 [04:29<01:47,  1.60s/it, loss=0.0543]Epoch 1/1 [Train]:  74%|#######3  | 184/250 [04:29<01:44,  1.58s/it, loss=0.0543]2025-03-31 22:31:57,977 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:31:58,022 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:31:58,023 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:31:58,615 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:31:58,659 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:31:58,659 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:31:59,244 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:31:59,244 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:31:59,245 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  74%|#######3  | 184/250 [04:31<01:44,  1.58s/it, loss=0.0772]Epoch 1/1 [Train]:  74%|#######4  | 185/250 [04:31<01:42,  1.58s/it, loss=0.0772]2025-03-31 22:31:59,580 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:31:59,637 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:31:59,637 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:32:00,183 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:32:00,232 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:32:00,232 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:32:00,789 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:32:00,789 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:32:00,789 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  74%|#######4  | 185/250 [04:32<01:42,  1.58s/it, loss=0.0576]Epoch 1/1 [Train]:  74%|#######4  | 186/250 [04:32<01:40,  1.57s/it, loss=0.0576]2025-03-31 22:32:01,150 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:32:01,215 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:32:01,215 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:32:01,789 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:32:01,840 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:32:01,840 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:32:02,406 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:32:02,406 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:32:02,406 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  74%|#######4  | 186/250 [04:34<01:40,  1.57s/it, loss=0.0823]Epoch 1/1 [Train]:  75%|#######4  | 187/250 [04:34<01:39,  1.58s/it, loss=0.0823]2025-03-31 22:32:02,736 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:32:02,791 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:32:02,792 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:32:03,374 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:32:03,436 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:32:03,436 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:32:03,992 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:32:03,992 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:32:03,992 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  75%|#######4  | 187/250 [04:35<01:39,  1.58s/it, loss=0.0653]Epoch 1/1 [Train]:  75%|#######5  | 188/250 [04:35<01:37,  1.58s/it, loss=0.0653]2025-03-31 22:32:04,306 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:32:04,355 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:32:04,355 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:32:04,910 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:32:04,970 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:32:04,971 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:32:05,502 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:32:05,502 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:32:05,502 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  75%|#######5  | 188/250 [04:37<01:37,  1.58s/it, loss=0.0596]Epoch 1/1 [Train]:  76%|#######5  | 189/250 [04:37<01:35,  1.56s/it, loss=0.0596]2025-03-31 22:32:05,853 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:32:05,907 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:32:05,908 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:32:06,471 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:32:06,524 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:32:06,524 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:32:07,104 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:32:07,104 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:32:07,104 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  76%|#######5  | 189/250 [04:38<01:35,  1.56s/it, loss=0.0497]Epoch 1/1 [Train]:  76%|#######6  | 190/250 [04:38<01:34,  1.58s/it, loss=0.0497]2025-03-31 22:32:07,441 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:32:07,488 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:32:07,489 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:32:08,093 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:32:08,141 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:32:08,141 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:32:08,730 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:32:08,730 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:32:08,730 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  76%|#######6  | 190/250 [04:40<01:34,  1.58s/it, loss=0.0999]Epoch 1/1 [Train]:  76%|#######6  | 191/250 [04:40<01:33,  1.59s/it, loss=0.0999]2025-03-31 22:32:09,076 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:32:09,135 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:32:09,136 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:32:09,687 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:32:09,731 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:32:09,731 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:32:10,283 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:32:10,283 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:32:10,283 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  76%|#######6  | 191/250 [04:42<01:33,  1.59s/it, loss=0.0719]Epoch 1/1 [Train]:  77%|#######6  | 192/250 [04:42<01:31,  1.58s/it, loss=0.0719]2025-03-31 22:32:10,649 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:32:10,703 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:32:10,703 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:32:11,264 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:32:11,318 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:32:11,318 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:32:11,882 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:32:11,882 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:32:11,882 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  77%|#######6  | 192/250 [04:43<01:31,  1.58s/it, loss=0.0538]Epoch 1/1 [Train]:  77%|#######7  | 193/250 [04:43<01:30,  1.59s/it, loss=0.0538]2025-03-31 22:32:12,357 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:32:12,421 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:32:12,421 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:32:12,962 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:32:13,016 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:32:13,017 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:32:13,576 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:32:13,576 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:32:13,576 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  77%|#######7  | 193/250 [04:45<01:30,  1.59s/it, loss=0.0435]Epoch 1/1 [Train]:  78%|#######7  | 194/250 [04:45<01:30,  1.62s/it, loss=0.0435]2025-03-31 22:32:13,928 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:32:13,979 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:32:13,980 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:32:14,542 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:32:14,595 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:32:14,595 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:32:15,160 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:32:15,160 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:32:15,160 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  78%|#######7  | 194/250 [04:47<01:30,  1.62s/it, loss=0.0607]Epoch 1/1 [Train]:  78%|#######8  | 195/250 [04:47<01:28,  1.60s/it, loss=0.0607]2025-03-31 22:32:15,541 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:32:15,605 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:32:15,605 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:32:16,165 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:32:16,213 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:32:16,213 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:32:16,763 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:32:16,763 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:32:16,764 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  78%|#######8  | 195/250 [04:48<01:28,  1.60s/it, loss=0.0619]Epoch 1/1 [Train]:  78%|#######8  | 196/250 [04:48<01:26,  1.60s/it, loss=0.0619]2025-03-31 22:32:17,102 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:32:17,163 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:32:17,163 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:32:17,749 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:32:17,796 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:32:17,796 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:32:18,378 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:32:18,379 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:32:18,379 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  78%|#######8  | 196/250 [04:50<01:26,  1.60s/it, loss=0.051] Epoch 1/1 [Train]:  79%|#######8  | 197/250 [04:50<01:25,  1.61s/it, loss=0.051]2025-03-31 22:32:18,738 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:32:18,798 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:32:18,798 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:32:19,386 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:32:19,433 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:32:19,433 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:32:20,017 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:32:20,017 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:32:20,017 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  79%|#######8  | 197/250 [04:51<01:25,  1.61s/it, loss=0.0559]Epoch 1/1 [Train]:  79%|#######9  | 198/250 [04:51<01:24,  1.62s/it, loss=0.0559]2025-03-31 22:32:20,336 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:32:20,384 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:32:20,384 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:32:20,979 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:32:21,025 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:32:21,026 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:32:21,610 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:32:21,610 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:32:21,610 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  79%|#######9  | 198/250 [04:53<01:24,  1.62s/it, loss=0.0533]Epoch 1/1 [Train]:  80%|#######9  | 199/250 [04:53<01:22,  1.61s/it, loss=0.0533]2025-03-31 22:32:21,967 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:32:22,022 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:32:22,022 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:32:22,575 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:32:22,623 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:32:22,624 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:32:23,198 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:32:23,199 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:32:23,199 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  80%|#######9  | 199/250 [04:55<01:22,  1.61s/it, loss=0.0617]Epoch 1/1 [Train]:  80%|########  | 200/250 [04:55<01:20,  1.60s/it, loss=0.0617]2025-03-31 22:32:23,534 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:32:23,592 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:32:23,592 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:32:24,141 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:32:24,196 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:32:24,196 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:32:24,747 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:32:24,747 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:32:24,748 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  80%|########  | 200/250 [04:56<01:20,  1.60s/it, loss=0.0698]Epoch 1/1 [Train]:  80%|########  | 201/250 [04:56<01:17,  1.59s/it, loss=0.0698]2025-03-31 22:32:25,149 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:32:25,210 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:32:25,210 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:32:25,803 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:32:25,861 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:32:25,861 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:32:26,401 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:32:26,401 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:32:26,401 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  80%|########  | 201/250 [04:58<01:17,  1.59s/it, loss=0.079] Epoch 1/1 [Train]:  81%|########  | 202/250 [04:58<01:17,  1.61s/it, loss=0.079]2025-03-31 22:32:26,778 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:32:26,824 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:32:26,824 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:32:27,433 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:32:27,479 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:32:27,479 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:32:28,072 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:32:28,073 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:32:28,073 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  81%|########  | 202/250 [04:59<01:17,  1.61s/it, loss=0.066]Epoch 1/1 [Train]:  81%|########1 | 203/250 [04:59<01:16,  1.62s/it, loss=0.066]2025-03-31 22:32:28,408 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:32:28,460 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:32:28,460 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:32:29,065 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:32:29,129 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:32:29,130 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:32:29,665 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:32:29,665 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:32:29,665 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  81%|########1 | 203/250 [05:01<01:16,  1.62s/it, loss=0.0697]Epoch 1/1 [Train]:  82%|########1 | 204/250 [05:01<01:14,  1.61s/it, loss=0.0697]2025-03-31 22:32:29,964 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:32:30,019 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:32:30,019 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:32:30,595 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:32:30,652 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:32:30,652 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:32:31,221 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:32:31,221 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:32:31,221 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  82%|########1 | 204/250 [05:03<01:14,  1.61s/it, loss=0.0627]Epoch 1/1 [Train]:  82%|########2 | 205/250 [05:03<01:12,  1.60s/it, loss=0.0627]2025-03-31 22:32:31,544 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:32:31,595 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:32:31,595 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:32:32,147 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:32:32,200 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:32:32,200 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:32:32,779 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:32:32,779 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:32:32,779 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  82%|########2 | 205/250 [05:04<01:12,  1.60s/it, loss=0.0524]Epoch 1/1 [Train]:  82%|########2 | 206/250 [05:04<01:09,  1.59s/it, loss=0.0524]2025-03-31 22:32:33,212 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:32:33,272 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:32:33,272 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:32:33,829 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:32:33,875 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:32:33,875 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:32:34,434 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:32:34,434 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:32:34,434 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  82%|########2 | 206/250 [05:06<01:09,  1.59s/it, loss=0.0604]Epoch 1/1 [Train]:  83%|########2 | 207/250 [05:06<01:09,  1.61s/it, loss=0.0604]2025-03-31 22:32:34,760 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:32:34,808 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:32:34,808 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:32:35,321 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:32:35,369 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:32:35,369 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:32:35,962 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:32:35,963 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:32:35,963 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  83%|########2 | 207/250 [05:07<01:09,  1.61s/it, loss=0.0907]Epoch 1/1 [Train]:  83%|########3 | 208/250 [05:07<01:06,  1.59s/it, loss=0.0907]2025-03-31 22:32:36,281 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:32:36,328 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:32:36,329 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:32:36,934 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:32:36,978 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:32:36,978 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:32:37,573 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:32:37,573 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:32:37,573 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  83%|########3 | 208/250 [05:09<01:06,  1.59s/it, loss=0.0543]Epoch 1/1 [Train]:  84%|########3 | 209/250 [05:09<01:05,  1.59s/it, loss=0.0543]2025-03-31 22:32:37,903 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:32:37,949 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:32:37,949 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:32:38,532 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:32:38,606 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:32:38,606 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:32:39,168 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:32:39,168 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:32:39,168 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  84%|########3 | 209/250 [05:11<01:05,  1.59s/it, loss=0.0664]Epoch 1/1 [Train]:  84%|########4 | 210/250 [05:11<01:04,  1.60s/it, loss=0.0664]2025-03-31 22:32:39,713 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:32:39,785 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:32:39,786 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:32:40,315 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:32:40,364 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:32:40,364 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:32:40,929 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:32:40,930 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:32:40,930 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  84%|########4 | 210/250 [05:12<01:04,  1.60s/it, loss=0.0651]Epoch 1/1 [Train]:  84%|########4 | 211/250 [05:12<01:04,  1.65s/it, loss=0.0651]2025-03-31 22:32:41,389 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:32:41,447 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:32:41,447 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:32:41,998 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:32:42,046 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:32:42,046 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:32:42,613 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:32:42,613 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:32:42,613 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  84%|########4 | 211/250 [05:14<01:04,  1.65s/it, loss=0.09]  Epoch 1/1 [Train]:  85%|########4 | 212/250 [05:14<01:03,  1.67s/it, loss=0.09]2025-03-31 22:32:43,092 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:32:43,158 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:32:43,158 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:32:43,732 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:32:43,796 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:32:43,797 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:32:44,386 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:32:44,386 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:32:44,386 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  85%|########4 | 212/250 [05:16<01:03,  1.67s/it, loss=0.0738]Epoch 1/1 [Train]:  85%|########5 | 213/250 [05:16<01:02,  1.69s/it, loss=0.0738]2025-03-31 22:32:44,773 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:32:44,837 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:32:44,837 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:32:45,443 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:32:45,496 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:32:45,497 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:32:46,077 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:32:46,077 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:32:46,077 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  85%|########5 | 213/250 [05:17<01:02,  1.69s/it, loss=0.0901]Epoch 1/1 [Train]:  86%|########5 | 214/250 [05:17<01:00,  1.68s/it, loss=0.0901]2025-03-31 22:32:46,393 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:32:46,448 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:32:46,448 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:32:47,037 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:32:47,085 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:32:47,085 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:32:47,669 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:32:47,669 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:32:47,669 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  86%|########5 | 214/250 [05:19<01:00,  1.68s/it, loss=0.0604]Epoch 1/1 [Train]:  86%|########6 | 215/250 [05:19<00:58,  1.66s/it, loss=0.0604]2025-03-31 22:32:47,999 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:32:48,049 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:32:48,049 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:32:48,646 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:32:48,705 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:32:48,706 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:32:49,279 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:32:49,279 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:32:49,279 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  86%|########6 | 215/250 [05:21<00:58,  1.66s/it, loss=0.0583]Epoch 1/1 [Train]:  86%|########6 | 216/250 [05:21<00:55,  1.64s/it, loss=0.0583]2025-03-31 22:32:49,604 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:32:49,653 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:32:49,653 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:32:50,252 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:32:50,317 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:32:50,317 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:32:50,884 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:32:50,884 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:32:50,884 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  86%|########6 | 216/250 [05:22<00:55,  1.64s/it, loss=0.0521]Epoch 1/1 [Train]:  87%|########6 | 217/250 [05:22<00:53,  1.63s/it, loss=0.0521]2025-03-31 22:32:51,240 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:32:51,287 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:32:51,287 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:32:51,867 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:32:51,915 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:32:51,915 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:32:52,499 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:32:52,499 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:32:52,499 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  87%|########6 | 217/250 [05:24<00:53,  1.63s/it, loss=0.0492]Epoch 1/1 [Train]:  87%|########7 | 218/250 [05:24<00:52,  1.63s/it, loss=0.0492]2025-03-31 22:32:52,817 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:32:52,864 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:32:52,864 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:32:53,438 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:32:53,483 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:32:53,483 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:32:54,076 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:32:54,076 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:32:54,076 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  87%|########7 | 218/250 [05:25<00:52,  1.63s/it, loss=0.0633]Epoch 1/1 [Train]:  88%|########7 | 219/250 [05:25<00:49,  1.61s/it, loss=0.0633]2025-03-31 22:32:54,390 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:32:54,436 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:32:54,436 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:32:55,041 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:32:55,084 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:32:55,085 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:32:55,678 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:32:55,678 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:32:55,678 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  88%|########7 | 219/250 [05:27<00:49,  1.61s/it, loss=0.0769]Epoch 1/1 [Train]:  88%|########8 | 220/250 [05:27<00:48,  1.61s/it, loss=0.0769]2025-03-31 22:32:56,021 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:32:56,067 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:32:56,067 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:32:56,675 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:32:56,720 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:32:56,720 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:32:57,313 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:32:57,313 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:32:57,313 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  88%|########8 | 220/250 [05:29<00:48,  1.61s/it, loss=0.0676]Epoch 1/1 [Train]:  88%|########8 | 221/250 [05:29<00:46,  1.62s/it, loss=0.0676]2025-03-31 22:32:57,638 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:32:57,680 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:32:57,680 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:32:58,299 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:32:58,352 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:32:58,353 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:32:58,936 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:32:58,936 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:32:58,936 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  88%|########8 | 221/250 [05:30<00:46,  1.62s/it, loss=0.0501]Epoch 1/1 [Train]:  89%|########8 | 222/250 [05:30<00:45,  1.61s/it, loss=0.0501]2025-03-31 22:32:59,252 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:32:59,305 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:32:59,305 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:32:59,918 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:33:00,004 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:33:00,005 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:33:00,555 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:33:00,555 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:33:00,555 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  89%|########8 | 222/250 [05:32<00:45,  1.61s/it, loss=0.0489]Epoch 1/1 [Train]:  89%|########9 | 223/250 [05:32<00:45,  1.70s/it, loss=0.0489]2025-03-31 22:33:01,226 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:33:01,289 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:33:01,289 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:33:01,816 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:33:01,857 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:33:01,857 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:33:02,445 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:33:02,445 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:33:02,445 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  89%|########9 | 223/250 [05:34<00:45,  1.70s/it, loss=0.0466]Epoch 1/1 [Train]:  90%|########9 | 224/250 [05:34<00:43,  1.68s/it, loss=0.0466]2025-03-31 22:33:02,775 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:33:02,831 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:33:02,832 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:33:03,460 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:33:03,536 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:33:03,537 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:33:04,063 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:33:04,063 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:33:04,063 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  90%|########9 | 224/250 [05:36<00:43,  1.68s/it, loss=0.0501]Epoch 1/1 [Train]:  90%|######### | 225/250 [05:36<00:42,  1.68s/it, loss=0.0501]2025-03-31 22:33:04,549 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:33:04,602 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:33:04,602 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:33:05,143 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:33:05,190 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:33:05,190 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:33:05,781 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:33:05,781 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:33:05,781 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  90%|######### | 225/250 [05:38<00:42,  1.68s/it, loss=0.0706]Epoch 1/1 [Train]:  90%|######### | 226/250 [05:38<00:45,  1.91s/it, loss=0.0706]2025-03-31 22:33:07,558 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:33:07,650 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:33:07,651 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:33:08,187 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:33:08,252 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:33:08,253 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:33:08,812 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:33:08,812 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:33:08,812 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  90%|######### | 226/250 [05:40<00:45,  1.91s/it, loss=0.0725]Epoch 1/1 [Train]:  91%|######### | 227/250 [05:40<00:46,  2.03s/it, loss=0.0725]2025-03-31 22:33:09,283 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:33:09,341 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:33:09,341 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:33:09,911 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:33:09,965 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:33:09,965 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:33:10,524 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:33:10,524 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:33:10,524 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  91%|######### | 227/250 [05:42<00:46,  2.03s/it, loss=0.0792]Epoch 1/1 [Train]:  91%|#########1| 228/250 [05:42<00:41,  1.91s/it, loss=0.0792]2025-03-31 22:33:10,878 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:33:10,926 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:33:10,927 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:33:11,523 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:33:11,574 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:33:11,575 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:33:12,169 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:33:12,169 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:33:12,169 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  91%|#########1| 228/250 [05:44<00:41,  1.91s/it, loss=0.0541]Epoch 1/1 [Train]:  92%|#########1| 229/250 [05:44<00:39,  1.87s/it, loss=0.0541]2025-03-31 22:33:12,652 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:33:12,707 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:33:12,708 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:33:13,232 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:33:13,293 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:33:13,293 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:33:13,881 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:33:13,882 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:33:13,882 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  92%|#########1| 229/250 [05:45<00:39,  1.87s/it, loss=0.0733]Epoch 1/1 [Train]:  92%|#########2| 230/250 [05:45<00:35,  1.78s/it, loss=0.0733]2025-03-31 22:33:14,229 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:33:14,282 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:33:14,282 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:33:14,895 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:33:14,944 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:33:14,945 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:33:15,550 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:33:15,550 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:33:15,550 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  92%|#########2| 230/250 [05:47<00:35,  1.78s/it, loss=0.0452]Epoch 1/1 [Train]:  92%|#########2| 231/250 [05:47<00:33,  1.75s/it, loss=0.0452]2025-03-31 22:33:15,897 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:33:15,961 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:33:15,961 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:33:16,567 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:33:16,622 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:33:16,622 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:33:17,187 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:33:17,187 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:33:17,187 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  92%|#########2| 231/250 [05:49<00:33,  1.75s/it, loss=0.0456]Epoch 1/1 [Train]:  93%|#########2| 232/250 [05:49<00:30,  1.72s/it, loss=0.0456]2025-03-31 22:33:17,519 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:33:17,568 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:33:17,569 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:33:18,192 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:33:18,251 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:33:18,251 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:33:18,812 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:33:18,812 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:33:18,812 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  93%|#########2| 232/250 [05:50<00:30,  1.72s/it, loss=0.0799]Epoch 1/1 [Train]:  93%|#########3| 233/250 [05:50<00:28,  1.69s/it, loss=0.0799]2025-03-31 22:33:19,199 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:33:19,252 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:33:19,252 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:33:19,829 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:33:19,883 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:33:19,883 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:33:20,446 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:33:20,446 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:33:20,447 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  93%|#########3| 233/250 [05:52<00:28,  1.69s/it, loss=0.059] Epoch 1/1 [Train]:  94%|#########3| 234/250 [05:52<00:26,  1.67s/it, loss=0.059]2025-03-31 22:33:20,753 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:33:20,793 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:33:20,794 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:33:21,381 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:33:21,419 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:33:21,419 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:33:21,999 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:33:21,999 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:33:21,999 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  94%|#########3| 234/250 [05:53<00:26,  1.67s/it, loss=0.0651]Epoch 1/1 [Train]:  94%|#########3| 235/250 [05:53<00:24,  1.63s/it, loss=0.0651]2025-03-31 22:33:22,336 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:33:22,395 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:33:22,395 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:33:22,969 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:33:23,014 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:33:23,014 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:33:23,599 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:33:23,600 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:33:23,600 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  94%|#########3| 235/250 [05:55<00:24,  1.63s/it, loss=0.0528]Epoch 1/1 [Train]:  94%|#########4| 236/250 [05:55<00:22,  1.63s/it, loss=0.0528]2025-03-31 22:33:23,912 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:33:23,955 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:33:23,956 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:33:24,558 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:33:24,605 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:33:24,605 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:33:25,187 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:33:25,187 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:33:25,187 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  94%|#########4| 236/250 [05:57<00:22,  1.63s/it, loss=0.0421]Epoch 1/1 [Train]:  95%|#########4| 237/250 [05:57<00:21,  1.62s/it, loss=0.0421]2025-03-31 22:33:25,513 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:33:25,557 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:33:25,558 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:33:26,154 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:33:26,202 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:33:26,202 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:33:26,783 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:33:26,784 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:33:26,784 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  95%|#########4| 237/250 [05:58<00:21,  1.62s/it, loss=0.045] Epoch 1/1 [Train]:  95%|#########5| 238/250 [05:58<00:19,  1.61s/it, loss=0.045]2025-03-31 22:33:27,138 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:33:27,197 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:33:27,197 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:33:27,779 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:33:27,820 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:33:27,820 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:33:28,409 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:33:28,409 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:33:28,409 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  95%|#########5| 238/250 [06:00<00:19,  1.61s/it, loss=0.0766]Epoch 1/1 [Train]:  96%|#########5| 239/250 [06:00<00:17,  1.61s/it, loss=0.0766]2025-03-31 22:33:28,721 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:33:28,767 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:33:28,767 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:33:29,371 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:33:29,422 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:33:29,423 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:33:30,001 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:33:30,001 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:33:30,001 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  96%|#########5| 239/250 [06:01<00:17,  1.61s/it, loss=0.0389]Epoch 1/1 [Train]:  96%|#########6| 240/250 [06:01<00:16,  1.61s/it, loss=0.0389]2025-03-31 22:33:30,324 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:33:30,369 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:33:30,369 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:33:30,941 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:33:30,982 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:33:30,982 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:33:31,572 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:33:31,573 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:33:31,573 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  96%|#########6| 240/250 [06:03<00:16,  1.61s/it, loss=0.0689]Epoch 1/1 [Train]:  96%|#########6| 241/250 [06:03<00:14,  1.60s/it, loss=0.0689]2025-03-31 22:33:31,909 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:33:31,954 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:33:31,955 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:33:32,557 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:33:32,605 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:33:32,605 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:33:33,188 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:33:33,188 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:33:33,188 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  96%|#########6| 241/250 [06:05<00:14,  1.60s/it, loss=0.0959]Epoch 1/1 [Train]:  97%|#########6| 242/250 [06:05<00:12,  1.60s/it, loss=0.0959]2025-03-31 22:33:33,497 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:33:33,543 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:33:33,543 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:33:34,148 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:33:34,206 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:33:34,206 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:33:34,780 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:33:34,780 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:33:34,780 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  97%|#########6| 242/250 [06:06<00:12,  1.60s/it, loss=0.0431]Epoch 1/1 [Train]:  97%|#########7| 243/250 [06:06<00:11,  1.60s/it, loss=0.0431]2025-03-31 22:33:35,099 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:33:35,147 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:33:35,147 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:33:35,744 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:33:35,786 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:33:35,786 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:33:36,375 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:33:36,375 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:33:36,375 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  97%|#########7| 243/250 [06:08<00:11,  1.60s/it, loss=0.0715]Epoch 1/1 [Train]:  98%|#########7| 244/250 [06:08<00:09,  1.60s/it, loss=0.0715]2025-03-31 22:33:36,695 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:33:36,741 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:33:36,741 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:33:37,317 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:33:37,362 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:33:37,362 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:33:37,948 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:33:37,948 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:33:37,948 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  98%|#########7| 244/250 [06:09<00:09,  1.60s/it, loss=0.0618]Epoch 1/1 [Train]:  98%|#########8| 245/250 [06:09<00:07,  1.59s/it, loss=0.0618]2025-03-31 22:33:38,265 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:33:38,310 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:33:38,310 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:33:38,888 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:33:38,938 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:33:38,938 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:33:39,525 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:33:39,525 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:33:39,525 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  98%|#########8| 245/250 [06:11<00:07,  1.59s/it, loss=0.0561]Epoch 1/1 [Train]:  98%|#########8| 246/250 [06:11<00:06,  1.58s/it, loss=0.0561]2025-03-31 22:33:39,816 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:33:39,866 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:33:39,866 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:33:40,468 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:33:40,511 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:33:40,512 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:33:41,106 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:33:41,106 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:33:41,106 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  98%|#########8| 246/250 [06:12<00:06,  1.58s/it, loss=0.0575]Epoch 1/1 [Train]:  99%|#########8| 247/250 [06:12<00:04,  1.59s/it, loss=0.0575]2025-03-31 22:33:41,425 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:33:41,472 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:33:41,472 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:33:42,039 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:33:42,091 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:33:42,091 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:33:42,684 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:33:42,684 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:33:42,684 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  99%|#########8| 247/250 [06:14<00:04,  1.59s/it, loss=0.0628]Epoch 1/1 [Train]:  99%|#########9| 248/250 [06:14<00:03,  1.58s/it, loss=0.0628]2025-03-31 22:33:42,999 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:33:43,043 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:33:43,043 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:33:43,615 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:33:43,662 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:33:43,662 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:33:44,215 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:33:44,215 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:33:44,215 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  99%|#########9| 248/250 [06:16<00:03,  1.58s/it, loss=0.0669]Epoch 1/1 [Train]: 100%|#########9| 249/250 [06:16<00:01,  1.56s/it, loss=0.0669]2025-03-31 22:33:44,512 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:33:44,551 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:33:44,551 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:33:45,125 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:33:45,169 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:33:45,169 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:33:45,729 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:33:45,729 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:33:45,729 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]: 100%|#########9| 249/250 [06:17<00:01,  1.56s/it, loss=0.0584]Epoch 1/1 [Train]: 100%|##########| 250/250 [06:17<00:00,  1.55s/it, loss=0.0584]Epoch 1/1 [Train]: 100%|##########| 250/250 [06:17<00:00,  1.51s/it, loss=0.0584]
2025-03-31 22:33:45,966 - __main__ - INFO - Epoch 1/1 - Train Loss: 0.089623
Epoch 1/1 [Val]:   0%|          | 0/100 [00:00<?, ?it/s]2025-03-31 22:33:46,062 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:33:46,106 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:33:46,106 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:33:46,719 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:33:46,763 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:33:46,763 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:33:47,365 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:33:47,366 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:33:47,366 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:   0%|          | 0/100 [00:01<?, ?it/s, loss=0.0444]Epoch 1/1 [Val]:   1%|1         | 1/100 [00:01<02:40,  1.62s/it, loss=0.0444]2025-03-31 22:33:47,666 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:33:47,707 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:33:47,707 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:33:48,326 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:33:48,374 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:33:48,374 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:33:48,927 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:33:48,927 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:33:48,928 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:   1%|1         | 1/100 [00:03<02:40,  1.62s/it, loss=0.0635]Epoch 1/1 [Val]:   2%|2         | 2/100 [00:03<02:34,  1.58s/it, loss=0.0635]2025-03-31 22:33:49,264 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:33:49,323 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:33:49,323 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:33:49,931 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:33:49,977 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:33:49,977 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:33:50,552 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:33:50,553 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:33:50,553 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:   2%|2         | 2/100 [00:04<02:34,  1.58s/it, loss=0.0489]Epoch 1/1 [Val]:   3%|3         | 3/100 [00:04<02:35,  1.60s/it, loss=0.0489]2025-03-31 22:33:50,874 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:33:50,918 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:33:50,919 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:33:51,505 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:33:51,549 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:33:51,549 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:33:52,121 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:33:52,121 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:33:52,121 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:   3%|3         | 3/100 [00:06<02:35,  1.60s/it, loss=0.0455]Epoch 1/1 [Val]:   4%|4         | 4/100 [00:06<02:32,  1.59s/it, loss=0.0455]2025-03-31 22:33:52,427 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:33:52,469 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:33:52,470 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:33:53,047 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:33:53,094 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:33:53,094 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:33:53,691 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:33:53,692 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:33:53,692 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:   4%|4         | 4/100 [00:07<02:32,  1.59s/it, loss=0.0479]Epoch 1/1 [Val]:   5%|5         | 5/100 [00:07<02:30,  1.58s/it, loss=0.0479]2025-03-31 22:33:54,020 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:33:54,090 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:33:54,090 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:33:54,676 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:33:54,778 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:33:54,778 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:33:55,317 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:33:55,317 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:33:55,317 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:   5%|5         | 5/100 [00:10<02:30,  1.58s/it, loss=0.0634]Epoch 1/1 [Val]:   6%|6         | 6/100 [00:10<02:46,  1.77s/it, loss=0.0634]2025-03-31 22:33:56,643 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:33:56,729 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:33:56,729 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:33:57,250 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:33:57,306 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:33:57,306 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:33:57,878 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:33:57,878 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:33:57,879 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:   6%|6         | 6/100 [00:12<02:46,  1.77s/it, loss=0.0657]Epoch 1/1 [Val]:   7%|7         | 7/100 [00:12<02:53,  1.86s/it, loss=0.0657]2025-03-31 22:33:58,215 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:33:58,265 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:33:58,266 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:33:58,854 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:33:58,914 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:33:58,914 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:33:59,486 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:33:59,486 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:33:59,486 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:   7%|7         | 7/100 [00:13<02:53,  1.86s/it, loss=0.0514]Epoch 1/1 [Val]:   8%|8         | 8/100 [00:13<02:43,  1.78s/it, loss=0.0514]2025-03-31 22:33:59,850 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:33:59,913 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:33:59,913 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:34:00,496 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:34:00,550 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:34:00,550 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:34:01,126 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:34:01,126 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:34:01,126 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:   8%|8         | 8/100 [00:15<02:43,  1.78s/it, loss=0.0484]Epoch 1/1 [Val]:   9%|9         | 9/100 [00:15<02:38,  1.74s/it, loss=0.0484]2025-03-31 22:34:01,444 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:34:01,494 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:34:01,494 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:34:02,076 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:34:02,137 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:34:02,137 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:34:02,721 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:34:02,721 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:34:02,721 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:   9%|9         | 9/100 [00:16<02:38,  1.74s/it, loss=0.0295]Epoch 1/1 [Val]:  10%|#         | 10/100 [00:16<02:32,  1.69s/it, loss=0.0295]2025-03-31 22:34:03,037 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:34:03,081 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:34:03,081 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:34:03,698 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:34:03,745 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:34:03,746 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:34:04,298 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:34:04,299 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:34:04,299 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  10%|#         | 10/100 [00:18<02:32,  1.69s/it, loss=0.0326]Epoch 1/1 [Val]:  11%|#1        | 11/100 [00:18<02:27,  1.66s/it, loss=0.0326]2025-03-31 22:34:04,608 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:34:04,663 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:34:04,663 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:34:05,274 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:34:05,327 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:34:05,327 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:34:05,922 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:34:05,923 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:34:05,923 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  11%|#1        | 11/100 [00:20<02:27,  1.66s/it, loss=0.0773]Epoch 1/1 [Val]:  12%|#2        | 12/100 [00:20<02:25,  1.65s/it, loss=0.0773]2025-03-31 22:34:06,431 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:34:06,488 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:34:06,489 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:34:07,075 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:34:07,138 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:34:07,139 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:34:07,719 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:34:07,719 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:34:07,719 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  12%|#2        | 12/100 [00:21<02:25,  1.65s/it, loss=0.0381]Epoch 1/1 [Val]:  13%|#3        | 13/100 [00:21<02:27,  1.69s/it, loss=0.0381]2025-03-31 22:34:08,039 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:34:08,088 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:34:08,088 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:34:08,688 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:34:08,732 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:34:08,732 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:34:09,333 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:34:09,333 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:34:09,333 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  13%|#3        | 13/100 [00:23<02:27,  1.69s/it, loss=0.0423]Epoch 1/1 [Val]:  14%|#4        | 14/100 [00:23<02:23,  1.67s/it, loss=0.0423]2025-03-31 22:34:09,676 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:34:09,724 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:34:09,724 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:34:10,296 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:34:10,345 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:34:10,345 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:34:10,947 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:34:10,947 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:34:10,947 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  14%|#4        | 14/100 [00:25<02:23,  1.67s/it, loss=0.0407]Epoch 1/1 [Val]:  15%|#5        | 15/100 [00:25<02:20,  1.65s/it, loss=0.0407]2025-03-31 22:34:11,287 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:34:11,345 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:34:11,345 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:34:11,930 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:34:11,977 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:34:11,977 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:34:12,580 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:34:12,581 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:34:12,581 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  15%|#5        | 15/100 [00:26<02:20,  1.65s/it, loss=0.0574]Epoch 1/1 [Val]:  16%|#6        | 16/100 [00:26<02:18,  1.65s/it, loss=0.0574]2025-03-31 22:34:12,912 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:34:12,962 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:34:12,963 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:34:13,544 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:34:13,593 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:34:13,593 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:34:14,164 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:34:14,165 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:34:14,165 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  16%|#6        | 16/100 [00:28<02:18,  1.65s/it, loss=0.0559]Epoch 1/1 [Val]:  17%|#7        | 17/100 [00:28<02:15,  1.63s/it, loss=0.0559]2025-03-31 22:34:14,515 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:34:14,576 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:34:14,576 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:34:15,155 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:34:15,210 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:34:15,210 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:34:15,807 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:34:15,808 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:34:15,808 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  17%|#7        | 17/100 [00:30<02:15,  1.63s/it, loss=0.052] Epoch 1/1 [Val]:  18%|#8        | 18/100 [00:30<02:13,  1.63s/it, loss=0.052]2025-03-31 22:34:16,142 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:34:16,200 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:34:16,200 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:34:16,777 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:34:16,826 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:34:16,826 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:34:17,428 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:34:17,428 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:34:17,428 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  18%|#8        | 18/100 [00:32<02:13,  1.63s/it, loss=0.0383]Epoch 1/1 [Val]:  19%|#9        | 19/100 [00:32<02:29,  1.85s/it, loss=0.0383]2025-03-31 22:34:19,981 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:34:20,043 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:34:20,044 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:34:20,570 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:34:20,632 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:34:20,633 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:34:21,211 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:34:21,211 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:34:21,211 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  19%|#9        | 19/100 [00:35<02:29,  1.85s/it, loss=0.0444]Epoch 1/1 [Val]:  20%|##        | 20/100 [00:35<02:56,  2.21s/it, loss=0.0444]2025-03-31 22:34:21,533 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:34:21,584 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:34:21,585 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:34:22,247 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:34:22,336 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:34:22,337 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:34:22,899 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:34:22,900 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:34:22,900 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  20%|##        | 20/100 [00:37<02:56,  2.21s/it, loss=0.0636]Epoch 1/1 [Val]:  21%|##1       | 21/100 [00:37<02:46,  2.11s/it, loss=0.0636]2025-03-31 22:34:23,778 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:34:23,871 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:34:23,871 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:34:24,381 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:34:24,458 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:34:24,458 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:34:25,036 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:34:25,037 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:34:25,037 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  21%|##1       | 21/100 [00:39<02:46,  2.11s/it, loss=0.0622]Epoch 1/1 [Val]:  22%|##2       | 22/100 [00:39<02:40,  2.06s/it, loss=0.0622]2025-03-31 22:34:25,398 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:34:25,454 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:34:25,454 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:34:26,065 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:34:26,111 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:34:26,111 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:34:26,721 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:34:26,721 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:34:26,721 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  22%|##2       | 22/100 [00:40<02:40,  2.06s/it, loss=0.0355]Epoch 1/1 [Val]:  23%|##3       | 23/100 [00:40<02:30,  1.95s/it, loss=0.0355]2025-03-31 22:34:27,098 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:34:27,158 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:34:27,159 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:34:27,732 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:34:27,774 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:34:27,775 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:34:28,351 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:34:28,351 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:34:28,351 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  23%|##3       | 23/100 [00:42<02:30,  1.95s/it, loss=0.035] Epoch 1/1 [Val]:  24%|##4       | 24/100 [00:42<02:20,  1.85s/it, loss=0.035]2025-03-31 22:34:28,691 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:34:28,754 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:34:28,754 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:34:29,327 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:34:29,374 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:34:29,374 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:34:29,947 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:34:29,947 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:34:29,947 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  24%|##4       | 24/100 [00:44<02:20,  1.85s/it, loss=0.045]Epoch 1/1 [Val]:  25%|##5       | 25/100 [00:44<02:13,  1.78s/it, loss=0.045]2025-03-31 22:34:30,275 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:34:30,327 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:34:30,327 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:34:30,922 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:34:30,974 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:34:30,974 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:34:31,547 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:34:31,548 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:34:31,548 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  25%|##5       | 25/100 [00:45<02:13,  1.78s/it, loss=0.0441]Epoch 1/1 [Val]:  26%|##6       | 26/100 [00:45<02:07,  1.72s/it, loss=0.0441]2025-03-31 22:34:31,893 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:34:31,942 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:34:31,942 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:34:32,557 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:34:32,601 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:34:32,601 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:34:33,211 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:34:33,211 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:34:33,212 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  26%|##6       | 26/100 [00:47<02:07,  1.72s/it, loss=0.0464]Epoch 1/1 [Val]:  27%|##7       | 27/100 [00:47<02:04,  1.71s/it, loss=0.0464]2025-03-31 22:34:33,551 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:34:33,604 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:34:33,604 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:34:34,218 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:34:34,282 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:34:34,282 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:34:34,871 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:34:34,871 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:34:34,871 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  27%|##7       | 27/100 [00:49<02:04,  1.71s/it, loss=0.0535]Epoch 1/1 [Val]:  28%|##8       | 28/100 [00:49<02:01,  1.69s/it, loss=0.0535]2025-03-31 22:34:35,175 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:34:35,217 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:34:35,218 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:34:35,850 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:34:35,918 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:34:35,918 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:34:36,503 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:34:36,503 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:34:36,504 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  28%|##8       | 28/100 [00:50<02:01,  1.69s/it, loss=0.101] Epoch 1/1 [Val]:  29%|##9       | 29/100 [00:50<01:58,  1.67s/it, loss=0.101]2025-03-31 22:34:36,833 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:34:36,888 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:34:36,888 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:34:37,417 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:34:37,470 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:34:37,470 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:34:38,067 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:34:38,068 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:34:38,068 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  29%|##9       | 29/100 [00:52<01:58,  1.67s/it, loss=0.0535]Epoch 1/1 [Val]:  30%|###       | 30/100 [00:52<01:54,  1.64s/it, loss=0.0535]2025-03-31 22:34:38,428 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:34:38,484 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:34:38,485 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:34:39,096 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:34:39,150 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:34:39,150 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:34:39,750 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:34:39,750 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:34:39,750 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  30%|###       | 30/100 [00:54<01:54,  1.64s/it, loss=0.0669]Epoch 1/1 [Val]:  31%|###1      | 31/100 [00:54<01:54,  1.65s/it, loss=0.0669]2025-03-31 22:34:40,090 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:34:40,145 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:34:40,146 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:34:40,759 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:34:40,814 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:34:40,814 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:34:41,413 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:34:41,413 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:34:41,413 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  31%|###1      | 31/100 [00:55<01:54,  1.65s/it, loss=0.0446]Epoch 1/1 [Val]:  32%|###2      | 32/100 [00:55<01:52,  1.66s/it, loss=0.0446]2025-03-31 22:34:41,730 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:34:41,776 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:34:41,777 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:34:42,373 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:34:42,418 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:34:42,418 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:34:43,011 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:34:43,012 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:34:43,012 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  32%|###2      | 32/100 [00:57<01:52,  1.66s/it, loss=0.0522]Epoch 1/1 [Val]:  33%|###3      | 33/100 [00:57<01:49,  1.64s/it, loss=0.0522]2025-03-31 22:34:43,358 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:34:43,400 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:34:43,400 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:34:44,013 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:34:44,062 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:34:44,062 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:34:44,653 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:34:44,653 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:34:44,653 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  33%|###3      | 33/100 [00:58<01:49,  1.64s/it, loss=0.0682]Epoch 1/1 [Val]:  34%|###4      | 34/100 [00:58<01:48,  1.64s/it, loss=0.0682]2025-03-31 22:34:45,002 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:34:45,053 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:34:45,053 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:34:45,675 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:34:45,733 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:34:45,733 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:34:46,328 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:34:46,329 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:34:46,329 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  34%|###4      | 34/100 [01:00<01:48,  1.64s/it, loss=0.0683]Epoch 1/1 [Val]:  35%|###5      | 35/100 [01:00<01:47,  1.65s/it, loss=0.0683]2025-03-31 22:34:46,639 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:34:46,683 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:34:46,683 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:34:47,305 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:34:47,347 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:34:47,347 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:34:47,928 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:34:47,929 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:34:47,929 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  35%|###5      | 35/100 [01:02<01:47,  1.65s/it, loss=0.0635]Epoch 1/1 [Val]:  36%|###6      | 36/100 [01:02<01:44,  1.64s/it, loss=0.0635]2025-03-31 22:34:48,281 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:34:48,335 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:34:48,335 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:34:48,951 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:34:48,997 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:34:48,998 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:34:49,605 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:34:49,605 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:34:49,605 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  36%|###6      | 36/100 [01:03<01:44,  1.64s/it, loss=0.0592]Epoch 1/1 [Val]:  37%|###7      | 37/100 [01:03<01:43,  1.65s/it, loss=0.0592]2025-03-31 22:34:49,926 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:34:49,989 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:34:49,989 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:34:50,572 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:34:50,623 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:34:50,623 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:34:51,206 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:34:51,206 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:34:51,207 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  37%|###7      | 37/100 [01:05<01:43,  1.65s/it, loss=0.0545]Epoch 1/1 [Val]:  38%|###8      | 38/100 [01:05<01:41,  1.63s/it, loss=0.0545]2025-03-31 22:34:51,544 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:34:51,594 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:34:51,594 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:34:52,210 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:34:52,256 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:34:52,257 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:34:52,866 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:34:52,866 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:34:52,866 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  38%|###8      | 38/100 [01:07<01:41,  1.63s/it, loss=0.0448]Epoch 1/1 [Val]:  39%|###9      | 39/100 [01:07<01:40,  1.64s/it, loss=0.0448]2025-03-31 22:34:53,182 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:34:53,229 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:34:53,230 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:34:53,850 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:34:53,893 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:34:53,894 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:34:54,490 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:34:54,490 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:34:54,490 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  39%|###9      | 39/100 [01:08<01:40,  1.64s/it, loss=0.101] Epoch 1/1 [Val]:  40%|####      | 40/100 [01:08<01:38,  1.64s/it, loss=0.101]2025-03-31 22:34:54,804 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:34:54,856 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:34:54,856 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:34:55,458 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:34:55,510 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:34:55,511 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:34:56,097 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:34:56,097 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:34:56,097 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  40%|####      | 40/100 [01:10<01:38,  1.64s/it, loss=0.0727]Epoch 1/1 [Val]:  41%|####1     | 41/100 [01:10<01:35,  1.63s/it, loss=0.0727]2025-03-31 22:34:56,399 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:34:56,444 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:34:56,445 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:34:57,053 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:34:57,096 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:34:57,096 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:34:57,690 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:34:57,690 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:34:57,691 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  41%|####1     | 41/100 [01:11<01:35,  1.63s/it, loss=0.039] Epoch 1/1 [Val]:  42%|####2     | 42/100 [01:11<01:33,  1.62s/it, loss=0.039]2025-03-31 22:34:58,034 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:34:58,092 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:34:58,092 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:34:58,661 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:34:58,710 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:34:58,710 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:34:59,294 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:34:59,294 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:34:59,294 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  42%|####2     | 42/100 [01:13<01:33,  1.62s/it, loss=0.0602]Epoch 1/1 [Val]:  43%|####3     | 43/100 [01:13<01:31,  1.61s/it, loss=0.0602]2025-03-31 22:34:59,617 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:34:59,671 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:34:59,671 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:35:00,256 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:35:00,316 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:35:00,316 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:35:00,869 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:35:00,869 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:35:00,869 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  43%|####3     | 43/100 [01:15<01:31,  1.61s/it, loss=0.053] Epoch 1/1 [Val]:  44%|####4     | 44/100 [01:15<01:29,  1.60s/it, loss=0.053]2025-03-31 22:35:01,187 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:35:01,232 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:35:01,232 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:35:01,808 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:35:01,853 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:35:01,854 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:35:02,466 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:35:02,466 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:35:02,466 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  44%|####4     | 44/100 [01:16<01:29,  1.60s/it, loss=0.0649]Epoch 1/1 [Val]:  45%|####5     | 45/100 [01:16<01:28,  1.60s/it, loss=0.0649]2025-03-31 22:35:02,789 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:35:02,837 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:35:02,837 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:35:03,459 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:35:03,504 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:35:03,504 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:35:04,114 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:35:04,114 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:35:04,114 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  45%|####5     | 45/100 [01:18<01:28,  1.60s/it, loss=0.0621]Epoch 1/1 [Val]:  46%|####6     | 46/100 [01:18<01:27,  1.61s/it, loss=0.0621]2025-03-31 22:35:04,425 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:35:04,466 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:35:04,467 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:35:05,092 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:35:05,137 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:35:05,137 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:35:05,748 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:35:05,748 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:35:05,748 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  46%|####6     | 46/100 [01:20<01:27,  1.61s/it, loss=0.0605]Epoch 1/1 [Val]:  47%|####6     | 47/100 [01:20<01:25,  1.62s/it, loss=0.0605]2025-03-31 22:35:06,063 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:35:06,121 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:35:06,121 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:35:06,731 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:35:06,772 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:35:06,772 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:35:07,387 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:35:07,388 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:35:07,388 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  47%|####6     | 47/100 [01:21<01:25,  1.62s/it, loss=0.0472]Epoch 1/1 [Val]:  48%|####8     | 48/100 [01:21<01:24,  1.63s/it, loss=0.0472]2025-03-31 22:35:07,712 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:35:07,761 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:35:07,761 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:35:08,379 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:35:08,425 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:35:08,425 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:35:09,032 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:35:09,032 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:35:09,033 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  48%|####8     | 48/100 [01:23<01:24,  1.63s/it, loss=0.061] Epoch 1/1 [Val]:  49%|####9     | 49/100 [01:23<01:23,  1.63s/it, loss=0.061]2025-03-31 22:35:09,371 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:35:09,425 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:35:09,425 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:35:10,040 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:35:10,090 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:35:10,090 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:35:10,692 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:35:10,692 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:35:10,692 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  49%|####9     | 49/100 [01:24<01:23,  1.63s/it, loss=0.0486]Epoch 1/1 [Val]:  50%|#####     | 50/100 [01:24<01:21,  1.64s/it, loss=0.0486]2025-03-31 22:35:10,998 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:35:11,046 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:35:11,046 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:35:11,669 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:35:11,728 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:35:11,728 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:35:12,279 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:35:12,279 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:35:12,279 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  50%|#####     | 50/100 [01:26<01:21,  1.64s/it, loss=0.0429]Epoch 1/1 [Val]:  51%|#####1    | 51/100 [01:26<01:19,  1.62s/it, loss=0.0429]2025-03-31 22:35:12,607 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:35:12,662 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:35:12,662 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:35:13,282 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:35:13,342 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:35:13,342 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:35:13,939 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:35:13,939 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:35:13,939 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  51%|#####1    | 51/100 [01:28<01:19,  1.62s/it, loss=0.0412]Epoch 1/1 [Val]:  52%|#####2    | 52/100 [01:28<01:18,  1.64s/it, loss=0.0412]2025-03-31 22:35:14,710 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:35:14,768 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:35:14,768 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:35:15,330 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:35:15,385 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:35:15,385 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:35:15,983 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:35:15,983 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:35:15,983 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  52%|#####2    | 52/100 [01:30<01:18,  1.64s/it, loss=0.0862]Epoch 1/1 [Val]:  53%|#####3    | 53/100 [01:30<01:22,  1.76s/it, loss=0.0862]2025-03-31 22:35:16,299 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:35:16,354 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:35:16,354 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:35:16,967 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:35:17,013 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:35:17,013 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:35:17,621 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:35:17,621 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:35:17,621 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  53%|#####3    | 53/100 [01:31<01:22,  1.76s/it, loss=0.0677]Epoch 1/1 [Val]:  54%|#####4    | 54/100 [01:31<01:19,  1.72s/it, loss=0.0677]2025-03-31 22:35:17,937 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:35:17,982 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:35:17,982 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:35:18,607 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:35:18,654 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:35:18,655 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:35:19,261 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:35:19,262 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:35:19,262 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  54%|#####4    | 54/100 [01:33<01:19,  1.72s/it, loss=0.0506]Epoch 1/1 [Val]:  55%|#####5    | 55/100 [01:33<01:16,  1.70s/it, loss=0.0506]2025-03-31 22:35:19,645 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:35:19,710 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:35:19,710 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:35:20,287 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:35:20,338 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:35:20,338 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:35:20,906 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:35:20,906 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:35:20,906 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  55%|#####5    | 55/100 [01:35<01:16,  1.70s/it, loss=0.0486]Epoch 1/1 [Val]:  56%|#####6    | 56/100 [01:35<01:13,  1.68s/it, loss=0.0486]2025-03-31 22:35:21,269 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:35:21,330 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:35:21,330 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:35:21,885 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:35:21,942 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:35:21,942 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:35:22,541 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:35:22,541 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:35:22,541 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  56%|#####6    | 56/100 [01:36<01:13,  1.68s/it, loss=0.0765]Epoch 1/1 [Val]:  57%|#####6    | 57/100 [01:36<01:11,  1.67s/it, loss=0.0765]2025-03-31 22:35:22,867 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:35:22,919 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:35:22,919 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:35:23,535 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:35:23,584 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:35:23,585 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:35:24,188 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:35:24,188 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:35:24,188 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  57%|#####6    | 57/100 [01:38<01:11,  1.67s/it, loss=0.064] Epoch 1/1 [Val]:  58%|#####8    | 58/100 [01:38<01:09,  1.66s/it, loss=0.064]2025-03-31 22:35:24,549 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:35:24,615 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:35:24,615 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:35:25,219 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:35:25,280 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:35:25,280 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:35:25,872 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:35:25,872 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:35:25,873 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  58%|#####8    | 58/100 [01:40<01:09,  1.66s/it, loss=0.0435]Epoch 1/1 [Val]:  59%|#####8    | 59/100 [01:40<01:08,  1.67s/it, loss=0.0435]2025-03-31 22:35:26,204 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:35:26,261 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:35:26,261 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:35:26,875 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:35:26,925 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:35:26,925 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:35:27,529 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:35:27,529 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:35:27,529 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  59%|#####8    | 59/100 [01:41<01:08,  1.67s/it, loss=0.038] Epoch 1/1 [Val]:  60%|######    | 60/100 [01:41<01:06,  1.66s/it, loss=0.038]2025-03-31 22:35:27,867 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:35:27,920 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:35:27,920 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:35:28,502 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:35:28,555 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:35:28,555 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:35:29,118 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:35:29,119 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:35:29,119 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  60%|######    | 60/100 [01:43<01:06,  1.66s/it, loss=0.0606]Epoch 1/1 [Val]:  61%|######1   | 61/100 [01:43<01:03,  1.64s/it, loss=0.0606]2025-03-31 22:35:29,492 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:35:29,558 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:35:29,558 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:35:30,126 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:35:30,171 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:35:30,171 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:35:30,780 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:35:30,780 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:35:30,781 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  61%|######1   | 61/100 [01:45<01:03,  1.64s/it, loss=0.0346]Epoch 1/1 [Val]:  62%|######2   | 62/100 [01:45<01:02,  1.65s/it, loss=0.0346]2025-03-31 22:35:31,119 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:35:31,173 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:35:31,173 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:35:31,717 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:35:31,778 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:35:31,778 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:35:32,370 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:35:32,370 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:35:32,371 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  62%|######2   | 62/100 [01:46<01:02,  1.65s/it, loss=0.0469]Epoch 1/1 [Val]:  63%|######3   | 63/100 [01:46<01:00,  1.63s/it, loss=0.0469]2025-03-31 22:35:32,705 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:35:32,763 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:35:32,763 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:35:33,372 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:35:33,417 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:35:33,417 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:35:34,026 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:35:34,026 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:35:34,026 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  63%|######3   | 63/100 [01:48<01:00,  1.63s/it, loss=0.0509]Epoch 1/1 [Val]:  64%|######4   | 64/100 [01:48<00:58,  1.64s/it, loss=0.0509]2025-03-31 22:35:34,362 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:35:34,409 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:35:34,409 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:35:35,028 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:35:35,070 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:35:35,071 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:35:35,683 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:35:35,683 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:35:35,683 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  64%|######4   | 64/100 [01:49<00:58,  1.64s/it, loss=0.0384]Epoch 1/1 [Val]:  65%|######5   | 65/100 [01:49<00:57,  1.64s/it, loss=0.0384]2025-03-31 22:35:36,004 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:35:36,057 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:35:36,057 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:35:36,671 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:35:36,717 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:35:36,717 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:35:37,325 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:35:37,325 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:35:37,326 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  65%|######5   | 65/100 [01:51<00:57,  1.64s/it, loss=0.0766]Epoch 1/1 [Val]:  66%|######6   | 66/100 [01:51<00:55,  1.64s/it, loss=0.0766]2025-03-31 22:35:37,652 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:35:37,706 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:35:37,707 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:35:38,322 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:35:38,377 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:35:38,377 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:35:38,976 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:35:38,976 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:35:38,976 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  66%|######6   | 66/100 [01:53<00:55,  1.64s/it, loss=0.0417]Epoch 1/1 [Val]:  67%|######7   | 67/100 [01:53<00:54,  1.65s/it, loss=0.0417]2025-03-31 22:35:39,314 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:35:39,366 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:35:39,366 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:35:39,980 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:35:40,030 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:35:40,031 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:35:40,634 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:35:40,635 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:35:40,635 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  67%|######7   | 67/100 [01:54<00:54,  1.65s/it, loss=0.0317]Epoch 1/1 [Val]:  68%|######8   | 68/100 [01:54<00:52,  1.65s/it, loss=0.0317]2025-03-31 22:35:40,934 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:35:40,980 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:35:40,980 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:35:41,600 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:35:41,654 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:35:41,655 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:35:42,255 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:35:42,255 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:35:42,255 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  68%|######8   | 68/100 [01:56<00:52,  1.65s/it, loss=0.0609]Epoch 1/1 [Val]:  69%|######9   | 69/100 [01:56<00:50,  1.64s/it, loss=0.0609]2025-03-31 22:35:42,566 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:35:42,617 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:35:42,617 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:35:43,179 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:35:43,228 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:35:43,228 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:35:43,836 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:35:43,836 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:35:43,836 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  69%|######9   | 69/100 [01:58<00:50,  1.64s/it, loss=0.0368]Epoch 1/1 [Val]:  70%|#######   | 70/100 [01:58<00:48,  1.62s/it, loss=0.0368]2025-03-31 22:35:44,151 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:35:44,201 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:35:44,202 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:35:44,814 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:35:44,856 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:35:44,856 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:35:45,465 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:35:45,466 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:35:45,466 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  70%|#######   | 70/100 [01:59<00:48,  1.62s/it, loss=0.0472]Epoch 1/1 [Val]:  71%|#######1  | 71/100 [01:59<00:47,  1.62s/it, loss=0.0472]2025-03-31 22:35:45,801 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:35:45,860 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:35:45,860 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:35:46,466 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:35:46,513 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:35:46,513 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:35:47,118 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:35:47,118 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:35:47,118 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  71%|#######1  | 71/100 [02:01<00:47,  1.62s/it, loss=0.058] Epoch 1/1 [Val]:  72%|#######2  | 72/100 [02:01<00:45,  1.63s/it, loss=0.058]2025-03-31 22:35:47,429 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:35:47,475 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:35:47,475 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:35:48,095 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:35:48,148 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:35:48,149 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:35:48,749 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:35:48,750 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:35:48,750 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  72%|#######2  | 72/100 [02:03<00:45,  1.63s/it, loss=0.0364]Epoch 1/1 [Val]:  73%|#######3  | 73/100 [02:03<00:44,  1.63s/it, loss=0.0364]2025-03-31 22:35:49,055 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:35:49,101 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:35:49,101 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:35:49,719 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:35:49,766 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:35:49,766 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:35:50,374 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:35:50,374 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:35:50,374 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  73%|#######3  | 73/100 [02:04<00:44,  1.63s/it, loss=0.0706]Epoch 1/1 [Val]:  74%|#######4  | 74/100 [02:04<00:42,  1.63s/it, loss=0.0706]2025-03-31 22:35:50,681 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:35:50,726 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:35:50,726 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:35:51,344 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:35:51,384 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:35:51,384 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:35:51,998 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:35:51,998 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:35:51,998 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  74%|#######4  | 74/100 [02:06<00:42,  1.63s/it, loss=0.0531]Epoch 1/1 [Val]:  75%|#######5  | 75/100 [02:06<00:40,  1.63s/it, loss=0.0531]2025-03-31 22:35:52,308 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:35:52,354 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:35:52,354 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:35:52,973 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:35:53,013 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:35:53,014 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:35:53,627 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:35:53,627 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:35:53,627 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  75%|#######5  | 75/100 [02:07<00:40,  1.63s/it, loss=0.033] Epoch 1/1 [Val]:  76%|#######6  | 76/100 [02:07<00:39,  1.63s/it, loss=0.033]2025-03-31 22:35:53,938 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:35:53,986 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:35:53,986 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:35:54,603 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:35:54,648 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:35:54,649 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:35:55,256 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:35:55,256 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:35:55,256 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  76%|#######6  | 76/100 [02:09<00:39,  1.63s/it, loss=0.0336]Epoch 1/1 [Val]:  77%|#######7  | 77/100 [02:09<00:37,  1.63s/it, loss=0.0336]2025-03-31 22:35:55,555 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:35:55,598 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:35:55,598 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:35:56,223 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:35:56,271 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:35:56,271 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:35:56,877 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:35:56,877 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:35:56,877 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  77%|#######7  | 77/100 [02:11<00:37,  1.63s/it, loss=0.0467]Epoch 1/1 [Val]:  78%|#######8  | 78/100 [02:11<00:35,  1.63s/it, loss=0.0467]2025-03-31 22:35:57,177 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:35:57,219 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:35:57,219 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:35:57,806 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:35:57,854 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:35:57,854 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:35:58,421 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:35:58,421 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:35:58,421 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  78%|#######8  | 78/100 [02:12<00:35,  1.63s/it, loss=0.0954]Epoch 1/1 [Val]:  79%|#######9  | 79/100 [02:12<00:33,  1.60s/it, loss=0.0954]2025-03-31 22:35:58,717 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:35:58,759 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:35:58,759 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:35:59,371 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:35:59,419 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:35:59,419 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:36:00,011 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:36:00,012 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:36:00,012 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  79%|#######9  | 79/100 [02:14<00:33,  1.60s/it, loss=0.0599]Epoch 1/1 [Val]:  80%|########  | 80/100 [02:14<00:31,  1.60s/it, loss=0.0599]2025-03-31 22:36:00,336 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:36:00,383 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:36:00,384 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:36:00,989 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:36:01,033 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:36:01,033 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:36:01,629 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:36:01,629 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:36:01,629 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  80%|########  | 80/100 [02:15<00:31,  1.60s/it, loss=0.0485]Epoch 1/1 [Val]:  81%|########1 | 81/100 [02:15<00:30,  1.60s/it, loss=0.0485]2025-03-31 22:36:01,947 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:36:02,003 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:36:02,003 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:36:02,600 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:36:02,647 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:36:02,647 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:36:03,241 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:36:03,241 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:36:03,241 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  81%|########1 | 81/100 [02:17<00:30,  1.60s/it, loss=0.055] Epoch 1/1 [Val]:  82%|########2 | 82/100 [02:17<00:28,  1.61s/it, loss=0.055]2025-03-31 22:36:03,537 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:36:03,582 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:36:03,582 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:36:04,189 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:36:04,235 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:36:04,235 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:36:04,830 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:36:04,831 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:36:04,831 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  82%|########2 | 82/100 [02:19<00:28,  1.61s/it, loss=0.0432]Epoch 1/1 [Val]:  83%|########2 | 83/100 [02:19<00:27,  1.60s/it, loss=0.0432]2025-03-31 22:36:05,141 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:36:05,187 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:36:05,187 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:36:05,773 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:36:05,816 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:36:05,816 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:36:06,427 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:36:06,427 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:36:06,427 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  83%|########2 | 83/100 [02:20<00:27,  1.60s/it, loss=0.0685]Epoch 1/1 [Val]:  84%|########4 | 84/100 [02:20<00:25,  1.60s/it, loss=0.0685]2025-03-31 22:36:06,766 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:36:06,825 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:36:06,825 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:36:07,402 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:36:07,451 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:36:07,452 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:36:08,018 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:36:08,019 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:36:08,019 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  84%|########4 | 84/100 [02:22<00:25,  1.60s/it, loss=0.067] Epoch 1/1 [Val]:  85%|########5 | 85/100 [02:22<00:23,  1.60s/it, loss=0.067]2025-03-31 22:36:08,325 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:36:08,369 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:36:08,369 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:36:08,961 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:36:09,019 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:36:09,019 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:36:09,576 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:36:09,577 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:36:09,577 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  85%|########5 | 85/100 [02:23<00:23,  1.60s/it, loss=0.0616]Epoch 1/1 [Val]:  86%|########6 | 86/100 [02:23<00:22,  1.58s/it, loss=0.0616]2025-03-31 22:36:09,880 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:36:09,926 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:36:09,926 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:36:10,534 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:36:10,577 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:36:10,577 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:36:11,190 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:36:11,190 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:36:11,190 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  86%|########6 | 86/100 [02:25<00:22,  1.58s/it, loss=0.0676]Epoch 1/1 [Val]:  87%|########7 | 87/100 [02:25<00:20,  1.60s/it, loss=0.0676]2025-03-31 22:36:11,591 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:36:11,650 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:36:11,650 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:36:12,254 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:36:12,303 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:36:12,303 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:36:12,898 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:36:12,898 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:36:12,898 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  87%|########7 | 87/100 [02:27<00:20,  1.60s/it, loss=0.0535]Epoch 1/1 [Val]:  88%|########8 | 88/100 [02:27<00:19,  1.63s/it, loss=0.0535]2025-03-31 22:36:13,217 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:36:13,269 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:36:13,270 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:36:13,878 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:36:13,925 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:36:13,925 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:36:14,521 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:36:14,522 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:36:14,522 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  88%|########8 | 88/100 [02:28<00:19,  1.63s/it, loss=0.0563]Epoch 1/1 [Val]:  89%|########9 | 89/100 [02:28<00:17,  1.63s/it, loss=0.0563]2025-03-31 22:36:14,907 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:36:14,957 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:36:14,957 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:36:15,569 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:36:15,619 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:36:15,620 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:36:16,184 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:36:16,184 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:36:16,184 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  89%|########9 | 89/100 [02:30<00:17,  1.63s/it, loss=0.0398]Epoch 1/1 [Val]:  90%|######### | 90/100 [02:30<00:16,  1.64s/it, loss=0.0398]2025-03-31 22:36:16,516 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:36:16,567 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:36:16,567 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:36:17,182 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:36:17,228 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:36:17,229 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:36:17,832 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:36:17,833 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:36:17,833 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  90%|######### | 90/100 [02:32<00:16,  1.64s/it, loss=0.0509]Epoch 1/1 [Val]:  91%|#########1| 91/100 [02:32<00:14,  1.64s/it, loss=0.0509]2025-03-31 22:36:18,175 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:36:18,227 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:36:18,227 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:36:18,844 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:36:18,894 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:36:18,895 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:36:19,461 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:36:19,461 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:36:19,461 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  91%|#########1| 91/100 [02:33<00:14,  1.64s/it, loss=0.0495]Epoch 1/1 [Val]:  92%|#########2| 92/100 [02:33<00:13,  1.64s/it, loss=0.0495]2025-03-31 22:36:19,779 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:36:19,825 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:36:19,825 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:36:20,443 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:36:20,495 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:36:20,495 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:36:21,097 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:36:21,098 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:36:21,098 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  92%|#########2| 92/100 [02:35<00:13,  1.64s/it, loss=0.0452]Epoch 1/1 [Val]:  93%|#########3| 93/100 [02:35<00:11,  1.64s/it, loss=0.0452]2025-03-31 22:36:21,412 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:36:21,465 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:36:21,465 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:36:22,078 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:36:22,126 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:36:22,126 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:36:22,731 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:36:22,731 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:36:22,731 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  93%|#########3| 93/100 [02:36<00:11,  1.64s/it, loss=0.0487]Epoch 1/1 [Val]:  94%|#########3| 94/100 [02:36<00:09,  1.64s/it, loss=0.0487]2025-03-31 22:36:23,046 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:36:23,103 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:36:23,103 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:36:23,710 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:36:23,758 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:36:23,758 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:36:24,364 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:36:24,364 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:36:24,364 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  94%|#########3| 94/100 [02:38<00:09,  1.64s/it, loss=0.057] Epoch 1/1 [Val]:  95%|#########5| 95/100 [02:38<00:08,  1.63s/it, loss=0.057]2025-03-31 22:36:24,674 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:36:24,722 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:36:24,722 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:36:25,340 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:36:25,390 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:36:25,390 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:36:25,992 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:36:25,992 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:36:25,992 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  95%|#########5| 95/100 [02:40<00:08,  1.63s/it, loss=0.0495]Epoch 1/1 [Val]:  96%|#########6| 96/100 [02:40<00:06,  1.63s/it, loss=0.0495]2025-03-31 22:36:26,317 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:36:26,364 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:36:26,364 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:36:26,981 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:36:27,027 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:36:27,027 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:36:27,634 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:36:27,634 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:36:27,634 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  96%|#########6| 96/100 [02:41<00:06,  1.63s/it, loss=0.0706]Epoch 1/1 [Val]:  97%|#########7| 97/100 [02:41<00:04,  1.64s/it, loss=0.0706]2025-03-31 22:36:27,965 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:36:28,025 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:36:28,025 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:36:28,635 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:36:28,682 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:36:28,682 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:36:29,287 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:36:29,287 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:36:29,287 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  97%|#########7| 97/100 [02:43<00:04,  1.64s/it, loss=0.0459]Epoch 1/1 [Val]:  98%|#########8| 98/100 [02:43<00:03,  1.64s/it, loss=0.0459]2025-03-31 22:36:29,603 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:36:29,652 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:36:29,652 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:36:30,278 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:36:30,333 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:36:30,333 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:36:30,929 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:36:30,929 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:36:30,929 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  98%|#########8| 98/100 [02:45<00:03,  1.64s/it, loss=0.054] Epoch 1/1 [Val]:  99%|#########9| 99/100 [02:45<00:01,  1.64s/it, loss=0.054]2025-03-31 22:36:31,237 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-31 22:36:31,284 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-31 22:36:31,284 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-31 22:36:31,906 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-31 22:36:31,964 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-31 22:36:31,965 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-31 22:36:32,560 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-31 22:36:32,560 - __main__ - INFO - Using num_sources = 2
2025-03-31 22:36:32,560 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  99%|#########9| 99/100 [02:46<00:01,  1.64s/it, loss=0.0492]Epoch 1/1 [Val]: 100%|##########| 100/100 [02:46<00:00,  1.64s/it, loss=0.0492]Epoch 1/1 [Val]: 100%|##########| 100/100 [02:46<00:00,  1.67s/it, loss=0.0492]
2025-03-31 22:36:32,788 - __main__ - INFO - Epoch 1/1 - Val Loss: 0.053736
2025-03-31 22:36:33,320 - __main__ - INFO - Saved best model with val_loss: 0.053736
2025-03-31 22:36:34,906 - __main__ - INFO - Model training complete. Best model saved to models/combined_pipeline/best_model.pt
