2025-03-30 22:50:46,343 - utils - INFO - Using device: cuda
2025-03-30 22:50:46,716 - speechbrain.utils.quirks - INFO - Applied quirks (see `speechbrain.utils.quirks`): [allow_tf32, disable_jit_profiling]
2025-03-30 22:50:46,716 - speechbrain.utils.quirks - INFO - Excluded quirks specified by the `SB_DISABLE_QUIRKS` environment (comma-separated list): []
C:\Users\SQREAM\Desktop\semester_six\speech_understanding_assignment_02\src\speech_enhancement\sepformer.py:12: UserWarning: Module 'speechbrain.pretrained' was deprecated, redirecting to 'speechbrain.inference'. Please update your script. This is a change from SpeechBrain 1.0. See: https://github.com/speechbrain/speechbrain/releases/tag/v1.0.0
  from speechbrain.pretrained import SepformerSeparation
2025-03-30 22:50:50,302 - speaker_verification.pretrained_eval - INFO - Initial pretrained_eval device setting: cuda
2025-03-30 22:50:50,991 - speaker_verification.finetune - INFO - Using device: cuda
2025-03-30 22:50:50,993 - __main__ - INFO - PESQ module is available for evaluation
2025-03-30 22:50:50,994 - speaker_verification.pretrained_eval - INFO - Using device for model loading: cuda
2025-03-30 22:50:50,994 - speaker_verification.pretrained_eval - INFO - CUDA is available. Device count: 1
2025-03-30 22:50:50,994 - speaker_verification.pretrained_eval - INFO - Loading pretrained model: microsoft/wavlm-base-plus
2025-03-30 22:50:53,426 - speaker_verification.pretrained_eval - INFO - Model moved to cuda
2025-03-30 22:50:53,427 - __main__ - INFO - Loading speaker model weights from models/speaker_verification/wavlm_ft/best_model.pt
2025-03-30 22:50:53,835 - __main__ - INFO - Direct loading failed, attempting to load with LoRA...
2025-03-30 22:50:53,957 - speaker_verification.finetune - INFO - Explicitly initialized base_model.model.backbone.encoder.layers.0.attention.k_proj.lora_B.default.weight with random values
2025-03-30 22:50:53,957 - speaker_verification.finetune - INFO - Explicitly initialized base_model.model.backbone.encoder.layers.0.attention.v_proj.lora_B.default.weight with random values
2025-03-30 22:50:53,957 - speaker_verification.finetune - INFO - Explicitly initialized base_model.model.backbone.encoder.layers.0.attention.q_proj.lora_B.default.weight with random values
2025-03-30 22:50:53,958 - speaker_verification.finetune - INFO - Explicitly initialized base_model.model.backbone.encoder.layers.0.attention.out_proj.lora_B.default.weight with random values
2025-03-30 22:50:53,958 - speaker_verification.finetune - INFO - Explicitly initialized base_model.model.backbone.encoder.layers.1.attention.k_proj.lora_B.default.weight with random values
2025-03-30 22:50:53,958 - speaker_verification.finetune - INFO - Explicitly initialized base_model.model.backbone.encoder.layers.1.attention.v_proj.lora_B.default.weight with random values
2025-03-30 22:50:53,958 - speaker_verification.finetune - INFO - Explicitly initialized base_model.model.backbone.encoder.layers.1.attention.q_proj.lora_B.default.weight with random values
2025-03-30 22:50:53,958 - speaker_verification.finetune - INFO - Explicitly initialized base_model.model.backbone.encoder.layers.1.attention.out_proj.lora_B.default.weight with random values
2025-03-30 22:50:53,958 - speaker_verification.finetune - INFO - Explicitly initialized base_model.model.backbone.encoder.layers.2.attention.k_proj.lora_B.default.weight with random values
2025-03-30 22:50:53,958 - speaker_verification.finetune - INFO - Explicitly initialized base_model.model.backbone.encoder.layers.2.attention.v_proj.lora_B.default.weight with random values
2025-03-30 22:50:53,958 - speaker_verification.finetune - INFO - Explicitly initialized base_model.model.backbone.encoder.layers.2.attention.q_proj.lora_B.default.weight with random values
2025-03-30 22:50:53,959 - speaker_verification.finetune - INFO - Explicitly initialized base_model.model.backbone.encoder.layers.2.attention.out_proj.lora_B.default.weight with random values
2025-03-30 22:50:53,959 - speaker_verification.finetune - INFO - Explicitly initialized base_model.model.backbone.encoder.layers.3.attention.k_proj.lora_B.default.weight with random values
2025-03-30 22:50:53,959 - speaker_verification.finetune - INFO - Explicitly initialized base_model.model.backbone.encoder.layers.3.attention.v_proj.lora_B.default.weight with random values
2025-03-30 22:50:53,959 - speaker_verification.finetune - INFO - Explicitly initialized base_model.model.backbone.encoder.layers.3.attention.q_proj.lora_B.default.weight with random values
2025-03-30 22:50:53,959 - speaker_verification.finetune - INFO - Explicitly initialized base_model.model.backbone.encoder.layers.3.attention.out_proj.lora_B.default.weight with random values
2025-03-30 22:50:53,959 - speaker_verification.finetune - INFO - Explicitly initialized base_model.model.backbone.encoder.layers.4.attention.k_proj.lora_B.default.weight with random values
2025-03-30 22:50:53,959 - speaker_verification.finetune - INFO - Explicitly initialized base_model.model.backbone.encoder.layers.4.attention.v_proj.lora_B.default.weight with random values
2025-03-30 22:50:53,959 - speaker_verification.finetune - INFO - Explicitly initialized base_model.model.backbone.encoder.layers.4.attention.q_proj.lora_B.default.weight with random values
2025-03-30 22:50:53,960 - speaker_verification.finetune - INFO - Explicitly initialized base_model.model.backbone.encoder.layers.4.attention.out_proj.lora_B.default.weight with random values
2025-03-30 22:50:53,960 - speaker_verification.finetune - INFO - Explicitly initialized base_model.model.backbone.encoder.layers.5.attention.k_proj.lora_B.default.weight with random values
2025-03-30 22:50:53,960 - speaker_verification.finetune - INFO - Explicitly initialized base_model.model.backbone.encoder.layers.5.attention.v_proj.lora_B.default.weight with random values
2025-03-30 22:50:53,960 - speaker_verification.finetune - INFO - Explicitly initialized base_model.model.backbone.encoder.layers.5.attention.q_proj.lora_B.default.weight with random values
2025-03-30 22:50:53,960 - speaker_verification.finetune - INFO - Explicitly initialized base_model.model.backbone.encoder.layers.5.attention.out_proj.lora_B.default.weight with random values
2025-03-30 22:50:53,960 - speaker_verification.finetune - INFO - Explicitly initialized base_model.model.backbone.encoder.layers.6.attention.k_proj.lora_B.default.weight with random values
2025-03-30 22:50:53,960 - speaker_verification.finetune - INFO - Explicitly initialized base_model.model.backbone.encoder.layers.6.attention.v_proj.lora_B.default.weight with random values
2025-03-30 22:50:53,960 - speaker_verification.finetune - INFO - Explicitly initialized base_model.model.backbone.encoder.layers.6.attention.q_proj.lora_B.default.weight with random values
2025-03-30 22:50:53,960 - speaker_verification.finetune - INFO - Explicitly initialized base_model.model.backbone.encoder.layers.6.attention.out_proj.lora_B.default.weight with random values
2025-03-30 22:50:53,961 - speaker_verification.finetune - INFO - Explicitly initialized base_model.model.backbone.encoder.layers.7.attention.k_proj.lora_B.default.weight with random values
2025-03-30 22:50:53,961 - speaker_verification.finetune - INFO - Explicitly initialized base_model.model.backbone.encoder.layers.7.attention.v_proj.lora_B.default.weight with random values
2025-03-30 22:50:53,961 - speaker_verification.finetune - INFO - Explicitly initialized base_model.model.backbone.encoder.layers.7.attention.q_proj.lora_B.default.weight with random values
2025-03-30 22:50:53,961 - speaker_verification.finetune - INFO - Explicitly initialized base_model.model.backbone.encoder.layers.7.attention.out_proj.lora_B.default.weight with random values
2025-03-30 22:50:53,961 - speaker_verification.finetune - INFO - Explicitly initialized base_model.model.backbone.encoder.layers.8.attention.k_proj.lora_B.default.weight with random values
2025-03-30 22:50:53,961 - speaker_verification.finetune - INFO - Explicitly initialized base_model.model.backbone.encoder.layers.8.attention.v_proj.lora_B.default.weight with random values
2025-03-30 22:50:53,961 - speaker_verification.finetune - INFO - Explicitly initialized base_model.model.backbone.encoder.layers.8.attention.q_proj.lora_B.default.weight with random values
2025-03-30 22:50:53,961 - speaker_verification.finetune - INFO - Explicitly initialized base_model.model.backbone.encoder.layers.8.attention.out_proj.lora_B.default.weight with random values
2025-03-30 22:50:53,961 - speaker_verification.finetune - INFO - Explicitly initialized base_model.model.backbone.encoder.layers.9.attention.k_proj.lora_B.default.weight with random values
2025-03-30 22:50:53,961 - speaker_verification.finetune - INFO - Explicitly initialized base_model.model.backbone.encoder.layers.9.attention.v_proj.lora_B.default.weight with random values
2025-03-30 22:50:53,962 - speaker_verification.finetune - INFO - Explicitly initialized base_model.model.backbone.encoder.layers.9.attention.q_proj.lora_B.default.weight with random values
2025-03-30 22:50:53,962 - speaker_verification.finetune - INFO - Explicitly initialized base_model.model.backbone.encoder.layers.9.attention.out_proj.lora_B.default.weight with random values
2025-03-30 22:50:53,962 - speaker_verification.finetune - INFO - Explicitly initialized base_model.model.backbone.encoder.layers.10.attention.k_proj.lora_B.default.weight with random values
2025-03-30 22:50:53,962 - speaker_verification.finetune - INFO - Explicitly initialized base_model.model.backbone.encoder.layers.10.attention.v_proj.lora_B.default.weight with random values
2025-03-30 22:50:53,962 - speaker_verification.finetune - INFO - Explicitly initialized base_model.model.backbone.encoder.layers.10.attention.q_proj.lora_B.default.weight with random values
2025-03-30 22:50:53,962 - speaker_verification.finetune - INFO - Explicitly initialized base_model.model.backbone.encoder.layers.10.attention.out_proj.lora_B.default.weight with random values
2025-03-30 22:50:53,962 - speaker_verification.finetune - INFO - Explicitly initialized base_model.model.backbone.encoder.layers.11.attention.k_proj.lora_B.default.weight with random values
2025-03-30 22:50:53,962 - speaker_verification.finetune - INFO - Explicitly initialized base_model.model.backbone.encoder.layers.11.attention.v_proj.lora_B.default.weight with random values
2025-03-30 22:50:53,963 - speaker_verification.finetune - INFO - Explicitly initialized base_model.model.backbone.encoder.layers.11.attention.q_proj.lora_B.default.weight with random values
2025-03-30 22:50:53,963 - speaker_verification.finetune - INFO - Explicitly initialized base_model.model.backbone.encoder.layers.11.attention.out_proj.lora_B.default.weight with random values
2025-03-30 22:50:53,965 - speaker_verification.finetune - INFO - Trainable params: 1179648 || All params: 95638384 || Trainable%: 1.2334%
2025-03-30 22:50:54,240 - speech_enhancement.sepformer - INFO - Loading SepFormer model...
2025-03-30 22:50:54,241 - speech_enhancement.sepformer - INFO - Downloading model files from speechbrain/sepformer-wham
2025-03-30 22:50:54,242 - speechbrain.utils.fetching - INFO - Fetch hyperparams.yaml: Fetching from HuggingFace Hub 'speechbrain/sepformer-wham' if not cached
C:\Users\SQREAM\Desktop\semester_six\speech_understanding_assignment_02\speech\lib\site-packages\speechbrain\utils\fetching.py:151: UserWarning: Using SYMLINK strategy on Windows for fetching potentially requires elevated privileges and is not recommended. See `LocalStrategy` documentation.
  warnings.warn(
2025-03-30 22:50:54,492 - speechbrain.utils.fetching - INFO - Fetch custom.py: Fetching from HuggingFace Hub 'speechbrain/sepformer-wham' if not cached
C:\Users\SQREAM\Desktop\semester_six\speech_understanding_assignment_02\speech\lib\site-packages\speechbrain\utils\parameter_transfer.py:234: UserWarning: Requested Pretrainer collection using symlinks on Windows. This might not work; see `LocalStrategy` documentation. Consider unsetting `collect_in` in Pretrainer to avoid symlinking altogether.
  warnings.warn(
2025-03-30 22:50:54,947 - speechbrain.utils.fetching - INFO - Fetch masknet.ckpt: Fetching from HuggingFace Hub 'speechbrain/sepformer-wham' if not cached
2025-03-30 22:50:55,192 - speechbrain.utils.fetching - INFO - Fetch encoder.ckpt: Fetching from HuggingFace Hub 'speechbrain/sepformer-wham' if not cached
2025-03-30 22:50:55,439 - speechbrain.utils.fetching - INFO - Fetch decoder.ckpt: Fetching from HuggingFace Hub 'speechbrain/sepformer-wham' if not cached
2025-03-30 22:50:55,688 - speech_enhancement.sepformer - INFO - Loading the model into memory
2025-03-30 22:50:55,689 - speechbrain.utils.fetching - INFO - Fetch hyperparams.yaml: Fetching from HuggingFace Hub 'speechbrain/sepformer-wham' if not cached
2025-03-30 22:50:55,928 - speechbrain.utils.fetching - INFO - Fetch custom.py: Fetching from HuggingFace Hub 'speechbrain/sepformer-wham' if not cached
2025-03-30 22:50:56,303 - speechbrain.utils.fetching - INFO - Fetch masknet.ckpt: Fetching from HuggingFace Hub 'speechbrain/sepformer-wham' if not cached
2025-03-30 22:50:56,542 - speechbrain.utils.fetching - INFO - Fetch encoder.ckpt: Fetching from HuggingFace Hub 'speechbrain/sepformer-wham' if not cached
2025-03-30 22:50:56,785 - speechbrain.utils.fetching - INFO - Fetch decoder.ckpt: Fetching from HuggingFace Hub 'speechbrain/sepformer-wham' if not cached
2025-03-30 22:50:57,033 - speechbrain.utils.parameter_transfer - INFO - Loading pretrained files for: masknet, encoder, decoder
2025-03-30 22:50:57,344 - speech_enhancement.sepformer - INFO - Testing if model is loaded properly
2025-03-30 22:50:57,344 - speech_enhancement.sepformer - INFO - SepFormer model loaded successfully
2025-03-30 22:50:57,387 - __main__ - INFO - Loaded dataset with 500 mixtures
2025-03-30 22:50:57,389 - __main__ - INFO - Loaded dataset with 200 mixtures
2025-03-30 22:50:57,393 - __main__ - INFO - Training with 20 parameters
Epoch 1/1 [Train]:   0%|          | 0/250 [00:00<?, ?it/s]2025-03-30 22:50:57,451 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:50:58,816 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:50:58,816 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:50:58,830 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:50:58,883 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:50:58,884 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:50:59,341 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:50:59,341 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:50:59,341 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:   0%|          | 0/250 [00:03<?, ?it/s, loss=0.263]Epoch 1/1 [Train]:   0%|          | 1/250 [00:03<12:34,  3.03s/it, loss=0.263]2025-03-30 22:51:00,533 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:51:00,599 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:51:00,599 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:51:01,054 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:51:01,091 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:51:01,092 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:51:01,564 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:51:01,564 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:51:01,564 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:   0%|          | 1/250 [00:04<12:34,  3.03s/it, loss=0.259]Epoch 1/1 [Train]:   1%|          | 2/250 [00:04<08:25,  2.04s/it, loss=0.259]2025-03-30 22:51:01,864 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:51:01,907 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:51:01,908 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:51:02,386 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:51:02,423 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:51:02,423 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:51:02,897 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:51:02,897 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:51:02,897 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:   1%|          | 2/250 [00:05<08:25,  2.04s/it, loss=0.203]Epoch 1/1 [Train]:   1%|1         | 3/250 [00:05<07:03,  1.71s/it, loss=0.203]2025-03-30 22:51:03,210 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:51:03,263 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:51:03,263 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:51:03,733 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:51:03,774 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:51:03,774 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:51:04,245 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:51:04,245 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:51:04,245 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:   1%|1         | 3/250 [00:07<07:03,  1.71s/it, loss=0.226]Epoch 1/1 [Train]:   2%|1         | 4/250 [00:07<06:26,  1.57s/it, loss=0.226]2025-03-30 22:51:04,583 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:51:04,624 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:51:04,624 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:51:05,106 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:51:05,147 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:51:05,147 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:51:05,618 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:51:05,619 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:51:05,619 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:   2%|1         | 4/250 [00:08<06:26,  1.57s/it, loss=0.205]Epoch 1/1 [Train]:   2%|2         | 5/250 [00:08<06:08,  1.50s/it, loss=0.205]2025-03-30 22:51:05,985 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:51:06,046 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:51:06,047 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:51:06,511 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:51:06,551 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:51:06,551 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:51:07,023 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:51:07,023 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:51:07,023 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:   2%|2         | 5/250 [00:09<06:08,  1.50s/it, loss=0.227]Epoch 1/1 [Train]:   2%|2         | 6/250 [00:09<05:56,  1.46s/it, loss=0.227]2025-03-30 22:51:07,328 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:51:07,382 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:51:07,382 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:51:07,849 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:51:07,885 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:51:07,885 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:51:08,359 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:51:08,360 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:51:08,360 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:   2%|2         | 6/250 [00:11<05:56,  1.46s/it, loss=0.205]Epoch 1/1 [Train]:   3%|2         | 7/250 [00:11<05:46,  1.43s/it, loss=0.205]2025-03-30 22:51:08,656 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:51:08,699 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:51:08,700 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:51:09,176 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:51:09,212 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:51:09,212 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:51:09,687 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:51:09,687 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:51:09,687 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:   3%|2         | 7/250 [00:12<05:46,  1.43s/it, loss=0.215]Epoch 1/1 [Train]:   3%|3         | 8/250 [00:12<05:37,  1.39s/it, loss=0.215]2025-03-30 22:51:09,972 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:51:10,015 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:51:10,015 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:51:10,498 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:51:10,537 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:51:10,537 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:51:11,009 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:51:11,009 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:51:11,009 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:   3%|3         | 8/250 [00:13<05:37,  1.39s/it, loss=0.215]Epoch 1/1 [Train]:   4%|3         | 9/250 [00:13<05:30,  1.37s/it, loss=0.215]2025-03-30 22:51:11,293 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:51:11,333 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:51:11,333 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:51:11,815 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:51:11,853 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:51:11,853 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:51:12,328 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:51:12,328 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:51:12,328 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:   4%|3         | 9/250 [00:15<05:30,  1.37s/it, loss=0.207]Epoch 1/1 [Train]:   4%|4         | 10/250 [00:15<05:31,  1.38s/it, loss=0.207]2025-03-30 22:51:12,751 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:51:12,801 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:51:12,802 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:51:13,278 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:51:13,315 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:51:13,315 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:51:13,790 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:51:13,790 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:51:13,790 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:   4%|4         | 10/250 [00:16<05:31,  1.38s/it, loss=0.16] Epoch 1/1 [Train]:   4%|4         | 11/250 [00:16<05:29,  1.38s/it, loss=0.16]2025-03-30 22:51:14,067 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:51:14,108 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:51:14,109 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:51:14,589 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:51:14,626 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:51:14,626 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:51:15,102 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:51:15,102 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:51:15,102 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:   4%|4         | 11/250 [00:17<05:29,  1.38s/it, loss=0.175]Epoch 1/1 [Train]:   5%|4         | 12/250 [00:17<05:22,  1.35s/it, loss=0.175]2025-03-30 22:51:15,380 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:51:15,421 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:51:15,421 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:51:15,903 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:51:15,939 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:51:15,940 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:51:16,415 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:51:16,415 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:51:16,416 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:   5%|4         | 12/250 [00:19<05:22,  1.35s/it, loss=0.185]Epoch 1/1 [Train]:   5%|5         | 13/250 [00:19<05:18,  1.34s/it, loss=0.185]2025-03-30 22:51:16,699 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:51:16,738 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:51:16,738 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:51:17,222 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:51:17,262 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:51:17,263 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:51:17,735 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:51:17,735 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:51:17,735 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:   5%|5         | 13/250 [00:20<05:18,  1.34s/it, loss=0.161]Epoch 1/1 [Train]:   6%|5         | 14/250 [00:20<05:16,  1.34s/it, loss=0.161]2025-03-30 22:51:18,028 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:51:18,064 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:51:18,065 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:51:18,551 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:51:18,591 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:51:18,591 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:51:19,064 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:51:19,064 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:51:19,064 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:   6%|5         | 14/250 [00:21<05:16,  1.34s/it, loss=0.193]Epoch 1/1 [Train]:   6%|6         | 15/250 [00:21<05:13,  1.34s/it, loss=0.193]2025-03-30 22:51:19,349 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:51:19,391 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:51:19,391 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:51:19,872 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:51:19,907 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:51:19,907 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:51:20,384 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:51:20,385 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:51:20,385 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:   6%|6         | 15/250 [00:23<05:13,  1.34s/it, loss=0.163]Epoch 1/1 [Train]:   6%|6         | 16/250 [00:23<05:11,  1.33s/it, loss=0.163]2025-03-30 22:51:20,691 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:51:20,731 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:51:20,731 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:51:21,213 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:51:21,248 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:51:21,248 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:51:21,725 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:51:21,725 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:51:21,725 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:   6%|6         | 16/250 [00:24<05:11,  1.33s/it, loss=0.176]Epoch 1/1 [Train]:   7%|6         | 17/250 [00:24<05:10,  1.33s/it, loss=0.176]2025-03-30 22:51:22,008 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:51:22,050 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:51:22,050 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:51:22,532 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:51:22,570 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:51:22,570 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:51:23,045 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:51:23,045 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:51:23,045 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:   7%|6         | 17/250 [00:25<05:10,  1.33s/it, loss=0.133]Epoch 1/1 [Train]:   7%|7         | 18/250 [00:25<05:08,  1.33s/it, loss=0.133]2025-03-30 22:51:23,322 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:51:23,363 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:51:23,363 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:51:23,845 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:51:23,883 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:51:23,883 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:51:24,358 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:51:24,358 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:51:24,358 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:   7%|7         | 18/250 [00:27<05:08,  1.33s/it, loss=0.139]Epoch 1/1 [Train]:   8%|7         | 19/250 [00:27<05:06,  1.33s/it, loss=0.139]2025-03-30 22:51:24,642 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:51:24,691 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:51:24,691 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:51:25,165 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:51:25,201 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:51:25,201 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:51:25,677 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:51:25,677 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:51:25,677 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:   8%|7         | 19/250 [00:28<05:06,  1.33s/it, loss=0.165]Epoch 1/1 [Train]:   8%|8         | 20/250 [00:28<05:04,  1.32s/it, loss=0.165]2025-03-30 22:51:25,945 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:51:25,980 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:51:25,980 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:51:26,468 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:51:26,504 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:51:26,504 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:51:26,981 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:51:26,981 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:51:26,981 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:   8%|8         | 20/250 [00:29<05:04,  1.32s/it, loss=0.117]Epoch 1/1 [Train]:   8%|8         | 21/250 [00:29<05:02,  1.32s/it, loss=0.117]2025-03-30 22:51:27,279 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:51:27,316 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:51:27,316 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:51:27,802 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:51:27,836 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:51:27,837 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:51:28,316 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:51:28,316 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:51:28,316 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:   8%|8         | 21/250 [00:31<05:02,  1.32s/it, loss=0.138]Epoch 1/1 [Train]:   9%|8         | 22/250 [00:31<05:01,  1.32s/it, loss=0.138]2025-03-30 22:51:28,614 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:51:28,653 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:51:28,653 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:51:29,139 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:51:29,174 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:51:29,175 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:51:29,652 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:51:29,653 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:51:29,653 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:   9%|8         | 22/250 [00:32<05:01,  1.32s/it, loss=0.159]Epoch 1/1 [Train]:   9%|9         | 23/250 [00:32<05:01,  1.33s/it, loss=0.159]2025-03-30 22:51:29,931 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:51:29,971 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:51:29,971 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:51:30,455 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:51:30,491 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:51:30,491 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:51:30,968 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:51:30,968 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:51:30,968 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:   9%|9         | 23/250 [00:33<05:01,  1.33s/it, loss=0.155]Epoch 1/1 [Train]:  10%|9         | 24/250 [00:33<04:58,  1.32s/it, loss=0.155]2025-03-30 22:51:31,247 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:51:31,285 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:51:31,285 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:51:31,771 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:51:31,806 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:51:31,806 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:51:32,285 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:51:32,285 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:51:32,285 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  10%|9         | 24/250 [00:35<04:58,  1.32s/it, loss=0.137]Epoch 1/1 [Train]:  10%|#         | 25/250 [00:35<04:57,  1.32s/it, loss=0.137]2025-03-30 22:51:32,560 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:51:32,600 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:51:32,600 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:51:33,088 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:51:33,127 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:51:33,127 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:51:33,602 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:51:33,602 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:51:33,602 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  10%|#         | 25/250 [00:36<04:57,  1.32s/it, loss=0.148]Epoch 1/1 [Train]:  10%|#         | 26/250 [00:36<04:55,  1.32s/it, loss=0.148]2025-03-30 22:51:33,878 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:51:33,917 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:51:33,917 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:51:34,401 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:51:34,441 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:51:34,441 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:51:34,916 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:51:34,916 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:51:34,916 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  10%|#         | 26/250 [00:37<04:55,  1.32s/it, loss=0.133]Epoch 1/1 [Train]:  11%|#         | 27/250 [00:37<04:54,  1.32s/it, loss=0.133]2025-03-30 22:51:35,198 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:51:35,241 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:51:35,242 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:51:35,722 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:51:35,758 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:51:35,758 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:51:36,235 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:51:36,235 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:51:36,235 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  11%|#         | 27/250 [00:39<04:54,  1.32s/it, loss=0.151]Epoch 1/1 [Train]:  11%|#1        | 28/250 [00:39<04:53,  1.32s/it, loss=0.151]2025-03-30 22:51:36,519 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:51:36,557 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:51:36,557 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:51:37,043 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:51:37,078 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:51:37,078 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:51:37,557 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:51:37,557 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:51:37,557 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  11%|#1        | 28/250 [00:40<04:53,  1.32s/it, loss=0.136]Epoch 1/1 [Train]:  12%|#1        | 29/250 [00:40<04:51,  1.32s/it, loss=0.136]2025-03-30 22:51:37,856 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:51:37,897 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:51:37,897 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:51:38,380 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:51:38,417 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:51:38,417 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:51:38,894 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:51:38,895 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:51:38,895 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  12%|#1        | 29/250 [00:41<04:51,  1.32s/it, loss=0.131]Epoch 1/1 [Train]:  12%|#2        | 30/250 [00:41<04:50,  1.32s/it, loss=0.131]2025-03-30 22:51:39,167 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:51:39,208 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:51:39,208 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:51:39,691 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:51:39,726 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:51:39,727 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:51:40,203 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:51:40,204 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:51:40,204 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  12%|#2        | 30/250 [00:43<04:50,  1.32s/it, loss=0.116]Epoch 1/1 [Train]:  12%|#2        | 31/250 [00:43<04:49,  1.32s/it, loss=0.116]2025-03-30 22:51:40,511 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:51:40,548 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:51:40,548 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:51:41,035 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:51:41,071 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:51:41,071 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:51:41,549 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:51:41,549 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:51:41,549 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  12%|#2        | 31/250 [00:44<04:49,  1.32s/it, loss=0.118]Epoch 1/1 [Train]:  13%|#2        | 32/250 [00:44<04:48,  1.32s/it, loss=0.118]2025-03-30 22:51:41,814 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:51:41,854 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:51:41,854 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:51:42,339 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:51:42,376 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:51:42,377 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:51:42,852 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:51:42,852 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:51:42,852 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  13%|#2        | 32/250 [00:45<04:48,  1.32s/it, loss=0.117]Epoch 1/1 [Train]:  13%|#3        | 33/250 [00:45<04:46,  1.32s/it, loss=0.117]2025-03-30 22:51:43,127 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:51:43,167 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:51:43,167 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:51:43,650 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:51:43,686 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:51:43,686 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:51:44,164 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:51:44,164 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:51:44,164 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  13%|#3        | 33/250 [00:46<04:46,  1.32s/it, loss=0.12] Epoch 1/1 [Train]:  14%|#3        | 34/250 [00:46<04:45,  1.32s/it, loss=0.12]2025-03-30 22:51:44,475 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:51:44,521 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:51:44,521 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:51:45,000 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:51:45,037 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:51:45,037 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:51:45,514 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:51:45,514 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:51:45,514 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  14%|#3        | 34/250 [00:48<04:45,  1.32s/it, loss=0.131]Epoch 1/1 [Train]:  14%|#4        | 35/250 [00:48<04:45,  1.33s/it, loss=0.131]2025-03-30 22:51:45,794 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:51:45,832 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:51:45,833 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:51:46,320 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:51:46,354 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:51:46,355 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:51:46,834 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:51:46,834 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:51:46,834 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  14%|#4        | 35/250 [00:49<04:45,  1.33s/it, loss=0.136]Epoch 1/1 [Train]:  14%|#4        | 36/250 [00:49<04:43,  1.32s/it, loss=0.136]2025-03-30 22:51:47,114 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:51:47,153 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:51:47,153 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:51:47,639 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:51:47,675 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:51:47,675 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:51:48,154 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:51:48,154 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:51:48,154 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  14%|#4        | 36/250 [00:50<04:43,  1.32s/it, loss=0.0996]Epoch 1/1 [Train]:  15%|#4        | 37/250 [00:50<04:41,  1.32s/it, loss=0.0996]2025-03-30 22:51:48,427 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:51:48,465 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:51:48,465 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:51:48,962 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:51:49,014 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:51:49,014 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:51:49,478 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:51:49,478 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:51:49,478 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  15%|#4        | 37/250 [00:52<04:41,  1.32s/it, loss=0.119] Epoch 1/1 [Train]:  15%|#5        | 38/250 [00:52<04:40,  1.32s/it, loss=0.119]2025-03-30 22:51:49,748 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:51:49,790 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:51:49,790 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:51:50,275 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:51:50,311 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:51:50,311 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:51:50,789 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:51:50,789 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:51:50,790 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  15%|#5        | 38/250 [00:53<04:40,  1.32s/it, loss=0.104]Epoch 1/1 [Train]:  16%|#5        | 39/250 [00:53<04:38,  1.32s/it, loss=0.104]2025-03-30 22:51:51,076 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:51:51,122 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:51:51,122 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:51:51,601 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:51:51,637 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:51:51,637 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:51:52,116 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:51:52,116 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:51:52,116 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  16%|#5        | 39/250 [00:54<04:38,  1.32s/it, loss=0.106]Epoch 1/1 [Train]:  16%|#6        | 40/250 [00:54<04:37,  1.32s/it, loss=0.106]2025-03-30 22:51:52,384 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:51:52,421 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:51:52,422 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:51:52,909 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:51:52,945 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:51:52,945 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:51:53,424 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:51:53,424 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:51:53,424 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  16%|#6        | 40/250 [00:56<04:37,  1.32s/it, loss=0.116]Epoch 1/1 [Train]:  16%|#6        | 41/250 [00:56<04:36,  1.32s/it, loss=0.116]2025-03-30 22:51:53,709 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:51:53,750 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:51:53,750 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:51:54,234 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:51:54,270 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:51:54,271 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:51:54,749 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:51:54,749 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:51:54,749 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  16%|#6        | 41/250 [00:57<04:36,  1.32s/it, loss=0.109]Epoch 1/1 [Train]:  17%|#6        | 42/250 [00:57<04:34,  1.32s/it, loss=0.109]2025-03-30 22:51:55,038 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:51:55,079 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:51:55,079 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:51:55,566 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:51:55,615 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:51:55,616 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:51:56,081 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:51:56,081 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:51:56,081 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  17%|#6        | 42/250 [00:58<04:34,  1.32s/it, loss=0.112]Epoch 1/1 [Train]:  17%|#7        | 43/250 [00:58<04:33,  1.32s/it, loss=0.112]2025-03-30 22:51:56,364 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:51:56,403 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:51:56,403 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:51:56,889 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:51:56,923 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:51:56,924 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:51:57,403 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:51:57,403 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:51:57,403 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  17%|#7        | 43/250 [01:00<04:33,  1.32s/it, loss=0.131]Epoch 1/1 [Train]:  18%|#7        | 44/250 [01:00<04:32,  1.32s/it, loss=0.131]2025-03-30 22:51:57,687 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:51:57,730 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:51:57,730 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:51:58,215 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:51:58,255 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:51:58,255 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:51:58,731 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:51:58,731 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:51:58,731 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  18%|#7        | 44/250 [01:01<04:32,  1.32s/it, loss=0.125]Epoch 1/1 [Train]:  18%|#8        | 45/250 [01:01<04:31,  1.32s/it, loss=0.125]2025-03-30 22:51:59,013 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:51:59,049 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:51:59,049 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:51:59,538 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:51:59,574 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:51:59,574 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:52:00,052 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:52:00,053 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:52:00,053 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  18%|#8        | 45/250 [01:02<04:31,  1.32s/it, loss=0.129]Epoch 1/1 [Train]:  18%|#8        | 46/250 [01:02<04:30,  1.33s/it, loss=0.129]2025-03-30 22:52:00,362 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:52:00,398 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:52:00,399 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:52:00,889 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:52:00,927 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:52:00,927 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:52:01,405 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:52:01,405 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:52:01,405 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  18%|#8        | 46/250 [01:04<04:30,  1.33s/it, loss=0.1]  Epoch 1/1 [Train]:  19%|#8        | 47/250 [01:04<04:30,  1.33s/it, loss=0.1]2025-03-30 22:52:01,692 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:52:01,730 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:52:01,730 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:52:02,218 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:52:02,253 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:52:02,253 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:52:02,732 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:52:02,732 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:52:02,732 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  19%|#8        | 47/250 [01:05<04:30,  1.33s/it, loss=0.0974]Epoch 1/1 [Train]:  19%|#9        | 48/250 [01:05<04:29,  1.33s/it, loss=0.0974]2025-03-30 22:52:03,018 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:52:03,061 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:52:03,062 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:52:03,547 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:52:03,587 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:52:03,587 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:52:04,063 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:52:04,063 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:52:04,063 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  19%|#9        | 48/250 [01:06<04:29,  1.33s/it, loss=0.107] Epoch 1/1 [Train]:  20%|#9        | 49/250 [01:06<04:27,  1.33s/it, loss=0.107]2025-03-30 22:52:04,350 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:52:04,385 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:52:04,385 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:52:04,877 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:52:04,913 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:52:04,913 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:52:05,392 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:52:05,392 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:52:05,392 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  20%|#9        | 49/250 [01:08<04:27,  1.33s/it, loss=0.0982]Epoch 1/1 [Train]:  20%|##        | 50/250 [01:08<04:26,  1.33s/it, loss=0.0982]2025-03-30 22:52:05,672 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:52:05,711 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:52:05,711 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:52:06,196 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:52:06,231 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:52:06,231 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:52:06,711 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:52:06,711 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:52:06,711 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  20%|##        | 50/250 [01:09<04:26,  1.33s/it, loss=0.123] Epoch 1/1 [Train]:  20%|##        | 51/250 [01:09<04:24,  1.33s/it, loss=0.123]2025-03-30 22:52:07,007 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:52:07,055 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:52:07,055 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:52:07,534 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:52:07,569 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:52:07,569 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:52:08,049 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:52:08,049 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:52:08,049 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  20%|##        | 51/250 [01:10<04:24,  1.33s/it, loss=0.0862]Epoch 1/1 [Train]:  21%|##        | 52/250 [01:10<04:22,  1.33s/it, loss=0.0862]2025-03-30 22:52:08,351 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:52:08,404 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:52:08,404 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:52:08,877 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:52:08,913 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:52:08,913 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:52:09,392 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:52:09,392 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:52:09,392 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  21%|##        | 52/250 [01:12<04:22,  1.33s/it, loss=0.121] Epoch 1/1 [Train]:  21%|##1       | 53/250 [01:12<04:22,  1.33s/it, loss=0.121]2025-03-30 22:52:09,682 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:52:09,720 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:52:09,721 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:52:10,208 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:52:10,244 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:52:10,244 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:52:10,723 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:52:10,723 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:52:10,723 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  21%|##1       | 53/250 [01:13<04:22,  1.33s/it, loss=0.139]Epoch 1/1 [Train]:  22%|##1       | 54/250 [01:13<04:21,  1.33s/it, loss=0.139]2025-03-30 22:52:11,008 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:52:11,051 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:52:11,051 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:52:11,538 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:52:11,579 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:52:11,579 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:52:12,053 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:52:12,053 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:52:12,053 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  22%|##1       | 54/250 [01:14<04:21,  1.33s/it, loss=0.112]Epoch 1/1 [Train]:  22%|##2       | 55/250 [01:14<04:20,  1.33s/it, loss=0.112]2025-03-30 22:52:12,344 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:52:12,382 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:52:12,382 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:52:12,871 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:52:12,906 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:52:12,906 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:52:13,388 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:52:13,388 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:52:13,388 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  22%|##2       | 55/250 [01:16<04:20,  1.33s/it, loss=0.0996]Epoch 1/1 [Train]:  22%|##2       | 56/250 [01:16<04:18,  1.33s/it, loss=0.0996]2025-03-30 22:52:13,665 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:52:13,702 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:52:13,702 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:52:14,193 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:52:14,228 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:52:14,229 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:52:14,708 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:52:14,708 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:52:14,708 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  22%|##2       | 56/250 [01:17<04:18,  1.33s/it, loss=0.113] Epoch 1/1 [Train]:  23%|##2       | 57/250 [01:17<04:16,  1.33s/it, loss=0.113]2025-03-30 22:52:14,985 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:52:15,027 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:52:15,027 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:52:15,512 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:52:15,547 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:52:15,548 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:52:16,029 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:52:16,029 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:52:16,029 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  23%|##2       | 57/250 [01:18<04:16,  1.33s/it, loss=0.097]Epoch 1/1 [Train]:  23%|##3       | 58/250 [01:18<04:14,  1.32s/it, loss=0.097]2025-03-30 22:52:16,317 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:52:16,358 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:52:16,358 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:52:16,844 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:52:16,879 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:52:16,879 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:52:17,360 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:52:17,360 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:52:17,360 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  23%|##3       | 58/250 [01:20<04:14,  1.32s/it, loss=0.105]Epoch 1/1 [Train]:  24%|##3       | 59/250 [01:20<04:13,  1.33s/it, loss=0.105]2025-03-30 22:52:17,631 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:52:17,672 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:52:17,672 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:52:18,159 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:52:18,194 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:52:18,194 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:52:18,675 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:52:18,675 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:52:18,675 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  24%|##3       | 59/250 [01:21<04:13,  1.33s/it, loss=0.101]Epoch 1/1 [Train]:  24%|##4       | 60/250 [01:21<04:11,  1.32s/it, loss=0.101]2025-03-30 22:52:18,948 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:52:18,985 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:52:18,986 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:52:19,474 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:52:19,511 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:52:19,511 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:52:19,990 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:52:19,991 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:52:19,991 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  24%|##4       | 60/250 [01:22<04:11,  1.32s/it, loss=0.0879]Epoch 1/1 [Train]:  24%|##4       | 61/250 [01:22<04:10,  1.32s/it, loss=0.0879]2025-03-30 22:52:20,267 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:52:20,303 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:52:20,304 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:52:20,794 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:52:20,830 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:52:20,830 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:52:21,311 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:52:21,311 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:52:21,311 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  24%|##4       | 61/250 [01:24<04:10,  1.32s/it, loss=0.0911]Epoch 1/1 [Train]:  25%|##4       | 62/250 [01:24<04:08,  1.32s/it, loss=0.0911]2025-03-30 22:52:21,594 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:52:21,635 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:52:21,636 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:52:22,120 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:52:22,156 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:52:22,156 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:52:22,636 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:52:22,637 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:52:22,637 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  25%|##4       | 62/250 [01:25<04:08,  1.32s/it, loss=0.0853]Epoch 1/1 [Train]:  25%|##5       | 63/250 [01:25<04:07,  1.33s/it, loss=0.0853]2025-03-30 22:52:22,941 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:52:22,981 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:52:22,981 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:52:23,469 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:52:23,508 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:52:23,508 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:52:23,987 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:52:23,987 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:52:23,987 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  25%|##5       | 63/250 [01:26<04:07,  1.33s/it, loss=0.101] Epoch 1/1 [Train]:  26%|##5       | 64/250 [01:26<04:07,  1.33s/it, loss=0.101]2025-03-30 22:52:24,261 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:52:24,299 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:52:24,299 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:52:24,789 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:52:24,824 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:52:24,824 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:52:25,305 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:52:25,305 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:52:25,305 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  26%|##5       | 64/250 [01:28<04:07,  1.33s/it, loss=0.121]Epoch 1/1 [Train]:  26%|##6       | 65/250 [01:28<04:05,  1.33s/it, loss=0.121]2025-03-30 22:52:25,625 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:52:25,680 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:52:25,680 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:52:26,159 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:52:26,211 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:52:26,211 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:52:26,676 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:52:26,676 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:52:26,677 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  26%|##6       | 65/250 [01:29<04:05,  1.33s/it, loss=0.0702]Epoch 1/1 [Train]:  26%|##6       | 66/250 [01:29<04:06,  1.34s/it, loss=0.0702]2025-03-30 22:52:26,952 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:52:26,996 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:52:26,996 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:52:27,481 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:52:27,518 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:52:27,518 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:52:27,998 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:52:27,998 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:52:27,998 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  26%|##6       | 66/250 [01:30<04:06,  1.34s/it, loss=0.1]   Epoch 1/1 [Train]:  27%|##6       | 67/250 [01:30<04:04,  1.34s/it, loss=0.1]2025-03-30 22:52:28,283 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:52:28,322 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:52:28,322 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:52:28,811 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:52:28,848 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:52:28,848 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:52:29,328 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:52:29,328 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:52:29,328 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  27%|##6       | 67/250 [01:32<04:04,  1.34s/it, loss=0.112]Epoch 1/1 [Train]:  27%|##7       | 68/250 [01:32<04:03,  1.34s/it, loss=0.112]2025-03-30 22:52:29,616 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:52:29,658 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:52:29,658 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:52:30,145 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:52:30,181 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:52:30,181 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:52:30,660 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:52:30,660 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:52:30,660 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  27%|##7       | 68/250 [01:33<04:03,  1.34s/it, loss=0.115]Epoch 1/1 [Train]:  28%|##7       | 69/250 [01:33<04:00,  1.33s/it, loss=0.115]2025-03-30 22:52:30,930 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:52:30,969 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:52:30,969 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:52:31,456 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:52:31,493 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:52:31,493 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:52:31,972 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:52:31,972 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:52:31,972 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  28%|##7       | 69/250 [01:34<04:00,  1.33s/it, loss=0.0963]Epoch 1/1 [Train]:  28%|##8       | 70/250 [01:34<03:59,  1.33s/it, loss=0.0963]2025-03-30 22:52:32,270 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:52:32,311 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:52:32,311 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:52:32,823 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:52:32,859 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:52:32,860 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:52:33,346 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:52:33,346 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:52:33,346 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  28%|##8       | 70/250 [01:36<03:59,  1.33s/it, loss=0.107] Epoch 1/1 [Train]:  28%|##8       | 71/250 [01:36<04:00,  1.34s/it, loss=0.107]2025-03-30 22:52:33,635 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:52:33,671 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:52:33,671 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:52:34,163 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:52:34,200 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:52:34,200 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:52:34,681 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:52:34,681 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:52:34,681 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  28%|##8       | 71/250 [01:37<04:00,  1.34s/it, loss=0.0777]Epoch 1/1 [Train]:  29%|##8       | 72/250 [01:37<03:58,  1.34s/it, loss=0.0777]2025-03-30 22:52:34,989 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:52:35,032 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:52:35,033 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:52:35,518 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:52:35,555 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:52:35,555 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:52:36,037 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:52:36,037 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:52:36,037 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  29%|##8       | 72/250 [01:38<03:58,  1.34s/it, loss=0.0664]Epoch 1/1 [Train]:  29%|##9       | 73/250 [01:38<03:56,  1.34s/it, loss=0.0664]2025-03-30 22:52:36,308 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:52:36,348 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:52:36,348 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:52:36,837 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:52:36,873 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:52:36,873 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:52:37,357 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:52:37,357 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:52:37,357 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  29%|##9       | 73/250 [01:40<03:56,  1.34s/it, loss=0.112] Epoch 1/1 [Train]:  30%|##9       | 74/250 [01:40<03:55,  1.34s/it, loss=0.112]2025-03-30 22:52:37,640 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:52:37,681 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:52:37,681 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:52:38,169 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:52:38,204 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:52:38,205 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:52:38,693 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:52:38,693 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:52:38,693 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  30%|##9       | 74/250 [01:41<03:55,  1.34s/it, loss=0.0927]Epoch 1/1 [Train]:  30%|###       | 75/250 [01:41<03:53,  1.34s/it, loss=0.0927]2025-03-30 22:52:39,007 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:52:39,057 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:52:39,057 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:52:39,538 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:52:39,573 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:52:39,574 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:52:40,060 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:52:40,060 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:52:40,060 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  30%|###       | 75/250 [01:42<03:53,  1.34s/it, loss=0.0821]Epoch 1/1 [Train]:  30%|###       | 76/250 [01:42<03:53,  1.34s/it, loss=0.0821]2025-03-30 22:52:40,328 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:52:40,371 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:52:40,372 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:52:40,859 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:52:40,897 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:52:40,897 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:52:41,381 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:52:41,381 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:52:41,381 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  30%|###       | 76/250 [01:44<03:53,  1.34s/it, loss=0.0633]Epoch 1/1 [Train]:  31%|###       | 77/250 [01:44<03:52,  1.34s/it, loss=0.0633]2025-03-30 22:52:41,674 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:52:41,719 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:52:41,719 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:52:42,209 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:52:42,246 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:52:42,246 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:52:42,731 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:52:42,731 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:52:42,731 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  31%|###       | 77/250 [01:45<03:52,  1.34s/it, loss=0.0601]Epoch 1/1 [Train]:  31%|###1      | 78/250 [01:45<03:51,  1.34s/it, loss=0.0601]2025-03-30 22:52:43,017 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:52:43,056 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:52:43,056 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:52:43,556 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:52:43,597 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:52:43,597 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:52:44,080 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:52:44,080 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:52:44,080 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  31%|###1      | 78/250 [01:46<03:51,  1.34s/it, loss=0.0723]Epoch 1/1 [Train]:  32%|###1      | 79/250 [01:46<03:49,  1.34s/it, loss=0.0723]2025-03-30 22:52:44,364 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:52:44,405 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:52:44,406 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:52:44,906 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:52:44,942 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:52:44,942 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:52:45,435 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:52:45,435 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:52:45,436 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  32%|###1      | 79/250 [01:48<03:49,  1.34s/it, loss=0.0739]Epoch 1/1 [Train]:  32%|###2      | 80/250 [01:48<03:49,  1.35s/it, loss=0.0739]2025-03-30 22:52:45,744 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:52:45,793 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:52:45,793 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:52:46,272 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:52:46,311 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:52:46,311 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:52:46,800 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:52:46,800 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:52:46,800 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  32%|###2      | 80/250 [01:49<03:49,  1.35s/it, loss=0.0727]Epoch 1/1 [Train]:  32%|###2      | 81/250 [01:49<03:48,  1.35s/it, loss=0.0727]2025-03-30 22:52:47,089 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:52:47,131 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:52:47,131 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:52:47,627 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:52:47,663 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:52:47,664 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:52:48,154 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:52:48,154 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:52:48,154 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  32%|###2      | 81/250 [01:50<03:48,  1.35s/it, loss=0.0897]Epoch 1/1 [Train]:  33%|###2      | 82/250 [01:50<03:46,  1.35s/it, loss=0.0897]2025-03-30 22:52:48,427 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:52:48,465 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:52:48,465 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:52:48,964 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:52:49,003 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:52:49,003 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:52:49,490 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:52:49,490 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:52:49,490 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  33%|###2      | 82/250 [01:52<03:46,  1.35s/it, loss=0.0742]Epoch 1/1 [Train]:  33%|###3      | 83/250 [01:52<03:45,  1.35s/it, loss=0.0742]2025-03-30 22:52:49,782 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:52:49,821 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:52:49,821 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:52:50,314 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:52:50,357 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:52:50,358 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:52:50,847 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:52:50,847 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:52:50,847 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  33%|###3      | 83/250 [01:53<03:45,  1.35s/it, loss=0.0691]Epoch 1/1 [Train]:  34%|###3      | 84/250 [01:53<03:44,  1.35s/it, loss=0.0691]2025-03-30 22:52:51,140 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:52:51,185 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:52:51,185 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:52:51,681 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:52:51,718 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:52:51,718 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:52:52,209 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:52:52,209 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:52:52,209 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  34%|###3      | 84/250 [01:55<03:44,  1.35s/it, loss=0.0731]Epoch 1/1 [Train]:  34%|###4      | 85/250 [01:55<03:43,  1.35s/it, loss=0.0731]2025-03-30 22:52:52,545 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:52:52,599 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:52:52,599 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:52:53,078 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:52:53,116 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:52:53,116 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:52:53,622 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:52:53,623 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:52:53,623 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  34%|###4      | 85/250 [01:56<03:43,  1.35s/it, loss=0.118] Epoch 1/1 [Train]:  34%|###4      | 86/250 [01:56<03:45,  1.37s/it, loss=0.118]2025-03-30 22:52:53,920 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:52:53,965 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:52:53,965 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:52:54,462 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:52:54,499 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:52:54,500 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:52:54,997 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:52:54,997 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:52:54,997 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  34%|###4      | 86/250 [01:57<03:45,  1.37s/it, loss=0.0823]Epoch 1/1 [Train]:  35%|###4      | 87/250 [01:57<03:44,  1.37s/it, loss=0.0823]2025-03-30 22:52:55,297 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:52:55,341 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:52:55,341 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:52:55,837 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:52:55,875 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:52:55,875 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:52:56,367 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:52:56,367 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:52:56,367 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  35%|###4      | 87/250 [01:59<03:44,  1.37s/it, loss=0.0847]Epoch 1/1 [Train]:  35%|###5      | 88/250 [01:59<03:42,  1.37s/it, loss=0.0847]2025-03-30 22:52:56,664 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:52:56,705 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:52:56,705 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:52:57,213 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:52:57,254 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:52:57,254 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:52:57,748 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:52:57,749 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:52:57,749 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  35%|###5      | 88/250 [02:00<03:42,  1.37s/it, loss=0.0862]Epoch 1/1 [Train]:  36%|###5      | 89/250 [02:00<03:41,  1.38s/it, loss=0.0862]2025-03-30 22:52:58,048 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:52:58,094 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:52:58,095 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:52:58,589 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:52:58,627 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:52:58,627 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:52:59,123 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:52:59,123 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:52:59,123 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  36%|###5      | 89/250 [02:01<03:41,  1.38s/it, loss=0.108] Epoch 1/1 [Train]:  36%|###6      | 90/250 [02:01<03:39,  1.37s/it, loss=0.108]2025-03-30 22:52:59,442 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:52:59,503 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:52:59,503 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:52:59,980 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:53:00,022 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:53:00,022 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:53:00,513 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:53:00,514 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:53:00,514 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  36%|###6      | 90/250 [02:03<03:39,  1.37s/it, loss=0.0853]Epoch 1/1 [Train]:  36%|###6      | 91/250 [02:03<03:39,  1.38s/it, loss=0.0853]2025-03-30 22:53:00,794 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:53:00,832 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:53:00,832 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:53:01,346 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:53:01,382 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:53:01,382 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:53:01,887 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:53:01,887 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:53:01,887 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  36%|###6      | 91/250 [02:04<03:39,  1.38s/it, loss=0.0652]Epoch 1/1 [Train]:  37%|###6      | 92/250 [02:04<03:38,  1.38s/it, loss=0.0652]2025-03-30 22:53:02,180 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:53:02,221 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:53:02,221 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:53:02,724 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:53:02,759 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:53:02,760 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:53:03,257 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:53:03,258 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:53:03,258 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  37%|###6      | 92/250 [02:06<03:38,  1.38s/it, loss=0.068] Epoch 1/1 [Train]:  37%|###7      | 93/250 [02:06<03:35,  1.37s/it, loss=0.068]2025-03-30 22:53:03,536 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:53:03,578 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:53:03,578 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:53:04,081 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:53:04,122 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:53:04,122 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:53:04,619 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:53:04,619 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:53:04,619 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  37%|###7      | 93/250 [02:07<03:35,  1.37s/it, loss=0.0646]Epoch 1/1 [Train]:  38%|###7      | 94/250 [02:07<03:34,  1.37s/it, loss=0.0646]2025-03-30 22:53:04,876 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:53:04,912 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:53:04,912 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:53:05,425 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:53:05,462 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:53:05,462 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:53:05,962 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:53:05,964 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:53:05,964 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  38%|###7      | 94/250 [02:08<03:34,  1.37s/it, loss=0.102] Epoch 1/1 [Train]:  38%|###8      | 95/250 [02:08<03:31,  1.36s/it, loss=0.102]2025-03-30 22:53:06,262 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:53:06,313 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:53:06,313 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:53:06,810 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:53:06,848 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:53:06,848 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:53:07,347 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:53:07,347 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:53:07,347 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  38%|###8      | 95/250 [02:10<03:31,  1.36s/it, loss=0.086]Epoch 1/1 [Train]:  38%|###8      | 96/250 [02:10<03:31,  1.37s/it, loss=0.086]2025-03-30 22:53:07,675 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:53:07,731 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:53:07,731 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:53:08,218 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:53:08,253 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:53:08,253 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:53:08,756 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:53:08,757 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:53:08,757 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  38%|###8      | 96/250 [02:11<03:31,  1.37s/it, loss=0.0674]Epoch 1/1 [Train]:  39%|###8      | 97/250 [02:11<03:31,  1.38s/it, loss=0.0674]2025-03-30 22:53:09,041 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:53:09,081 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:53:09,081 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:53:09,586 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:53:09,622 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:53:09,622 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:53:10,133 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:53:10,133 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:53:10,133 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  39%|###8      | 97/250 [02:12<03:31,  1.38s/it, loss=0.0809]Epoch 1/1 [Train]:  39%|###9      | 98/250 [02:12<03:29,  1.38s/it, loss=0.0809]2025-03-30 22:53:10,408 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:53:10,446 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:53:10,446 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:53:10,962 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:53:11,000 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:53:11,001 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:53:11,503 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:53:11,504 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:53:11,504 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  39%|###9      | 98/250 [02:14<03:29,  1.38s/it, loss=0.0699]Epoch 1/1 [Train]:  40%|###9      | 99/250 [02:14<03:28,  1.38s/it, loss=0.0699]2025-03-30 22:53:11,788 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:53:11,830 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:53:11,830 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:53:12,340 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:53:12,375 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:53:12,375 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:53:12,882 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:53:12,882 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:53:12,882 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  40%|###9      | 99/250 [02:15<03:28,  1.38s/it, loss=0.103] Epoch 1/1 [Train]:  40%|####      | 100/250 [02:15<03:26,  1.38s/it, loss=0.103]2025-03-30 22:53:13,203 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:53:13,250 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:53:13,250 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:53:13,751 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:53:13,789 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:53:13,789 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:53:14,293 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:53:14,293 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:53:14,293 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  40%|####      | 100/250 [02:17<03:26,  1.38s/it, loss=0.105]Epoch 1/1 [Train]:  40%|####      | 101/250 [02:17<03:26,  1.39s/it, loss=0.105]2025-03-30 22:53:14,581 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:53:14,625 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:53:14,625 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:53:15,132 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:53:15,179 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:53:15,179 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:53:15,669 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:53:15,669 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:53:15,669 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  40%|####      | 101/250 [02:18<03:26,  1.39s/it, loss=0.0858]Epoch 1/1 [Train]:  41%|####      | 102/250 [02:18<03:24,  1.38s/it, loss=0.0858]2025-03-30 22:53:15,954 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:53:15,996 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:53:15,996 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:53:16,501 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:53:16,539 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:53:16,539 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:53:17,038 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:53:17,038 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:53:17,039 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  41%|####      | 102/250 [02:19<03:24,  1.38s/it, loss=0.0679]Epoch 1/1 [Train]:  41%|####1     | 103/250 [02:19<03:22,  1.37s/it, loss=0.0679]2025-03-30 22:53:17,306 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:53:17,346 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:53:17,347 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:53:17,857 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:53:17,894 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:53:17,894 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:53:18,406 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:53:18,406 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:53:18,406 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  41%|####1     | 103/250 [02:21<03:22,  1.37s/it, loss=0.087] Epoch 1/1 [Train]:  42%|####1     | 104/250 [02:21<03:21,  1.38s/it, loss=0.087]2025-03-30 22:53:18,698 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:53:18,736 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:53:18,736 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:53:19,247 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:53:19,282 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:53:19,282 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:53:19,785 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:53:19,785 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:53:19,785 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  42%|####1     | 104/250 [02:22<03:21,  1.38s/it, loss=0.063]Epoch 1/1 [Train]:  42%|####2     | 105/250 [02:22<03:19,  1.37s/it, loss=0.063]2025-03-30 22:53:20,084 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:53:20,127 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:53:20,127 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:53:20,639 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:53:20,677 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:53:20,677 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:53:21,179 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:53:21,179 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:53:21,179 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  42%|####2     | 105/250 [02:23<03:19,  1.37s/it, loss=0.0839]Epoch 1/1 [Train]:  42%|####2     | 106/250 [02:23<03:19,  1.38s/it, loss=0.0839]2025-03-30 22:53:21,454 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:53:21,494 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:53:21,494 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:53:22,006 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:53:22,047 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:53:22,048 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:53:22,546 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:53:22,547 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:53:22,547 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  42%|####2     | 106/250 [02:25<03:19,  1.38s/it, loss=0.0567]Epoch 1/1 [Train]:  43%|####2     | 107/250 [02:25<03:16,  1.38s/it, loss=0.0567]2025-03-30 22:53:22,812 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:53:22,854 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:53:22,855 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:53:23,363 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:53:23,399 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:53:23,399 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:53:23,902 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:53:23,902 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:53:23,902 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  43%|####2     | 107/250 [02:26<03:16,  1.38s/it, loss=0.0612]Epoch 1/1 [Train]:  43%|####3     | 108/250 [02:26<03:14,  1.37s/it, loss=0.0612]2025-03-30 22:53:24,189 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:53:24,233 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:53:24,233 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:53:24,739 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:53:24,774 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:53:24,774 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:53:25,279 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:53:25,279 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:53:25,279 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  43%|####3     | 108/250 [02:28<03:14,  1.37s/it, loss=0.0664]Epoch 1/1 [Train]:  44%|####3     | 109/250 [02:28<03:13,  1.37s/it, loss=0.0664]2025-03-30 22:53:25,560 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:53:25,600 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:53:25,600 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:53:26,115 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:53:26,163 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:53:26,163 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:53:26,661 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:53:26,661 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:53:26,661 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  44%|####3     | 109/250 [02:29<03:13,  1.37s/it, loss=0.0834]Epoch 1/1 [Train]:  44%|####4     | 110/250 [02:29<03:12,  1.37s/it, loss=0.0834]2025-03-30 22:53:26,924 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:53:26,967 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:53:26,967 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:53:27,486 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:53:27,523 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:53:27,523 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:53:28,040 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:53:28,040 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:53:28,040 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  44%|####4     | 110/250 [02:30<03:12,  1.37s/it, loss=0.107] Epoch 1/1 [Train]:  44%|####4     | 111/250 [02:30<03:11,  1.37s/it, loss=0.107]2025-03-30 22:53:28,298 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:53:28,335 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:53:28,335 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:53:28,852 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:53:28,896 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:53:28,896 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:53:29,396 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:53:29,396 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:53:29,396 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  44%|####4     | 111/250 [02:32<03:11,  1.37s/it, loss=0.0686]Epoch 1/1 [Train]:  45%|####4     | 112/250 [02:32<03:09,  1.37s/it, loss=0.0686]2025-03-30 22:53:29,693 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:53:29,735 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:53:29,735 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:53:30,248 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:53:30,287 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:53:30,287 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:53:30,794 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:53:30,794 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:53:30,794 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  45%|####4     | 112/250 [02:33<03:09,  1.37s/it, loss=0.0532]Epoch 1/1 [Train]:  45%|####5     | 113/250 [02:33<03:08,  1.38s/it, loss=0.0532]2025-03-30 22:53:31,101 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:53:31,159 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:53:31,159 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:53:31,656 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:53:31,693 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:53:31,693 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:53:32,201 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:53:32,201 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:53:32,201 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  45%|####5     | 113/250 [02:34<03:08,  1.38s/it, loss=0.0593]Epoch 1/1 [Train]:  46%|####5     | 114/250 [02:34<03:08,  1.38s/it, loss=0.0593]2025-03-30 22:53:32,461 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:53:32,502 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:53:32,503 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:53:33,014 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:53:33,055 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:53:33,055 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:53:33,554 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:53:33,554 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:53:33,554 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  46%|####5     | 114/250 [02:36<03:08,  1.38s/it, loss=0.1]   Epoch 1/1 [Train]:  46%|####6     | 115/250 [02:36<03:08,  1.40s/it, loss=0.1]2025-03-30 22:53:33,980 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:53:34,051 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:53:34,051 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:53:34,531 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:53:34,566 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:53:34,567 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:53:35,079 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:53:35,079 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:53:35,079 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  46%|####6     | 115/250 [02:37<03:08,  1.40s/it, loss=0.0615]Epoch 1/1 [Train]:  46%|####6     | 116/250 [02:37<03:10,  1.42s/it, loss=0.0615]2025-03-30 22:53:35,379 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:53:35,425 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:53:35,425 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:53:35,945 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:53:35,997 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:53:35,998 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:53:36,495 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:53:36,495 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:53:36,495 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  46%|####6     | 116/250 [02:39<03:10,  1.42s/it, loss=0.102] Epoch 1/1 [Train]:  47%|####6     | 117/250 [02:39<03:08,  1.41s/it, loss=0.102]2025-03-30 22:53:36,763 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:53:36,805 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:53:36,805 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:53:37,321 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:53:37,356 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:53:37,356 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:53:37,870 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:53:37,870 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:53:37,870 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  47%|####6     | 117/250 [02:40<03:08,  1.41s/it, loss=0.0764]Epoch 1/1 [Train]:  47%|####7     | 118/250 [02:40<03:05,  1.41s/it, loss=0.0764]2025-03-30 22:53:38,168 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:53:38,214 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:53:38,214 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:53:38,721 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:53:38,758 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:53:38,758 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:53:39,272 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:53:39,272 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:53:39,272 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  47%|####7     | 118/250 [02:42<03:05,  1.41s/it, loss=0.0629]Epoch 1/1 [Train]:  48%|####7     | 119/250 [02:42<03:03,  1.40s/it, loss=0.0629]2025-03-30 22:53:39,561 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:53:39,601 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:53:39,601 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:53:40,116 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:53:40,152 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:53:40,152 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:53:40,666 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:53:40,666 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:53:40,666 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  48%|####7     | 119/250 [02:43<03:03,  1.40s/it, loss=0.0882]Epoch 1/1 [Train]:  48%|####8     | 120/250 [02:43<03:02,  1.40s/it, loss=0.0882]2025-03-30 22:53:40,950 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:53:40,990 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:53:40,990 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:53:41,512 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:53:41,549 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:53:41,549 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:53:42,062 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:53:42,062 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:53:42,062 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  48%|####8     | 120/250 [02:44<03:02,  1.40s/it, loss=0.109] Epoch 1/1 [Train]:  48%|####8     | 121/250 [02:44<03:00,  1.40s/it, loss=0.109]2025-03-30 22:53:42,328 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:53:42,368 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:53:42,368 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:53:42,902 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:53:42,943 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:53:42,944 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:53:43,463 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:53:43,464 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:53:43,464 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  48%|####8     | 121/250 [02:46<03:00,  1.40s/it, loss=0.13] Epoch 1/1 [Train]:  49%|####8     | 122/250 [02:46<02:58,  1.40s/it, loss=0.13]2025-03-30 22:53:43,739 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:53:43,780 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:53:43,780 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:53:44,296 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:53:44,330 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:53:44,330 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:53:44,842 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:53:44,842 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:53:44,842 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  49%|####8     | 122/250 [02:47<02:58,  1.40s/it, loss=0.0761]Epoch 1/1 [Train]:  49%|####9     | 123/250 [02:47<02:57,  1.39s/it, loss=0.0761]2025-03-30 22:53:45,133 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:53:45,178 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:53:45,178 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:53:45,692 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:53:45,728 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:53:45,728 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:53:46,247 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:53:46,247 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:53:46,247 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  49%|####9     | 123/250 [02:49<02:57,  1.39s/it, loss=0.073] Epoch 1/1 [Train]:  50%|####9     | 124/250 [02:49<02:55,  1.40s/it, loss=0.073]2025-03-30 22:53:46,519 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:53:46,564 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:53:46,564 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:53:47,076 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:53:47,112 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:53:47,112 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:53:47,635 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:53:47,635 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:53:47,635 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  50%|####9     | 124/250 [02:50<02:55,  1.40s/it, loss=0.0988]Epoch 1/1 [Train]:  50%|#####     | 125/250 [02:50<02:54,  1.40s/it, loss=0.0988]2025-03-30 22:53:47,925 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:53:47,964 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:53:47,964 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:53:48,501 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:53:48,571 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:53:48,571 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:53:49,061 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:53:49,061 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:53:49,061 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  50%|#####     | 125/250 [02:51<02:54,  1.40s/it, loss=0.112] Epoch 1/1 [Train]:  50%|#####     | 126/250 [02:51<02:54,  1.41s/it, loss=0.112]2025-03-30 22:53:49,353 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:53:49,397 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:53:49,397 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:53:49,921 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:53:49,957 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:53:49,957 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:53:50,480 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:53:50,480 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:53:50,480 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  50%|#####     | 126/250 [02:53<02:54,  1.41s/it, loss=0.0556]Epoch 1/1 [Train]:  51%|#####     | 127/250 [02:53<02:53,  1.41s/it, loss=0.0556]2025-03-30 22:53:50,777 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:53:50,821 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:53:50,821 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:53:51,346 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:53:51,386 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:53:51,386 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:53:51,906 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:53:51,906 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:53:51,906 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  51%|#####     | 127/250 [02:54<02:53,  1.41s/it, loss=0.0809]Epoch 1/1 [Train]:  51%|#####1    | 128/250 [02:54<02:52,  1.42s/it, loss=0.0809]2025-03-30 22:53:52,232 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:53:52,276 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:53:52,277 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:53:52,791 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:53:52,828 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:53:52,828 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:53:53,349 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:53:53,349 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:53:53,349 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  51%|#####1    | 128/250 [02:56<02:52,  1.42s/it, loss=0.0686]Epoch 1/1 [Train]:  52%|#####1    | 129/250 [02:56<02:51,  1.42s/it, loss=0.0686]2025-03-30 22:53:53,620 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:53:53,663 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:53:53,663 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:53:54,191 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:53:54,227 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:53:54,227 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:53:54,752 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:53:54,752 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:53:54,752 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  52%|#####1    | 129/250 [02:57<02:51,  1.42s/it, loss=0.0683]Epoch 1/1 [Train]:  52%|#####2    | 130/250 [02:57<02:49,  1.41s/it, loss=0.0683]2025-03-30 22:53:55,038 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:53:55,079 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:53:55,079 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:53:55,608 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:53:55,649 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:53:55,649 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:53:56,169 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:53:56,169 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:53:56,169 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  52%|#####2    | 130/250 [02:58<02:49,  1.41s/it, loss=0.0523]Epoch 1/1 [Train]:  52%|#####2    | 131/250 [02:58<02:48,  1.42s/it, loss=0.0523]2025-03-30 22:53:56,483 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:53:56,533 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:53:56,533 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:53:57,052 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:53:57,095 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:53:57,096 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:53:57,602 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:53:57,602 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:53:57,602 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  52%|#####2    | 131/250 [03:00<02:48,  1.42s/it, loss=0.0597]Epoch 1/1 [Train]:  53%|#####2    | 132/250 [03:00<02:48,  1.42s/it, loss=0.0597]2025-03-30 22:53:57,893 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:53:57,936 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:53:57,936 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:53:58,464 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:53:58,500 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:53:58,500 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:53:59,027 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:53:59,027 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:53:59,027 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  53%|#####2    | 132/250 [03:01<02:48,  1.42s/it, loss=0.0913]Epoch 1/1 [Train]:  53%|#####3    | 133/250 [03:01<02:46,  1.42s/it, loss=0.0913]2025-03-30 22:53:59,324 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:53:59,364 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:53:59,364 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:53:59,898 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:53:59,933 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:53:59,933 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:54:00,459 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:54:00,459 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:54:00,459 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  53%|#####3    | 133/250 [03:03<02:46,  1.42s/it, loss=0.0772]Epoch 1/1 [Train]:  54%|#####3    | 134/250 [03:03<02:45,  1.43s/it, loss=0.0772]2025-03-30 22:54:00,757 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:54:00,802 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:54:00,803 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:54:01,331 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:54:01,367 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:54:01,368 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:54:01,893 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:54:01,893 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:54:01,893 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  54%|#####3    | 134/250 [03:04<02:45,  1.43s/it, loss=0.0996]Epoch 1/1 [Train]:  54%|#####4    | 135/250 [03:04<02:44,  1.43s/it, loss=0.0996]2025-03-30 22:54:02,187 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:54:02,231 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:54:02,231 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:54:02,759 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:54:02,797 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:54:02,797 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:54:03,321 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:54:03,322 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:54:03,322 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  54%|#####4    | 135/250 [03:06<02:44,  1.43s/it, loss=0.0937]Epoch 1/1 [Train]:  54%|#####4    | 136/250 [03:06<02:43,  1.43s/it, loss=0.0937]2025-03-30 22:54:03,633 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:54:03,675 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:54:03,676 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:54:04,206 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:54:04,242 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:54:04,242 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:54:04,767 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:54:04,767 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:54:04,767 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  54%|#####4    | 136/250 [03:07<02:43,  1.43s/it, loss=0.0736]Epoch 1/1 [Train]:  55%|#####4    | 137/250 [03:07<02:41,  1.43s/it, loss=0.0736]2025-03-30 22:54:05,074 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:54:05,125 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:54:05,126 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:54:05,649 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:54:05,690 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:54:05,690 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:54:06,210 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:54:06,211 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:54:06,211 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  55%|#####4    | 137/250 [03:09<02:41,  1.43s/it, loss=0.0685]Epoch 1/1 [Train]:  55%|#####5    | 138/250 [03:09<02:41,  1.44s/it, loss=0.0685]2025-03-30 22:54:06,526 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:54:06,572 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:54:06,572 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:54:07,088 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:54:07,130 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:54:07,130 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:54:07,638 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:54:07,638 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:54:07,638 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  55%|#####5    | 138/250 [03:10<02:41,  1.44s/it, loss=0.0795]Epoch 1/1 [Train]:  56%|#####5    | 139/250 [03:10<02:38,  1.43s/it, loss=0.0795]2025-03-30 22:54:07,922 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:54:07,978 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:54:07,978 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:54:08,496 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:54:08,535 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:54:08,535 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:54:09,061 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:54:09,061 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:54:09,061 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  56%|#####5    | 139/250 [03:11<02:38,  1.43s/it, loss=0.0635]Epoch 1/1 [Train]:  56%|#####6    | 140/250 [03:11<02:37,  1.43s/it, loss=0.0635]2025-03-30 22:54:09,387 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:54:09,435 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:54:09,436 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:54:09,962 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:54:10,001 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:54:10,001 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:54:10,526 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:54:10,526 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:54:10,526 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  56%|#####6    | 140/250 [03:13<02:37,  1.43s/it, loss=0.0895]Epoch 1/1 [Train]:  56%|#####6    | 141/250 [03:13<02:36,  1.43s/it, loss=0.0895]2025-03-30 22:54:10,791 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:54:10,838 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:54:10,839 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:54:11,365 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:54:11,400 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:54:11,400 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:54:11,928 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:54:11,928 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:54:11,928 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  56%|#####6    | 141/250 [03:14<02:36,  1.43s/it, loss=0.0996]Epoch 1/1 [Train]:  57%|#####6    | 142/250 [03:14<02:34,  1.43s/it, loss=0.0996]2025-03-30 22:54:12,218 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:54:12,259 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:54:12,259 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:54:12,791 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:54:12,827 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:54:12,827 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:54:13,354 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:54:13,354 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:54:13,354 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  57%|#####6    | 142/250 [03:16<02:34,  1.43s/it, loss=0.06]  Epoch 1/1 [Train]:  57%|#####7    | 143/250 [03:16<02:33,  1.43s/it, loss=0.06]2025-03-30 22:54:13,637 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:54:13,678 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:54:13,678 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:54:14,211 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:54:14,248 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:54:14,248 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:54:14,773 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:54:14,774 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:54:14,774 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  57%|#####7    | 143/250 [03:17<02:33,  1.43s/it, loss=0.0529]Epoch 1/1 [Train]:  58%|#####7    | 144/250 [03:17<02:31,  1.43s/it, loss=0.0529]2025-03-30 22:54:15,074 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:54:15,118 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:54:15,118 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:54:15,647 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:54:15,683 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:54:15,683 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:54:16,210 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:54:16,210 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:54:16,210 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  58%|#####7    | 144/250 [03:19<02:31,  1.43s/it, loss=0.0648]Epoch 1/1 [Train]:  58%|#####8    | 145/250 [03:19<02:29,  1.43s/it, loss=0.0648]2025-03-30 22:54:16,497 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:54:16,548 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:54:16,548 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:54:17,059 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:54:17,097 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:54:17,098 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:54:17,609 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:54:17,609 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:54:17,609 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  58%|#####8    | 145/250 [03:20<02:29,  1.43s/it, loss=0.0813]Epoch 1/1 [Train]:  58%|#####8    | 146/250 [03:20<02:27,  1.42s/it, loss=0.0813]2025-03-30 22:54:17,922 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:54:17,986 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:54:17,986 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:54:18,477 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:54:18,514 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:54:18,514 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:54:19,033 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:54:19,033 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:54:19,033 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  58%|#####8    | 146/250 [03:21<02:27,  1.42s/it, loss=0.0703]Epoch 1/1 [Train]:  59%|#####8    | 147/250 [03:21<02:26,  1.42s/it, loss=0.0703]2025-03-30 22:54:19,349 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:54:19,402 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:54:19,402 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:54:19,909 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:54:19,945 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:54:19,945 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:54:20,468 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:54:20,468 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:54:20,468 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  59%|#####8    | 147/250 [03:23<02:26,  1.42s/it, loss=0.0734]Epoch 1/1 [Train]:  59%|#####9    | 148/250 [03:23<02:25,  1.42s/it, loss=0.0734]2025-03-30 22:54:20,732 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:54:20,773 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:54:20,773 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:54:21,293 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:54:21,329 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:54:21,330 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:54:21,845 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:54:21,845 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:54:21,845 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  59%|#####9    | 148/250 [03:24<02:25,  1.42s/it, loss=0.0617]Epoch 1/1 [Train]:  60%|#####9    | 149/250 [03:24<02:22,  1.41s/it, loss=0.0617]2025-03-30 22:54:22,136 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:54:22,186 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:54:22,186 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:54:22,733 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:54:22,796 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:54:22,796 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:54:23,300 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:54:23,300 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:54:23,300 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  60%|#####9    | 149/250 [03:26<02:22,  1.41s/it, loss=0.0543]Epoch 1/1 [Train]:  60%|######    | 150/250 [03:26<02:22,  1.43s/it, loss=0.0543]2025-03-30 22:54:23,634 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:54:23,685 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:54:23,685 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:54:24,197 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:54:24,232 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:54:24,233 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:54:24,749 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:54:24,749 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:54:24,749 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  60%|######    | 150/250 [03:27<02:22,  1.43s/it, loss=0.0588]Epoch 1/1 [Train]:  60%|######    | 151/250 [03:27<02:21,  1.43s/it, loss=0.0588]2025-03-30 22:54:25,052 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:54:25,093 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:54:25,093 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:54:25,614 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:54:25,652 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:54:25,652 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:54:26,174 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:54:26,175 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:54:26,175 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  60%|######    | 151/250 [03:28<02:21,  1.43s/it, loss=0.0577]Epoch 1/1 [Train]:  61%|######    | 152/250 [03:28<02:20,  1.43s/it, loss=0.0577]2025-03-30 22:54:26,544 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:54:26,599 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:54:26,599 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:54:27,111 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:54:27,162 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:54:27,162 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:54:27,671 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:54:27,671 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:54:27,671 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  61%|######    | 152/250 [03:30<02:20,  1.43s/it, loss=0.0446]Epoch 1/1 [Train]:  61%|######1   | 153/250 [03:30<02:21,  1.46s/it, loss=0.0446]2025-03-30 22:54:27,982 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:54:28,026 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:54:28,026 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:54:28,552 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:54:28,592 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:54:28,592 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:54:29,113 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:54:29,114 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:54:29,114 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  61%|######1   | 153/250 [03:31<02:21,  1.46s/it, loss=0.052] Epoch 1/1 [Train]:  62%|######1   | 154/250 [03:31<02:18,  1.45s/it, loss=0.052]2025-03-30 22:54:29,404 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:54:29,450 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:54:29,450 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:54:29,974 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:54:30,009 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:54:30,009 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:54:30,534 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:54:30,534 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:54:30,534 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  62%|######1   | 154/250 [03:33<02:18,  1.45s/it, loss=0.0692]Epoch 1/1 [Train]:  62%|######2   | 155/250 [03:33<02:16,  1.44s/it, loss=0.0692]2025-03-30 22:54:30,853 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:54:30,916 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:54:30,916 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:54:31,417 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:54:31,455 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:54:31,455 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:54:31,979 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:54:31,979 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:54:31,979 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  62%|######2   | 155/250 [03:34<02:16,  1.44s/it, loss=0.074] Epoch 1/1 [Train]:  62%|######2   | 156/250 [03:34<02:15,  1.44s/it, loss=0.074]2025-03-30 22:54:32,265 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:54:32,304 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:54:32,305 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:54:32,834 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:54:32,876 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:54:32,876 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:54:33,395 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:54:33,395 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:54:33,395 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  62%|######2   | 156/250 [03:36<02:15,  1.44s/it, loss=0.0739]Epoch 1/1 [Train]:  63%|######2   | 157/250 [03:36<02:13,  1.43s/it, loss=0.0739]2025-03-30 22:54:33,669 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:54:33,710 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:54:33,710 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:54:34,241 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:54:34,276 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:54:34,276 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:54:34,801 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:54:34,801 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:54:34,801 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  63%|######2   | 157/250 [03:37<02:13,  1.43s/it, loss=0.0611]Epoch 1/1 [Train]:  63%|######3   | 158/250 [03:37<02:10,  1.42s/it, loss=0.0611]2025-03-30 22:54:35,111 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:54:35,161 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:54:35,161 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:54:35,677 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:54:35,722 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:54:35,723 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:54:36,238 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:54:36,238 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:54:36,238 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  63%|######3   | 158/250 [03:39<02:10,  1.42s/it, loss=0.067] Epoch 1/1 [Train]:  64%|######3   | 159/250 [03:39<02:09,  1.42s/it, loss=0.067]2025-03-30 22:54:36,522 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:54:36,563 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:54:36,563 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:54:37,086 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:54:37,122 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:54:37,122 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:54:37,646 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:54:37,646 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:54:37,646 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  64%|######3   | 159/250 [03:40<02:09,  1.42s/it, loss=0.0961]Epoch 1/1 [Train]:  64%|######4   | 160/250 [03:40<02:08,  1.43s/it, loss=0.0961]2025-03-30 22:54:37,942 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:54:37,985 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:54:37,986 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:54:38,513 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:54:38,548 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:54:38,548 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:54:39,074 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:54:39,074 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:54:39,074 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  64%|######4   | 160/250 [03:41<02:08,  1.43s/it, loss=0.065] Epoch 1/1 [Train]:  64%|######4   | 161/250 [03:41<02:06,  1.42s/it, loss=0.065]2025-03-30 22:54:39,356 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:54:39,399 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:54:39,399 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:54:39,925 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:54:39,966 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:54:39,966 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:54:40,485 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:54:40,485 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:54:40,486 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  64%|######4   | 161/250 [03:43<02:06,  1.42s/it, loss=0.0896]Epoch 1/1 [Train]:  65%|######4   | 162/250 [03:43<02:05,  1.42s/it, loss=0.0896]2025-03-30 22:54:40,856 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:54:40,907 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:54:40,907 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:54:41,446 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:54:41,482 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:54:41,483 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:54:42,021 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:54:42,021 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:54:42,021 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  65%|######4   | 162/250 [03:44<02:05,  1.42s/it, loss=0.0512]Epoch 1/1 [Train]:  65%|######5   | 163/250 [03:44<02:06,  1.46s/it, loss=0.0512]2025-03-30 22:54:42,358 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:54:42,417 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:54:42,417 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:54:42,928 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:54:42,964 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:54:42,964 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:54:43,487 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:54:43,488 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:54:43,488 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  65%|######5   | 163/250 [03:46<02:06,  1.46s/it, loss=0.0682]Epoch 1/1 [Train]:  66%|######5   | 164/250 [03:46<02:05,  1.46s/it, loss=0.0682]2025-03-30 22:54:43,785 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:54:43,827 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:54:43,827 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:54:44,369 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:54:44,405 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:54:44,406 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:54:44,945 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:54:44,945 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:54:44,945 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  66%|######5   | 164/250 [03:47<02:05,  1.46s/it, loss=0.0492]Epoch 1/1 [Train]:  66%|######6   | 165/250 [03:47<02:03,  1.46s/it, loss=0.0492]2025-03-30 22:54:45,236 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:54:45,279 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:54:45,279 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:54:45,820 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:54:45,855 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:54:45,856 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:54:46,393 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:54:46,394 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:54:46,394 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  66%|######6   | 165/250 [03:49<02:03,  1.46s/it, loss=0.0854]Epoch 1/1 [Train]:  66%|######6   | 166/250 [03:49<02:02,  1.46s/it, loss=0.0854]2025-03-30 22:54:46,682 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:54:46,723 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:54:46,723 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:54:47,266 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:54:47,302 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:54:47,302 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:54:47,841 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:54:47,842 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:54:47,842 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  66%|######6   | 166/250 [03:50<02:02,  1.46s/it, loss=0.0773]Epoch 1/1 [Train]:  67%|######6   | 167/250 [03:50<02:00,  1.45s/it, loss=0.0773]2025-03-30 22:54:48,143 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:54:48,186 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:54:48,186 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:54:48,729 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:54:48,766 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:54:48,766 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:54:49,303 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:54:49,304 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:54:49,304 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  67%|######6   | 167/250 [03:52<02:00,  1.45s/it, loss=0.0441]Epoch 1/1 [Train]:  67%|######7   | 168/250 [03:52<01:59,  1.45s/it, loss=0.0441]2025-03-30 22:54:49,588 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:54:49,628 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:54:49,629 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:54:50,173 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:54:50,209 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:54:50,209 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:54:50,747 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:54:50,748 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:54:50,748 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  67%|######7   | 168/250 [03:53<01:59,  1.45s/it, loss=0.0482]Epoch 1/1 [Train]:  68%|######7   | 169/250 [03:53<01:57,  1.45s/it, loss=0.0482]2025-03-30 22:54:51,021 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:54:51,061 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:54:51,061 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:54:51,598 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:54:51,634 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:54:51,634 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:54:52,156 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:54:52,156 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:54:52,156 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  68%|######7   | 169/250 [03:54<01:57,  1.45s/it, loss=0.0575]Epoch 1/1 [Train]:  68%|######8   | 170/250 [03:54<01:55,  1.44s/it, loss=0.0575]2025-03-30 22:54:52,472 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:54:52,528 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:54:52,528 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:54:53,037 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:54:53,080 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:54:53,080 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:54:53,615 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:54:53,615 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:54:53,616 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  68%|######8   | 170/250 [03:56<01:55,  1.44s/it, loss=0.0948]Epoch 1/1 [Train]:  68%|######8   | 171/250 [03:56<01:54,  1.45s/it, loss=0.0948]2025-03-30 22:54:53,913 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:54:53,952 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:54:53,952 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:54:54,486 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:54:54,522 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:54:54,522 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:54:55,047 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:54:55,047 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:54:55,047 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  68%|######8   | 171/250 [03:57<01:54,  1.45s/it, loss=0.0742]Epoch 1/1 [Train]:  69%|######8   | 172/250 [03:57<01:52,  1.44s/it, loss=0.0742]2025-03-30 22:54:55,344 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:54:55,383 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:54:55,383 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:54:55,909 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:54:55,945 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:54:55,946 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:54:56,467 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:54:56,467 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:54:56,467 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  69%|######8   | 172/250 [03:59<01:52,  1.44s/it, loss=0.0574]Epoch 1/1 [Train]:  69%|######9   | 173/250 [03:59<01:50,  1.43s/it, loss=0.0574]2025-03-30 22:54:56,752 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:54:56,792 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:54:56,792 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:54:57,321 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:54:57,360 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:54:57,361 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:54:57,881 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:54:57,881 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:54:57,881 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  69%|######9   | 173/250 [04:00<01:50,  1.43s/it, loss=0.0543]Epoch 1/1 [Train]:  70%|######9   | 174/250 [04:00<01:48,  1.43s/it, loss=0.0543]2025-03-30 22:54:58,165 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
2025-03-30 22:54:58,206 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:54:58,206 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:54:58,734 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:54:58,773 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:54:58,773 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:54:59,293 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:54:59,293 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:54:59,293 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  70%|######9   | 174/250 [04:02<01:48,  1.43s/it, loss=0.0865]Epoch 1/1 [Train]:  70%|#######   | 175/250 [04:02<01:46,  1.42s/it, loss=0.0865]2025-03-30 22:54:59,663 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:54:59,729 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:54:59,729 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:55:00,225 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:55:00,261 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:55:00,262 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:55:00,783 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:55:00,783 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:55:00,783 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  70%|#######   | 175/250 [04:03<01:46,  1.42s/it, loss=0.053] Epoch 1/1 [Train]:  70%|#######   | 176/250 [04:03<01:46,  1.44s/it, loss=0.053]2025-03-30 22:55:01,078 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:55:01,122 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:55:01,123 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:55:01,647 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:55:01,683 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:55:01,683 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:55:02,216 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:55:02,216 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:55:02,216 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  70%|#######   | 176/250 [04:05<01:46,  1.44s/it, loss=0.051]Epoch 1/1 [Train]:  71%|#######   | 177/250 [04:05<01:45,  1.44s/it, loss=0.051]2025-03-30 22:55:02,579 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:55:02,646 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:55:02,646 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:55:03,149 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:55:03,197 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:55:03,197 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:55:03,711 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:55:03,711 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:55:03,711 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  71%|#######   | 177/250 [04:06<01:45,  1.44s/it, loss=0.0606]Epoch 1/1 [Train]:  71%|#######1  | 178/250 [04:06<01:44,  1.46s/it, loss=0.0606]2025-03-30 22:55:04,015 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:55:04,056 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:55:04,056 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:55:04,588 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:55:04,632 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:55:04,633 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:55:05,148 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:55:05,148 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:55:05,149 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  71%|#######1  | 178/250 [04:07<01:44,  1.46s/it, loss=0.0453]Epoch 1/1 [Train]:  72%|#######1  | 179/250 [04:07<01:42,  1.45s/it, loss=0.0453]2025-03-30 22:55:05,463 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:55:05,523 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:55:05,524 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:55:06,031 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:55:06,067 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:55:06,067 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:55:06,594 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:55:06,594 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:55:06,595 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  72%|#######1  | 179/250 [04:09<01:42,  1.45s/it, loss=0.0926]Epoch 1/1 [Train]:  72%|#######2  | 180/250 [04:09<01:41,  1.45s/it, loss=0.0926]2025-03-30 22:55:06,889 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:55:06,928 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:55:06,928 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:55:07,473 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:55:07,510 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:55:07,511 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:55:08,046 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:55:08,046 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:55:08,046 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  72%|#######2  | 180/250 [04:10<01:41,  1.45s/it, loss=0.0859]Epoch 1/1 [Train]:  72%|#######2  | 181/250 [04:10<01:40,  1.45s/it, loss=0.0859]2025-03-30 22:55:08,346 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:55:08,390 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:55:08,390 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:55:08,931 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:55:08,968 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:55:08,968 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:55:09,505 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:55:09,505 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:55:09,505 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  72%|#######2  | 181/250 [04:12<01:40,  1.45s/it, loss=0.071] Epoch 1/1 [Train]:  73%|#######2  | 182/250 [04:12<01:38,  1.45s/it, loss=0.071]2025-03-30 22:55:09,777 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:55:09,819 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:55:09,819 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:55:10,363 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:55:10,402 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:55:10,402 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:55:10,936 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:55:10,937 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:55:10,937 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  73%|#######2  | 182/250 [04:13<01:38,  1.45s/it, loss=0.0862]Epoch 1/1 [Train]:  73%|#######3  | 183/250 [04:13<01:37,  1.45s/it, loss=0.0862]2025-03-30 22:55:11,231 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:55:11,277 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:55:11,277 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:55:11,814 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:55:11,849 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:55:11,850 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:55:12,387 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:55:12,387 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:55:12,387 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  73%|#######3  | 183/250 [04:15<01:37,  1.45s/it, loss=0.0543]Epoch 1/1 [Train]:  74%|#######3  | 184/250 [04:15<01:35,  1.45s/it, loss=0.0543]2025-03-30 22:55:12,674 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:55:12,713 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:55:12,713 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:55:13,258 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:55:13,293 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:55:13,293 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:55:13,832 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:55:13,833 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:55:13,833 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  74%|#######3  | 184/250 [04:16<01:35,  1.45s/it, loss=0.0772]Epoch 1/1 [Train]:  74%|#######4  | 185/250 [04:16<01:34,  1.45s/it, loss=0.0772]2025-03-30 22:55:14,116 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:55:14,153 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:55:14,153 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:55:14,699 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:55:14,736 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:55:14,736 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:55:15,273 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:55:15,274 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:55:15,274 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  74%|#######4  | 185/250 [04:18<01:34,  1.45s/it, loss=0.0576]Epoch 1/1 [Train]:  74%|#######4  | 186/250 [04:18<01:32,  1.45s/it, loss=0.0576]2025-03-30 22:55:15,572 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:55:15,617 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:55:15,617 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:55:16,156 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:55:16,191 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:55:16,191 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:55:16,730 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:55:16,730 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:55:16,730 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  74%|#######4  | 186/250 [04:19<01:32,  1.45s/it, loss=0.0823]Epoch 1/1 [Train]:  75%|#######4  | 187/250 [04:19<01:31,  1.45s/it, loss=0.0823]2025-03-30 22:55:17,013 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:55:17,051 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:55:17,051 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:55:17,595 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:55:17,631 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:55:17,631 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:55:18,169 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:55:18,169 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:55:18,169 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  75%|#######4  | 187/250 [04:20<01:31,  1.45s/it, loss=0.0653]Epoch 1/1 [Train]:  75%|#######5  | 188/250 [04:20<01:29,  1.44s/it, loss=0.0653]2025-03-30 22:55:18,497 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:55:18,559 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:55:18,560 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:55:19,066 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:55:19,104 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:55:19,104 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:55:19,625 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:55:19,626 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:55:19,626 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  75%|#######5  | 188/250 [04:22<01:29,  1.44s/it, loss=0.0596]Epoch 1/1 [Train]:  76%|#######5  | 189/250 [04:22<01:28,  1.45s/it, loss=0.0596]2025-03-30 22:55:19,919 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:55:19,961 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:55:19,961 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:55:20,482 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:55:20,520 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:55:20,520 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:55:21,050 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:55:21,050 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:55:21,050 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  76%|#######5  | 189/250 [04:23<01:28,  1.45s/it, loss=0.0497]Epoch 1/1 [Train]:  76%|#######6  | 190/250 [04:23<01:26,  1.44s/it, loss=0.0497]2025-03-30 22:55:21,339 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:55:21,376 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:55:21,377 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:55:21,906 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:55:21,943 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:55:21,944 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:55:22,467 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:55:22,467 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:55:22,467 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  76%|#######6  | 190/250 [04:25<01:26,  1.44s/it, loss=0.0999]Epoch 1/1 [Train]:  76%|#######6  | 191/250 [04:25<01:24,  1.43s/it, loss=0.0999]2025-03-30 22:55:22,756 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:55:22,796 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:55:22,796 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:55:23,329 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:55:23,365 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:55:23,365 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:55:23,892 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:55:23,893 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:55:23,893 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  76%|#######6  | 191/250 [04:26<01:24,  1.43s/it, loss=0.0719]Epoch 1/1 [Train]:  77%|#######6  | 192/250 [04:26<01:23,  1.43s/it, loss=0.0719]2025-03-30 22:55:24,181 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:55:24,227 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:55:24,227 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:55:24,752 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:55:24,787 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:55:24,787 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:55:25,315 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:55:25,316 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:55:25,316 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  77%|#######6  | 192/250 [04:28<01:23,  1.43s/it, loss=0.0538]Epoch 1/1 [Train]:  77%|#######7  | 193/250 [04:28<01:21,  1.43s/it, loss=0.0538]2025-03-30 22:55:25,640 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:55:25,698 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:55:25,699 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:55:26,211 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:55:26,248 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:55:26,248 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:55:26,790 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:55:26,790 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:55:26,791 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  77%|#######7  | 193/250 [04:29<01:21,  1.43s/it, loss=0.0435]Epoch 1/1 [Train]:  78%|#######7  | 194/250 [04:29<01:20,  1.44s/it, loss=0.0435]2025-03-30 22:55:27,086 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:55:27,134 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:55:27,134 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:55:27,660 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:55:27,702 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:55:27,702 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:55:28,222 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:55:28,223 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:55:28,223 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  78%|#######7  | 194/250 [04:31<01:20,  1.44s/it, loss=0.0607]Epoch 1/1 [Train]:  78%|#######8  | 195/250 [04:31<01:19,  1.45s/it, loss=0.0607]2025-03-30 22:55:28,589 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:55:28,634 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:55:28,634 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:55:29,155 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:55:29,197 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:55:29,197 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:55:29,726 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:55:29,726 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:55:29,726 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  78%|#######8  | 195/250 [04:32<01:19,  1.45s/it, loss=0.0619]Epoch 1/1 [Train]:  78%|#######8  | 196/250 [04:32<01:18,  1.45s/it, loss=0.0619]2025-03-30 22:55:30,027 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:55:30,078 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:55:30,078 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:55:30,605 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:55:30,643 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:55:30,643 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:55:31,172 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:55:31,172 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:55:31,172 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  78%|#######8  | 196/250 [04:33<01:18,  1.45s/it, loss=0.051] Epoch 1/1 [Train]:  79%|#######8  | 197/250 [04:33<01:17,  1.45s/it, loss=0.051]2025-03-30 22:55:31,474 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:55:31,519 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:55:31,520 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:55:32,053 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:55:32,091 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:55:32,091 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:55:32,621 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:55:32,621 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:55:32,621 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  79%|#######8  | 197/250 [04:35<01:17,  1.45s/it, loss=0.0559]Epoch 1/1 [Train]:  79%|#######9  | 198/250 [04:35<01:15,  1.45s/it, loss=0.0559]2025-03-30 22:55:32,968 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:55:33,028 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:55:33,028 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:55:33,548 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:55:33,592 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:55:33,592 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:55:34,116 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:55:34,116 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:55:34,116 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  79%|#######9  | 198/250 [04:36<01:15,  1.45s/it, loss=0.0533]Epoch 1/1 [Train]:  80%|#######9  | 199/250 [04:36<01:14,  1.47s/it, loss=0.0533]2025-03-30 22:55:34,420 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:55:34,466 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:55:34,466 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:55:34,996 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:55:35,035 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:55:35,036 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:55:35,563 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:55:35,564 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:55:35,564 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  80%|#######9  | 199/250 [04:38<01:14,  1.47s/it, loss=0.0617]Epoch 1/1 [Train]:  80%|########  | 200/250 [04:38<01:13,  1.47s/it, loss=0.0617]2025-03-30 22:55:35,905 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:55:35,954 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:55:35,954 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:55:36,488 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:55:36,540 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:55:36,540 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:55:37,065 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:55:37,065 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:55:37,065 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  80%|########  | 200/250 [04:39<01:13,  1.47s/it, loss=0.0698]Epoch 1/1 [Train]:  80%|########  | 201/250 [04:39<01:12,  1.47s/it, loss=0.0698]2025-03-30 22:55:37,359 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:55:37,411 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:55:37,411 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:55:37,931 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:55:37,973 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:55:37,973 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:55:38,504 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:55:38,504 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:55:38,504 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  80%|########  | 201/250 [04:41<01:12,  1.47s/it, loss=0.079] Epoch 1/1 [Train]:  81%|########  | 202/250 [04:41<01:10,  1.47s/it, loss=0.079]2025-03-30 22:55:38,833 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:55:38,879 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:55:38,879 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:55:39,414 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:55:39,450 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:55:39,450 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:55:39,999 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:55:39,999 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:55:39,999 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  81%|########  | 202/250 [04:42<01:10,  1.47s/it, loss=0.066]Epoch 1/1 [Train]:  81%|########1 | 203/250 [04:42<01:09,  1.47s/it, loss=0.066]2025-03-30 22:55:40,320 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:55:40,380 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:55:40,380 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:55:40,915 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:55:40,951 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:55:40,951 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:55:41,499 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:55:41,500 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:55:41,500 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  81%|########1 | 203/250 [04:44<01:09,  1.47s/it, loss=0.0697]Epoch 1/1 [Train]:  82%|########1 | 204/250 [04:44<01:07,  1.48s/it, loss=0.0697]2025-03-30 22:55:41,794 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:55:41,838 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:55:41,839 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:55:42,389 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:55:42,426 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:55:42,426 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:55:42,974 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:55:42,974 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:55:42,974 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  82%|########1 | 204/250 [04:45<01:07,  1.48s/it, loss=0.0627]Epoch 1/1 [Train]:  82%|########2 | 205/250 [04:45<01:06,  1.48s/it, loss=0.0627]2025-03-30 22:55:43,303 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:55:43,348 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:55:43,348 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:55:43,880 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:55:43,918 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:55:43,918 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:55:44,447 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:55:44,447 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:55:44,447 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  82%|########2 | 205/250 [04:47<01:06,  1.48s/it, loss=0.0524]Epoch 1/1 [Train]:  82%|########2 | 206/250 [04:47<01:05,  1.48s/it, loss=0.0524]2025-03-30 22:55:44,766 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:55:44,817 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:55:44,817 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:55:45,347 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:55:45,416 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:55:45,416 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:55:45,919 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:55:45,920 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:55:45,920 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  82%|########2 | 206/250 [04:48<01:05,  1.48s/it, loss=0.0604]Epoch 1/1 [Train]:  83%|########2 | 207/250 [04:48<01:03,  1.48s/it, loss=0.0604]2025-03-30 22:55:46,241 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:55:46,297 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:55:46,298 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:55:46,824 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:55:46,865 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:55:46,865 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:55:47,395 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:55:47,395 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:55:47,395 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  83%|########2 | 207/250 [04:50<01:03,  1.48s/it, loss=0.0907]Epoch 1/1 [Train]:  83%|########3 | 208/250 [04:50<01:01,  1.48s/it, loss=0.0907]2025-03-30 22:55:47,712 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:55:47,757 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:55:47,757 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:55:48,296 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:55:48,350 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:55:48,350 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:55:48,868 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:55:48,868 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:55:48,868 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  83%|########3 | 208/250 [04:51<01:01,  1.48s/it, loss=0.0542]Epoch 1/1 [Train]:  84%|########3 | 209/250 [04:51<01:01,  1.49s/it, loss=0.0542]2025-03-30 22:55:49,280 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:55:49,337 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:55:49,338 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:55:49,854 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:55:49,894 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:55:49,894 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:55:50,439 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:55:50,439 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:55:50,439 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  84%|########3 | 209/250 [04:53<01:01,  1.49s/it, loss=0.0664]Epoch 1/1 [Train]:  84%|########4 | 210/250 [04:53<00:59,  1.50s/it, loss=0.0664]2025-03-30 22:55:50,728 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:55:50,774 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:55:50,774 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:55:51,329 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:55:51,365 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:55:51,365 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:55:51,914 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:55:51,914 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:55:51,914 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  84%|########4 | 210/250 [04:54<00:59,  1.50s/it, loss=0.0651]Epoch 1/1 [Train]:  84%|########4 | 211/250 [04:54<00:58,  1.49s/it, loss=0.0651]2025-03-30 22:55:52,222 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:55:52,268 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:55:52,268 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:55:52,816 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:55:52,854 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:55:52,854 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:55:53,402 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:55:53,402 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:55:53,402 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  84%|########4 | 211/250 [04:56<00:58,  1.49s/it, loss=0.09]  Epoch 1/1 [Train]:  85%|########4 | 212/250 [04:56<00:56,  1.49s/it, loss=0.09]2025-03-30 22:55:53,706 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:55:53,752 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:55:53,752 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:55:54,287 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:55:54,324 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:55:54,324 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:55:54,853 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:55:54,853 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:55:54,853 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  85%|########4 | 212/250 [04:57<00:56,  1.49s/it, loss=0.0737]Epoch 1/1 [Train]:  85%|########5 | 213/250 [04:57<00:54,  1.48s/it, loss=0.0737]2025-03-30 22:55:55,149 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:55:55,189 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:55:55,189 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:55:55,726 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:55:55,762 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:55:55,762 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:55:56,302 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:55:56,302 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:55:56,302 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  85%|########5 | 213/250 [04:59<00:54,  1.48s/it, loss=0.0901]Epoch 1/1 [Train]:  86%|########5 | 214/250 [04:59<00:52,  1.46s/it, loss=0.0901]2025-03-30 22:55:56,637 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:55:56,704 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:55:56,704 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:55:57,233 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:55:57,270 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:55:57,270 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:55:57,814 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:55:57,814 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:55:57,814 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  86%|########5 | 214/250 [05:00<00:52,  1.46s/it, loss=0.0603]Epoch 1/1 [Train]:  86%|########6 | 215/250 [05:00<00:51,  1.48s/it, loss=0.0603]2025-03-30 22:55:58,137 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:55:58,189 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:55:58,189 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:55:58,739 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:55:58,798 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:55:58,798 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:55:59,322 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:55:59,323 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:55:59,323 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  86%|########6 | 215/250 [05:02<00:51,  1.48s/it, loss=0.0582]Epoch 1/1 [Train]:  86%|########6 | 216/250 [05:02<00:50,  1.49s/it, loss=0.0582]2025-03-30 22:55:59,620 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:55:59,663 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:55:59,663 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:56:00,211 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:56:00,249 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:56:00,249 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:56:00,793 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:56:00,794 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:56:00,794 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  86%|########6 | 216/250 [05:03<00:50,  1.49s/it, loss=0.0521]Epoch 1/1 [Train]:  87%|########6 | 217/250 [05:03<00:49,  1.49s/it, loss=0.0521]2025-03-30 22:56:01,142 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:56:01,197 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:56:01,198 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:56:01,718 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:56:01,755 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:56:01,755 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:56:02,286 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:56:02,286 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:56:02,286 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  87%|########6 | 217/250 [05:05<00:49,  1.49s/it, loss=0.0492]Epoch 1/1 [Train]:  87%|########7 | 218/250 [05:05<00:47,  1.49s/it, loss=0.0492]2025-03-30 22:56:02,600 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:56:02,651 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:56:02,651 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:56:03,197 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:56:03,239 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:56:03,239 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:56:03,777 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:56:03,777 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:56:03,777 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  87%|########7 | 218/250 [05:06<00:47,  1.49s/it, loss=0.0633]Epoch 1/1 [Train]:  88%|########7 | 219/250 [05:06<00:46,  1.49s/it, loss=0.0633]2025-03-30 22:56:04,049 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:56:04,094 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:56:04,094 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:56:04,637 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:56:04,673 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:56:04,673 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:56:05,217 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:56:05,217 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:56:05,217 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  88%|########7 | 219/250 [05:08<00:46,  1.49s/it, loss=0.0769]Epoch 1/1 [Train]:  88%|########8 | 220/250 [05:08<00:44,  1.48s/it, loss=0.0769]2025-03-30 22:56:05,521 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:56:05,564 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:56:05,564 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:56:06,111 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:56:06,148 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:56:06,148 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:56:06,691 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:56:06,692 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:56:06,692 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  88%|########8 | 220/250 [05:09<00:44,  1.48s/it, loss=0.0676]Epoch 1/1 [Train]:  88%|########8 | 221/250 [05:09<00:42,  1.48s/it, loss=0.0676]2025-03-30 22:56:07,003 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:56:07,058 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:56:07,058 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:56:07,578 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:56:07,614 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:56:07,614 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:56:08,158 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:56:08,158 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:56:08,158 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  88%|########8 | 221/250 [05:10<00:42,  1.48s/it, loss=0.0501]Epoch 1/1 [Train]:  89%|########8 | 222/250 [05:10<00:41,  1.47s/it, loss=0.0501]2025-03-30 22:56:08,446 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:56:08,492 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:56:08,492 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:56:09,027 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:56:09,065 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:56:09,066 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:56:09,593 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:56:09,593 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:56:09,594 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  89%|########8 | 222/250 [05:12<00:41,  1.47s/it, loss=0.0489]Epoch 1/1 [Train]:  89%|########9 | 223/250 [05:12<00:39,  1.48s/it, loss=0.0489]2025-03-30 22:56:09,972 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:56:10,037 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:56:10,037 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:56:10,544 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:56:10,579 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:56:10,580 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:56:11,148 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:56:11,148 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:56:11,148 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  89%|########9 | 223/250 [05:13<00:39,  1.48s/it, loss=0.0466]Epoch 1/1 [Train]:  90%|########9 | 224/250 [05:13<00:38,  1.49s/it, loss=0.0466]2025-03-30 22:56:11,459 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:56:11,509 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:56:11,510 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:56:12,061 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:56:12,098 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:56:12,098 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:56:12,639 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:56:12,639 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:56:12,639 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  90%|########9 | 224/250 [05:15<00:38,  1.49s/it, loss=0.0501]Epoch 1/1 [Train]:  90%|######### | 225/250 [05:15<00:37,  1.49s/it, loss=0.0501]2025-03-30 22:56:12,939 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:56:12,987 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:56:12,988 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:56:13,526 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:56:13,561 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:56:13,561 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:56:14,110 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:56:14,111 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:56:14,111 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  90%|######### | 225/250 [05:16<00:37,  1.49s/it, loss=0.0706]Epoch 1/1 [Train]:  90%|######### | 226/250 [05:16<00:35,  1.48s/it, loss=0.0706]2025-03-30 22:56:14,420 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:56:14,463 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:56:14,463 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:56:15,005 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:56:15,041 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:56:15,041 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:56:15,595 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:56:15,595 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:56:15,595 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  90%|######### | 226/250 [05:18<00:35,  1.48s/it, loss=0.0725]Epoch 1/1 [Train]:  91%|######### | 227/250 [05:18<00:34,  1.49s/it, loss=0.0725]2025-03-30 22:56:15,910 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:56:15,962 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:56:15,962 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:56:16,490 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:56:16,530 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:56:16,530 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:56:17,061 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:56:17,061 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:56:17,061 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  91%|######### | 227/250 [05:19<00:34,  1.49s/it, loss=0.0792]Epoch 1/1 [Train]:  91%|#########1| 228/250 [05:19<00:32,  1.47s/it, loss=0.0792]2025-03-30 22:56:17,376 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:56:17,423 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:56:17,423 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:56:17,958 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:56:17,994 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:56:17,994 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:56:18,528 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:56:18,529 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:56:18,529 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  91%|#########1| 228/250 [05:21<00:32,  1.47s/it, loss=0.0541]Epoch 1/1 [Train]:  92%|#########1| 229/250 [05:21<00:30,  1.47s/it, loss=0.0541]2025-03-30 22:56:18,829 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:56:18,879 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:56:18,879 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:56:19,410 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:56:19,448 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:56:19,448 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:56:19,995 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:56:19,995 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:56:19,995 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  92%|#########1| 229/250 [05:22<00:30,  1.47s/it, loss=0.0733]Epoch 1/1 [Train]:  92%|#########2| 230/250 [05:22<00:29,  1.47s/it, loss=0.0733]2025-03-30 22:56:20,312 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:56:20,367 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:56:20,368 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:56:20,912 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:56:20,948 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:56:20,948 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:56:21,502 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:56:21,502 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:56:21,502 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  92%|#########2| 230/250 [05:24<00:29,  1.47s/it, loss=0.0452]Epoch 1/1 [Train]:  92%|#########2| 231/250 [05:24<00:28,  1.49s/it, loss=0.0452]2025-03-30 22:56:21,827 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:56:21,874 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:56:21,874 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:56:22,404 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:56:22,443 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:56:22,443 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:56:22,974 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:56:22,974 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:56:22,974 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  92%|#########2| 231/250 [05:25<00:28,  1.49s/it, loss=0.0456]Epoch 1/1 [Train]:  93%|#########2| 232/250 [05:25<00:26,  1.48s/it, loss=0.0456]2025-03-30 22:56:23,297 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:56:23,344 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:56:23,344 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:56:23,868 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:56:23,903 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:56:23,903 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:56:24,444 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:56:24,444 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:56:24,444 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  93%|#########2| 232/250 [05:27<00:26,  1.48s/it, loss=0.0799]Epoch 1/1 [Train]:  93%|#########3| 233/250 [05:27<00:25,  1.48s/it, loss=0.0799]2025-03-30 22:56:24,766 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:56:24,813 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:56:24,813 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:56:25,365 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:56:25,402 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:56:25,402 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:56:25,954 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:56:25,954 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:56:25,954 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  93%|#########3| 233/250 [05:28<00:25,  1.48s/it, loss=0.059] Epoch 1/1 [Train]:  94%|#########3| 234/250 [05:28<00:23,  1.49s/it, loss=0.059]2025-03-30 22:56:26,257 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:56:26,300 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:56:26,301 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:56:26,854 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:56:26,896 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:56:26,896 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:56:27,444 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:56:27,444 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:56:27,444 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  94%|#########3| 234/250 [05:30<00:23,  1.49s/it, loss=0.0651]Epoch 1/1 [Train]:  94%|#########3| 235/250 [05:30<00:22,  1.49s/it, loss=0.0651]2025-03-30 22:56:27,758 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:56:27,801 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:56:27,801 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:56:28,341 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:56:28,379 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:56:28,379 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:56:28,910 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:56:28,910 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:56:28,910 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  94%|#########3| 235/250 [05:31<00:22,  1.49s/it, loss=0.0528]Epoch 1/1 [Train]:  94%|#########4| 236/250 [05:31<00:20,  1.48s/it, loss=0.0528]2025-03-30 22:56:29,213 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:56:29,256 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:56:29,256 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:56:29,794 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:56:29,838 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:56:29,839 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:56:30,364 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:56:30,364 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:56:30,364 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  94%|#########4| 236/250 [05:33<00:20,  1.48s/it, loss=0.0421]Epoch 1/1 [Train]:  95%|#########4| 237/250 [05:33<00:19,  1.47s/it, loss=0.0421]2025-03-30 22:56:30,682 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:56:30,728 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:56:30,728 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:56:31,286 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:56:31,321 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:56:31,321 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:56:31,868 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:56:31,868 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:56:31,868 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  95%|#########4| 237/250 [05:34<00:19,  1.47s/it, loss=0.045] Epoch 1/1 [Train]:  95%|#########5| 238/250 [05:34<00:17,  1.48s/it, loss=0.045]2025-03-30 22:56:32,179 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:56:32,224 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:56:32,224 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:56:32,772 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:56:32,808 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:56:32,808 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:56:33,353 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:56:33,353 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:56:33,354 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  95%|#########5| 238/250 [05:36<00:17,  1.48s/it, loss=0.0766]Epoch 1/1 [Train]:  96%|#########5| 239/250 [05:36<00:16,  1.48s/it, loss=0.0766]2025-03-30 22:56:33,652 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:56:33,698 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:56:33,698 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:56:34,230 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:56:34,267 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:56:34,267 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:56:34,815 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:56:34,815 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:56:34,815 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  96%|#########5| 239/250 [05:37<00:16,  1.48s/it, loss=0.0389]Epoch 1/1 [Train]:  96%|#########6| 240/250 [05:37<00:14,  1.48s/it, loss=0.0389]2025-03-30 22:56:35,113 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:56:35,153 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:56:35,153 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:56:35,688 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:56:35,725 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:56:35,725 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:56:36,267 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:56:36,267 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:56:36,267 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  96%|#########6| 240/250 [05:39<00:14,  1.48s/it, loss=0.0689]Epoch 1/1 [Train]:  96%|#########6| 241/250 [05:39<00:13,  1.47s/it, loss=0.0689]2025-03-30 22:56:36,595 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:56:36,667 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:56:36,667 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:56:37,185 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:56:37,233 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:56:37,233 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:56:37,769 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:56:37,769 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:56:37,769 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  96%|#########6| 241/250 [05:40<00:13,  1.47s/it, loss=0.0959]Epoch 1/1 [Train]:  97%|#########6| 242/250 [05:40<00:11,  1.48s/it, loss=0.0959]2025-03-30 22:56:38,065 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:56:38,111 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:56:38,111 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:56:38,659 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:56:38,696 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:56:38,696 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:56:39,243 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:56:39,243 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:56:39,243 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  97%|#########6| 242/250 [05:42<00:11,  1.48s/it, loss=0.0431]Epoch 1/1 [Train]:  97%|#########7| 243/250 [05:42<00:10,  1.48s/it, loss=0.0431]2025-03-30 22:56:39,588 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:56:39,647 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:56:39,647 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:56:40,168 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:56:40,204 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:56:40,204 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:56:40,754 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:56:40,754 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:56:40,754 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  97%|#########7| 243/250 [05:43<00:10,  1.48s/it, loss=0.0715]Epoch 1/1 [Train]:  98%|#########7| 244/250 [05:43<00:08,  1.48s/it, loss=0.0715]2025-03-30 22:56:41,022 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:56:41,059 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:56:41,059 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:56:41,604 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:56:41,640 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:56:41,640 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:56:42,196 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:56:42,196 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:56:42,196 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  98%|#########7| 244/250 [05:45<00:08,  1.48s/it, loss=0.0618]Epoch 1/1 [Train]:  98%|#########8| 245/250 [05:45<00:07,  1.48s/it, loss=0.0618]2025-03-30 22:56:42,526 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:56:42,575 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:56:42,575 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:56:43,106 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:56:43,142 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:56:43,142 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:56:43,676 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:56:43,676 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:56:43,676 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  98%|#########8| 245/250 [05:46<00:07,  1.48s/it, loss=0.0561]Epoch 1/1 [Train]:  98%|#########8| 246/250 [05:46<00:05,  1.47s/it, loss=0.0561]2025-03-30 22:56:43,986 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:56:44,054 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:56:44,055 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:56:44,570 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:56:44,610 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:56:44,610 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:56:45,140 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:56:45,140 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:56:45,140 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  98%|#########8| 246/250 [05:47<00:05,  1.47s/it, loss=0.0575]Epoch 1/1 [Train]:  99%|#########8| 247/250 [05:47<00:04,  1.47s/it, loss=0.0575]2025-03-30 22:56:45,432 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:56:45,474 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:56:45,474 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:56:46,029 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:56:46,066 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:56:46,066 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:56:46,617 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:56:46,617 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:56:46,617 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  99%|#########8| 247/250 [05:49<00:04,  1.47s/it, loss=0.0628]Epoch 1/1 [Train]:  99%|#########9| 248/250 [05:49<00:02,  1.47s/it, loss=0.0628]2025-03-30 22:56:46,931 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:56:46,987 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:56:46,987 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:56:47,529 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:56:47,571 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:56:47,571 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:56:48,117 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:56:48,117 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:56:48,117 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]:  99%|#########9| 248/250 [05:50<00:02,  1.47s/it, loss=0.0669]Epoch 1/1 [Train]: 100%|#########9| 249/250 [05:50<00:01,  1.48s/it, loss=0.0669]2025-03-30 22:56:48,410 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:56:48,456 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:56:48,456 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:56:48,990 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:56:49,029 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:56:49,029 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:56:49,561 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:56:49,561 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:56:49,561 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Train]: 100%|#########9| 249/250 [05:52<00:01,  1.48s/it, loss=0.0584]Epoch 1/1 [Train]: 100%|##########| 250/250 [05:52<00:00,  1.47s/it, loss=0.0584]Epoch 1/1 [Train]: 100%|##########| 250/250 [05:52<00:00,  1.41s/it, loss=0.0584]
2025-03-30 22:56:49,785 - __main__ - INFO - Epoch 1/1 - Train Loss: 0.089622
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Epoch 1/1 [Val]:   0%|          | 0/100 [00:00<?, ?it/s]2025-03-30 22:56:49,810 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:56:49,852 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:56:49,852 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:56:50,408 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:56:50,445 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:56:50,445 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:56:50,995 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:56:50,995 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:56:50,995 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:   0%|          | 0/100 [00:01<?, ?it/s, loss=0.0443]Epoch 1/1 [Val]:   1%|1         | 1/100 [00:01<02:20,  1.42s/it, loss=0.0443]2025-03-30 22:56:51,260 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:56:51,322 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:56:51,323 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:56:51,840 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:56:51,879 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:56:51,879 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:56:52,407 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:56:52,408 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:56:52,408 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:   1%|1         | 1/100 [00:02<02:20,  1.42s/it, loss=0.0634]Epoch 1/1 [Val]:   2%|2         | 2/100 [00:02<02:18,  1.41s/it, loss=0.0634]2025-03-30 22:56:52,643 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:56:52,682 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:56:52,682 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:56:53,242 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:56:53,277 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:56:53,277 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:56:53,832 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:56:53,832 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:56:53,832 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:   2%|2         | 2/100 [00:04<02:18,  1.41s/it, loss=0.0489]Epoch 1/1 [Val]:   3%|3         | 3/100 [00:04<02:17,  1.42s/it, loss=0.0489]2025-03-30 22:56:54,070 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:56:54,116 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:56:54,116 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:56:54,671 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:56:54,708 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:56:54,709 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:56:55,261 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:56:55,261 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:56:55,261 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:   3%|3         | 3/100 [00:05<02:17,  1.42s/it, loss=0.0454]Epoch 1/1 [Val]:   4%|4         | 4/100 [00:05<02:16,  1.42s/it, loss=0.0454]2025-03-30 22:56:55,499 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:56:55,544 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:56:55,545 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:56:56,098 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:56:56,136 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:56:56,136 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:56:56,688 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:56:56,688 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:56:56,688 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:   4%|4         | 4/100 [00:07<02:16,  1.42s/it, loss=0.0479]Epoch 1/1 [Val]:   5%|5         | 5/100 [00:07<02:15,  1.42s/it, loss=0.0479]2025-03-30 22:56:56,924 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:56:56,968 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:56:56,968 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:56:57,525 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:56:57,566 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:56:57,566 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:56:58,115 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:56:58,115 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:56:58,115 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:   5%|5         | 5/100 [00:08<02:15,  1.42s/it, loss=0.0633]Epoch 1/1 [Val]:   6%|6         | 6/100 [00:08<02:14,  1.43s/it, loss=0.0633]2025-03-30 22:56:58,349 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:56:58,390 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:56:58,390 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:56:58,949 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:56:58,985 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:56:58,986 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:56:59,538 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:56:59,538 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:56:59,538 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:   6%|6         | 6/100 [00:09<02:14,  1.43s/it, loss=0.0657]Epoch 1/1 [Val]:   7%|7         | 7/100 [00:09<02:12,  1.42s/it, loss=0.0657]2025-03-30 22:56:59,799 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:56:59,867 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:56:59,867 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:57:00,398 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:57:00,435 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:57:00,435 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:57:00,987 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:57:00,987 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:57:00,987 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:   7%|7         | 7/100 [00:11<02:12,  1.42s/it, loss=0.0514]Epoch 1/1 [Val]:   8%|8         | 8/100 [00:11<02:11,  1.43s/it, loss=0.0514]2025-03-30 22:57:01,221 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:57:01,260 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:57:01,260 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:57:01,821 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:57:01,858 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:57:01,858 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:57:02,409 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:57:02,409 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:57:02,409 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:   8%|8         | 8/100 [00:12<02:11,  1.43s/it, loss=0.0484]Epoch 1/1 [Val]:   9%|9         | 9/100 [00:12<02:10,  1.43s/it, loss=0.0484]2025-03-30 22:57:02,650 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:57:02,697 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:57:02,698 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:57:03,250 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:57:03,285 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:57:03,285 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:57:03,830 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:57:03,831 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:57:03,831 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:   9%|9         | 9/100 [00:14<02:10,  1.43s/it, loss=0.0294]Epoch 1/1 [Val]:  10%|#         | 10/100 [00:14<02:08,  1.43s/it, loss=0.0294]2025-03-30 22:57:04,070 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:57:04,131 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:57:04,131 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:57:04,653 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:57:04,690 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:57:04,691 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:57:05,222 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:57:05,223 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:57:05,223 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  10%|#         | 10/100 [00:15<02:08,  1.43s/it, loss=0.0325]Epoch 1/1 [Val]:  11%|#1        | 11/100 [00:15<02:05,  1.42s/it, loss=0.0325]2025-03-30 22:57:05,456 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:57:05,498 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:57:05,498 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:57:06,053 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:57:06,099 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:57:06,100 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:57:06,640 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:57:06,640 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:57:06,640 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  11%|#1        | 11/100 [00:17<02:05,  1.42s/it, loss=0.0773]Epoch 1/1 [Val]:  12%|#2        | 12/100 [00:17<02:04,  1.42s/it, loss=0.0773]2025-03-30 22:57:06,876 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:57:06,926 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:57:06,926 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:57:07,471 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:57:07,511 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:57:07,511 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:57:08,056 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:57:08,057 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:57:08,057 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  12%|#2        | 12/100 [00:18<02:04,  1.42s/it, loss=0.038] Epoch 1/1 [Val]:  13%|#3        | 13/100 [00:18<02:03,  1.42s/it, loss=0.038]2025-03-30 22:57:08,295 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:57:08,342 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:57:08,342 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:57:08,891 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:57:08,929 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:57:08,929 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:57:09,475 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:57:09,476 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:57:09,476 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  13%|#3        | 13/100 [00:19<02:03,  1.42s/it, loss=0.0422]Epoch 1/1 [Val]:  14%|#4        | 14/100 [00:19<02:01,  1.42s/it, loss=0.0422]2025-03-30 22:57:09,714 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:57:09,767 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:57:09,767 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:57:10,309 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:57:10,345 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:57:10,345 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:57:10,875 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:57:10,876 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:57:10,876 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  14%|#4        | 14/100 [00:21<02:01,  1.42s/it, loss=0.0406]Epoch 1/1 [Val]:  15%|#5        | 15/100 [00:21<01:59,  1.41s/it, loss=0.0406]2025-03-30 22:57:11,110 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:57:11,157 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:57:11,157 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:57:11,689 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:57:11,726 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:57:11,726 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:57:12,272 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:57:12,273 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:57:12,273 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  15%|#5        | 15/100 [00:22<01:59,  1.41s/it, loss=0.0573]Epoch 1/1 [Val]:  16%|#6        | 16/100 [00:22<01:58,  1.41s/it, loss=0.0573]2025-03-30 22:57:12,509 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:57:12,553 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:57:12,553 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:57:13,106 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:57:13,142 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:57:13,142 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:57:13,692 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:57:13,692 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:57:13,692 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  16%|#6        | 16/100 [00:24<01:58,  1.41s/it, loss=0.0559]Epoch 1/1 [Val]:  17%|#7        | 17/100 [00:24<01:57,  1.41s/it, loss=0.0559]2025-03-30 22:57:13,925 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:57:13,969 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:57:13,969 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:57:14,523 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:57:14,560 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:57:14,561 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:57:15,108 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:57:15,108 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:57:15,108 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  17%|#7        | 17/100 [00:25<01:57,  1.41s/it, loss=0.0519]Epoch 1/1 [Val]:  18%|#8        | 18/100 [00:25<01:55,  1.41s/it, loss=0.0519]2025-03-30 22:57:15,343 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:57:15,387 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:57:15,387 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:57:15,941 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:57:15,978 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:57:15,978 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:57:16,528 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:57:16,528 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:57:16,528 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  18%|#8        | 18/100 [00:26<01:55,  1.41s/it, loss=0.0383]Epoch 1/1 [Val]:  19%|#9        | 19/100 [00:26<01:54,  1.42s/it, loss=0.0383]2025-03-30 22:57:16,965 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:57:17,023 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:57:17,023 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:57:17,551 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:57:17,604 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:57:17,604 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:57:18,119 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:57:18,120 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:57:18,120 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  19%|#9        | 19/100 [00:28<01:54,  1.42s/it, loss=0.0444]Epoch 1/1 [Val]:  20%|##        | 20/100 [00:28<01:57,  1.47s/it, loss=0.0444]2025-03-30 22:57:18,360 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:57:18,409 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:57:18,409 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:57:18,961 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:57:18,997 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:57:18,997 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:57:19,547 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:57:19,547 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:57:19,547 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  20%|##        | 20/100 [00:29<01:57,  1.47s/it, loss=0.0636]Epoch 1/1 [Val]:  21%|##1       | 21/100 [00:29<01:55,  1.46s/it, loss=0.0636]2025-03-30 22:57:19,781 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:57:19,822 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:57:19,822 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:57:20,382 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:57:20,426 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:57:20,426 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:57:20,970 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:57:20,970 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:57:20,970 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  21%|##1       | 21/100 [00:31<01:55,  1.46s/it, loss=0.0622]Epoch 1/1 [Val]:  22%|##2       | 22/100 [00:31<01:52,  1.45s/it, loss=0.0622]2025-03-30 22:57:21,206 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:57:21,251 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:57:21,252 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:57:21,803 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:57:21,841 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:57:21,841 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:57:22,391 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:57:22,391 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:57:22,391 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  22%|##2       | 22/100 [00:32<01:52,  1.45s/it, loss=0.0354]Epoch 1/1 [Val]:  23%|##3       | 23/100 [00:32<01:50,  1.44s/it, loss=0.0354]2025-03-30 22:57:22,626 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:57:22,682 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:57:22,682 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:57:23,229 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:57:23,270 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:57:23,270 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:57:23,817 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:57:23,817 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:57:23,817 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  23%|##3       | 23/100 [00:34<01:50,  1.44s/it, loss=0.0349]Epoch 1/1 [Val]:  24%|##4       | 24/100 [00:34<01:49,  1.43s/it, loss=0.0349]2025-03-30 22:57:24,051 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:57:24,093 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:57:24,093 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:57:24,650 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:57:24,698 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:57:24,698 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:57:25,219 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:57:25,219 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:57:25,219 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  24%|##4       | 24/100 [00:35<01:49,  1.43s/it, loss=0.0449]Epoch 1/1 [Val]:  25%|##5       | 25/100 [00:35<01:46,  1.42s/it, loss=0.0449]2025-03-30 22:57:25,452 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:57:25,502 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:57:25,502 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:57:26,040 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:57:26,077 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:57:26,077 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:57:26,627 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:57:26,627 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:57:26,627 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  25%|##5       | 25/100 [00:37<01:46,  1.42s/it, loss=0.0441]Epoch 1/1 [Val]:  26%|##6       | 26/100 [00:37<01:45,  1.42s/it, loss=0.0441]2025-03-30 22:57:26,865 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:57:26,920 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:57:26,920 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:57:27,466 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:57:27,506 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:57:27,506 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:57:28,051 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:57:28,052 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:57:28,052 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  26%|##6       | 26/100 [00:38<01:45,  1.42s/it, loss=0.0463]Epoch 1/1 [Val]:  27%|##7       | 27/100 [00:38<01:43,  1.42s/it, loss=0.0463]2025-03-30 22:57:28,292 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:57:28,340 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:57:28,340 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:57:28,896 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:57:28,945 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:57:28,946 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:57:29,483 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:57:29,483 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:57:29,483 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  27%|##7       | 27/100 [00:39<01:43,  1.42s/it, loss=0.0534]Epoch 1/1 [Val]:  28%|##8       | 28/100 [00:39<01:42,  1.43s/it, loss=0.0534]2025-03-30 22:57:29,722 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:57:29,764 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:57:29,765 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:57:30,319 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:57:30,356 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:57:30,356 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:57:30,906 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:57:30,906 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:57:30,907 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  28%|##8       | 28/100 [00:41<01:42,  1.43s/it, loss=0.101] Epoch 1/1 [Val]:  29%|##9       | 29/100 [00:41<01:41,  1.42s/it, loss=0.101]2025-03-30 22:57:31,143 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:57:31,188 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:57:31,188 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:57:31,741 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:57:31,783 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:57:31,783 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:57:32,328 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:57:32,328 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:57:32,328 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  29%|##9       | 29/100 [00:42<01:41,  1.42s/it, loss=0.0534]Epoch 1/1 [Val]:  30%|###       | 30/100 [00:42<01:39,  1.42s/it, loss=0.0534]2025-03-30 22:57:32,563 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:57:32,605 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:57:32,605 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:57:33,160 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:57:33,197 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:57:33,197 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:57:33,747 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:57:33,747 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:57:33,747 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  30%|###       | 30/100 [00:44<01:39,  1.42s/it, loss=0.0669]Epoch 1/1 [Val]:  31%|###1      | 31/100 [00:44<01:38,  1.42s/it, loss=0.0669]2025-03-30 22:57:34,023 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:57:34,093 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:57:34,093 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:57:34,635 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:57:34,710 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:57:34,711 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:57:35,224 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:57:35,224 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:57:35,224 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  31%|###1      | 31/100 [00:45<01:38,  1.42s/it, loss=0.0446]Epoch 1/1 [Val]:  32%|###2      | 32/100 [00:45<01:37,  1.44s/it, loss=0.0446]2025-03-30 22:57:35,464 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:57:35,525 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:57:35,526 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:57:36,063 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:57:36,099 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:57:36,100 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:57:36,649 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:57:36,649 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:57:36,649 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  32%|###2      | 32/100 [00:47<01:37,  1.44s/it, loss=0.0521]Epoch 1/1 [Val]:  33%|###3      | 33/100 [00:47<01:36,  1.43s/it, loss=0.0521]2025-03-30 22:57:36,895 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:57:36,943 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:57:36,943 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:57:37,498 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:57:37,539 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:57:37,540 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:57:38,086 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:57:38,086 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:57:38,086 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  33%|###3      | 33/100 [00:48<01:36,  1.43s/it, loss=0.0682]Epoch 1/1 [Val]:  34%|###4      | 34/100 [00:48<01:34,  1.44s/it, loss=0.0682]2025-03-30 22:57:38,327 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:57:38,375 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:57:38,375 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:57:38,927 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:57:38,966 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:57:38,966 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:57:39,515 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:57:39,515 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:57:39,515 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  34%|###4      | 34/100 [00:49<01:34,  1.44s/it, loss=0.0683]Epoch 1/1 [Val]:  35%|###5      | 35/100 [00:49<01:33,  1.43s/it, loss=0.0683]2025-03-30 22:57:39,750 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:57:39,791 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:57:39,792 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:57:40,347 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:57:40,383 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:57:40,383 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:57:40,933 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:57:40,933 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:57:40,934 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  35%|###5      | 35/100 [00:51<01:33,  1.43s/it, loss=0.0635]Epoch 1/1 [Val]:  36%|###6      | 36/100 [00:51<01:31,  1.43s/it, loss=0.0635]2025-03-30 22:57:41,181 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:57:41,248 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:57:41,249 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:57:41,780 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:57:41,817 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:57:41,817 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:57:42,368 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:57:42,368 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:57:42,368 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  36%|###6      | 36/100 [00:52<01:31,  1.43s/it, loss=0.0592]Epoch 1/1 [Val]:  37%|###7      | 37/100 [00:52<01:30,  1.43s/it, loss=0.0592]2025-03-30 22:57:42,600 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:57:42,643 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:57:42,643 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:57:43,199 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:57:43,235 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:57:43,236 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:57:43,787 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:57:43,787 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:57:43,787 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  37%|###7      | 37/100 [00:54<01:30,  1.43s/it, loss=0.0544]Epoch 1/1 [Val]:  38%|###8      | 38/100 [00:54<01:28,  1.43s/it, loss=0.0544]2025-03-30 22:57:44,029 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:57:44,071 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:57:44,071 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:57:44,632 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:57:44,667 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:57:44,667 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:57:45,219 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:57:45,219 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:57:45,219 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  38%|###8      | 38/100 [00:55<01:28,  1.43s/it, loss=0.0447]Epoch 1/1 [Val]:  39%|###9      | 39/100 [00:55<01:27,  1.43s/it, loss=0.0447]2025-03-30 22:57:45,458 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:57:45,499 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:57:45,499 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:57:46,056 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:57:46,092 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:57:46,092 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:57:46,642 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:57:46,643 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:57:46,643 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  39%|###9      | 39/100 [00:57<01:27,  1.43s/it, loss=0.101] Epoch 1/1 [Val]:  40%|####      | 40/100 [00:57<01:25,  1.43s/it, loss=0.101]2025-03-30 22:57:46,881 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:57:46,926 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:57:46,926 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:57:47,480 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:57:47,519 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:57:47,520 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:57:48,068 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:57:48,068 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:57:48,068 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  40%|####      | 40/100 [00:58<01:25,  1.43s/it, loss=0.0726]Epoch 1/1 [Val]:  41%|####1     | 41/100 [00:58<01:24,  1.43s/it, loss=0.0726]2025-03-30 22:57:48,327 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:57:48,397 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:57:48,397 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:57:48,926 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:57:48,963 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:57:48,964 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:57:49,514 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:57:49,514 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:57:49,514 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  41%|####1     | 41/100 [00:59<01:24,  1.43s/it, loss=0.039] Epoch 1/1 [Val]:  42%|####2     | 42/100 [00:59<01:23,  1.43s/it, loss=0.039]2025-03-30 22:57:49,752 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:57:49,796 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:57:49,796 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:57:50,350 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:57:50,390 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:57:50,391 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:57:50,937 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:57:50,937 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:57:50,937 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  42%|####2     | 42/100 [01:01<01:23,  1.43s/it, loss=0.0601]Epoch 1/1 [Val]:  43%|####3     | 43/100 [01:01<01:21,  1.43s/it, loss=0.0601]2025-03-30 22:57:51,178 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:57:51,220 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:57:51,220 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:57:51,776 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:57:51,812 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:57:51,812 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:57:52,363 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:57:52,364 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:57:52,364 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  43%|####3     | 43/100 [01:02<01:21,  1.43s/it, loss=0.053] Epoch 1/1 [Val]:  44%|####4     | 44/100 [01:02<01:19,  1.43s/it, loss=0.053]2025-03-30 22:57:52,603 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:57:52,660 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:57:52,661 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:57:53,202 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:57:53,240 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:57:53,240 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:57:53,789 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:57:53,790 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:57:53,790 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  44%|####4     | 44/100 [01:04<01:19,  1.43s/it, loss=0.0648]Epoch 1/1 [Val]:  45%|####5     | 45/100 [01:04<01:18,  1.43s/it, loss=0.0648]2025-03-30 22:57:54,027 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:57:54,073 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:57:54,073 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:57:54,625 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:57:54,661 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:57:54,661 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:57:55,213 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:57:55,213 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:57:55,213 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  45%|####5     | 45/100 [01:05<01:18,  1.43s/it, loss=0.0621]Epoch 1/1 [Val]:  46%|####6     | 46/100 [01:05<01:18,  1.45s/it, loss=0.0621]2025-03-30 22:57:55,577 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:57:55,652 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:57:55,652 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:57:56,158 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:57:56,199 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:57:56,199 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:57:56,736 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:57:56,736 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:57:56,736 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  46%|####6     | 46/100 [01:07<01:18,  1.45s/it, loss=0.0604]Epoch 1/1 [Val]:  47%|####6     | 47/100 [01:07<01:16,  1.45s/it, loss=0.0604]2025-03-30 22:57:56,971 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:57:57,011 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:57:57,011 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:57:57,569 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:57:57,606 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:57:57,606 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:57:58,156 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:57:58,157 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:57:58,157 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  47%|####6     | 47/100 [01:08<01:16,  1.45s/it, loss=0.0471]Epoch 1/1 [Val]:  48%|####8     | 48/100 [01:08<01:14,  1.44s/it, loss=0.0471]2025-03-30 22:57:58,390 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:57:58,433 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:57:58,433 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:57:58,987 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:57:59,024 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:57:59,024 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:57:59,572 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:57:59,573 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:57:59,573 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  48%|####8     | 48/100 [01:09<01:14,  1.44s/it, loss=0.0609]Epoch 1/1 [Val]:  49%|####9     | 49/100 [01:09<01:13,  1.43s/it, loss=0.0609]2025-03-30 22:57:59,823 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:57:59,880 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:57:59,880 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:58:00,418 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:58:00,454 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:58:00,454 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:58:01,004 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:58:01,004 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:58:01,004 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  49%|####9     | 49/100 [01:11<01:13,  1.43s/it, loss=0.0486]Epoch 1/1 [Val]:  50%|#####     | 50/100 [01:11<01:11,  1.43s/it, loss=0.0486]2025-03-30 22:58:01,238 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:58:01,278 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:58:01,278 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:58:01,836 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:58:01,872 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:58:01,872 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:58:02,421 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:58:02,421 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:58:02,421 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  50%|#####     | 50/100 [01:12<01:11,  1.43s/it, loss=0.0429]Epoch 1/1 [Val]:  51%|#####1    | 51/100 [01:12<01:09,  1.43s/it, loss=0.0429]2025-03-30 22:58:02,657 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:58:02,695 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:58:02,695 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:58:03,252 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:58:03,288 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:58:03,288 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:58:03,838 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:58:03,838 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:58:03,838 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  51%|#####1    | 51/100 [01:14<01:09,  1.43s/it, loss=0.0411]Epoch 1/1 [Val]:  52%|#####2    | 52/100 [01:14<01:08,  1.42s/it, loss=0.0411]2025-03-30 22:58:04,070 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:58:04,118 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:58:04,119 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:58:04,684 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:58:04,746 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:58:04,746 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:58:05,273 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:58:05,273 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:58:05,274 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  52%|#####2    | 52/100 [01:15<01:08,  1.42s/it, loss=0.0861]Epoch 1/1 [Val]:  53%|#####3    | 53/100 [01:15<01:07,  1.43s/it, loss=0.0861]2025-03-30 22:58:05,525 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:58:05,574 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:58:05,575 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:58:06,124 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:58:06,162 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:58:06,162 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:58:06,711 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:58:06,711 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:58:06,711 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  53%|#####3    | 53/100 [01:17<01:07,  1.43s/it, loss=0.0676]Epoch 1/1 [Val]:  54%|#####4    | 54/100 [01:17<01:05,  1.43s/it, loss=0.0676]2025-03-30 22:58:06,949 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:58:06,996 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:58:06,997 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:58:07,545 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:58:07,582 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:58:07,582 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:58:08,131 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:58:08,131 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:58:08,131 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  54%|#####4    | 54/100 [01:18<01:05,  1.43s/it, loss=0.0505]Epoch 1/1 [Val]:  55%|#####5    | 55/100 [01:18<01:04,  1.43s/it, loss=0.0505]2025-03-30 22:58:08,377 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:58:08,437 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:58:08,437 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:58:08,975 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:58:09,013 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:58:09,013 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:58:09,560 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:58:09,560 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:58:09,560 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  55%|#####5    | 55/100 [01:19<01:04,  1.43s/it, loss=0.0486]Epoch 1/1 [Val]:  56%|#####6    | 56/100 [01:19<01:02,  1.43s/it, loss=0.0486]2025-03-30 22:58:09,793 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:58:09,833 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:58:09,833 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:58:10,389 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:58:10,426 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:58:10,426 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:58:10,974 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:58:10,975 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:58:10,975 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  56%|#####6    | 56/100 [01:21<01:02,  1.43s/it, loss=0.0765]Epoch 1/1 [Val]:  57%|#####6    | 57/100 [01:21<01:01,  1.42s/it, loss=0.0765]2025-03-30 22:58:11,216 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:58:11,266 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:58:11,266 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:58:11,812 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:58:11,849 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:58:11,849 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:58:12,398 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:58:12,398 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:58:12,398 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  57%|#####6    | 57/100 [01:22<01:01,  1.42s/it, loss=0.0639]Epoch 1/1 [Val]:  58%|#####8    | 58/100 [01:22<00:59,  1.42s/it, loss=0.0639]2025-03-30 22:58:12,631 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:58:12,672 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:58:12,672 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:58:13,228 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:58:13,263 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:58:13,263 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:58:13,813 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:58:13,814 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:58:13,814 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  58%|#####8    | 58/100 [01:24<00:59,  1.42s/it, loss=0.0434]Epoch 1/1 [Val]:  59%|#####8    | 59/100 [01:24<00:58,  1.42s/it, loss=0.0434]2025-03-30 22:58:14,050 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:58:14,094 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:58:14,095 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:58:14,646 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:58:14,682 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:58:14,682 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:58:15,232 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:58:15,232 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:58:15,232 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  59%|#####8    | 59/100 [01:25<00:58,  1.42s/it, loss=0.0379]Epoch 1/1 [Val]:  60%|######    | 60/100 [01:25<00:56,  1.42s/it, loss=0.0379]2025-03-30 22:58:15,468 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:58:15,514 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:58:15,514 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:58:16,070 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:58:16,138 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:58:16,138 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:58:16,657 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:58:16,657 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:58:16,657 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  60%|######    | 60/100 [01:27<00:56,  1.42s/it, loss=0.0606]Epoch 1/1 [Val]:  61%|######1   | 61/100 [01:27<00:55,  1.42s/it, loss=0.0606]2025-03-30 22:58:16,892 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:58:16,931 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:58:16,931 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:58:17,487 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:58:17,527 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:58:17,527 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:58:18,060 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:58:18,061 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:58:18,061 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  61%|######1   | 61/100 [01:28<00:55,  1.42s/it, loss=0.0345]Epoch 1/1 [Val]:  62%|######2   | 62/100 [01:28<00:53,  1.42s/it, loss=0.0345]2025-03-30 22:58:18,297 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:58:18,334 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:58:18,334 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:58:18,881 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:58:18,918 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:58:18,919 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:58:19,472 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:58:19,472 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:58:19,473 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  62%|######2   | 62/100 [01:29<00:53,  1.42s/it, loss=0.0469]Epoch 1/1 [Val]:  63%|######3   | 63/100 [01:29<00:52,  1.42s/it, loss=0.0469]2025-03-30 22:58:19,707 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:58:19,750 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:58:19,750 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:58:20,309 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:58:20,347 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:58:20,347 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:58:20,900 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:58:20,900 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:58:20,900 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  63%|######3   | 63/100 [01:31<00:52,  1.42s/it, loss=0.0509]Epoch 1/1 [Val]:  64%|######4   | 64/100 [01:31<00:51,  1.42s/it, loss=0.0509]2025-03-30 22:58:21,136 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:58:21,179 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:58:21,180 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:58:21,737 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:58:21,772 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:58:21,772 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:58:22,326 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:58:22,326 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:58:22,326 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  64%|######4   | 64/100 [01:32<00:51,  1.42s/it, loss=0.0384]Epoch 1/1 [Val]:  65%|######5   | 65/100 [01:32<00:49,  1.42s/it, loss=0.0384]2025-03-30 22:58:22,568 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:58:22,616 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:58:22,616 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:58:23,169 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:58:23,205 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:58:23,205 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:58:23,759 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:58:23,759 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:58:23,759 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  65%|######5   | 65/100 [01:34<00:49,  1.42s/it, loss=0.0765]Epoch 1/1 [Val]:  66%|######6   | 66/100 [01:34<00:48,  1.42s/it, loss=0.0765]2025-03-30 22:58:23,995 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:58:24,036 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:58:24,037 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:58:24,594 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:58:24,632 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:58:24,632 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:58:25,185 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:58:25,185 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:58:25,185 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  66%|######6   | 66/100 [01:35<00:48,  1.42s/it, loss=0.0416]Epoch 1/1 [Val]:  67%|######7   | 67/100 [01:35<00:47,  1.43s/it, loss=0.0416]2025-03-30 22:58:25,423 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:58:25,465 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:58:25,465 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:58:26,024 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:58:26,059 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:58:26,060 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:58:26,603 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:58:26,603 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:58:26,603 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  67%|######7   | 67/100 [01:37<00:47,  1.43s/it, loss=0.0317]Epoch 1/1 [Val]:  68%|######8   | 68/100 [01:37<00:45,  1.42s/it, loss=0.0317]2025-03-30 22:58:26,838 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:58:26,896 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:58:26,896 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:58:27,422 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:58:27,465 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:58:27,465 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:58:27,993 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:58:27,993 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:58:27,993 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  68%|######8   | 68/100 [01:38<00:45,  1.42s/it, loss=0.0608]Epoch 1/1 [Val]:  69%|######9   | 69/100 [01:38<00:43,  1.41s/it, loss=0.0608]2025-03-30 22:58:28,226 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:58:28,267 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:58:28,267 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:58:28,837 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:58:28,877 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:58:28,877 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:58:29,434 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:58:29,434 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:58:29,434 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  69%|######9   | 69/100 [01:39<00:43,  1.41s/it, loss=0.0367]Epoch 1/1 [Val]:  70%|#######   | 70/100 [01:39<00:42,  1.42s/it, loss=0.0367]2025-03-30 22:58:29,673 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:58:29,715 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:58:29,715 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:58:30,272 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:58:30,314 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:58:30,314 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:58:30,846 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:58:30,846 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:58:30,846 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  70%|#######   | 70/100 [01:41<00:42,  1.42s/it, loss=0.0471]Epoch 1/1 [Val]:  71%|#######1  | 71/100 [01:41<00:41,  1.42s/it, loss=0.0471]2025-03-30 22:58:31,088 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:58:31,142 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:58:31,142 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:58:31,674 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:58:31,712 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:58:31,712 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:58:32,248 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:58:32,249 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:58:32,249 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  71%|#######1  | 71/100 [01:42<00:41,  1.42s/it, loss=0.058] Epoch 1/1 [Val]:  72%|#######2  | 72/100 [01:42<00:39,  1.41s/it, loss=0.058]2025-03-30 22:58:32,486 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:58:32,538 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:58:32,538 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:58:33,071 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:58:33,110 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:58:33,110 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:58:33,644 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:58:33,644 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:58:33,644 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  72%|#######2  | 72/100 [01:44<00:39,  1.41s/it, loss=0.0363]Epoch 1/1 [Val]:  73%|#######3  | 73/100 [01:44<00:38,  1.41s/it, loss=0.0363]2025-03-30 22:58:33,882 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:58:33,931 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:58:33,931 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:58:34,470 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:58:34,509 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:58:34,509 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:58:35,043 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:58:35,044 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:58:35,044 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  73%|#######3  | 73/100 [01:45<00:38,  1.41s/it, loss=0.0705]Epoch 1/1 [Val]:  74%|#######4  | 74/100 [01:45<00:36,  1.41s/it, loss=0.0705]2025-03-30 22:58:35,277 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:58:35,323 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:58:35,323 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:58:35,877 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:58:35,913 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:58:35,913 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:58:36,466 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:58:36,466 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:58:36,466 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  74%|#######4  | 74/100 [01:46<00:36,  1.41s/it, loss=0.0531]Epoch 1/1 [Val]:  75%|#######5  | 75/100 [01:46<00:35,  1.41s/it, loss=0.0531]2025-03-30 22:58:36,709 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:58:36,759 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:58:36,759 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:58:37,313 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:58:37,358 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:58:37,358 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:58:37,901 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:58:37,901 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:58:37,901 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  75%|#######5  | 75/100 [01:48<00:35,  1.41s/it, loss=0.0329]Epoch 1/1 [Val]:  76%|#######6  | 76/100 [01:48<00:34,  1.42s/it, loss=0.0329]2025-03-30 22:58:38,136 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:58:38,182 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:58:38,182 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:58:38,740 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:58:38,776 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:58:38,776 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:58:39,327 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:58:39,327 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:58:39,327 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  76%|#######6  | 76/100 [01:49<00:34,  1.42s/it, loss=0.0336]Epoch 1/1 [Val]:  77%|#######7  | 77/100 [01:49<00:32,  1.42s/it, loss=0.0336]2025-03-30 22:58:39,564 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:58:39,609 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:58:39,609 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:58:40,165 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:58:40,202 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:58:40,203 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:58:40,753 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:58:40,753 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:58:40,753 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  77%|#######7  | 77/100 [01:51<00:32,  1.42s/it, loss=0.0467]Epoch 1/1 [Val]:  78%|#######8  | 78/100 [01:51<00:31,  1.42s/it, loss=0.0467]2025-03-30 22:58:40,989 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:58:41,034 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:58:41,034 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:58:41,589 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:58:41,624 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:58:41,624 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:58:42,176 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:58:42,176 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:58:42,176 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  78%|#######8  | 78/100 [01:52<00:31,  1.42s/it, loss=0.0954]Epoch 1/1 [Val]:  79%|#######9  | 79/100 [01:52<00:29,  1.42s/it, loss=0.0954]2025-03-30 22:58:42,417 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:58:42,464 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:58:42,464 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:58:43,018 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:58:43,057 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:58:43,057 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:58:43,606 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:58:43,606 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:58:43,606 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  79%|#######9  | 79/100 [01:54<00:29,  1.42s/it, loss=0.0598]Epoch 1/1 [Val]:  80%|########  | 80/100 [01:54<00:28,  1.42s/it, loss=0.0598]2025-03-30 22:58:43,847 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:58:43,905 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:58:43,905 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:58:44,447 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:58:44,482 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:58:44,482 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:58:45,035 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:58:45,035 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:58:45,035 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  80%|########  | 80/100 [01:55<00:28,  1.42s/it, loss=0.0484]Epoch 1/1 [Val]:  81%|########1 | 81/100 [01:55<00:27,  1.43s/it, loss=0.0484]2025-03-30 22:58:45,274 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:58:45,319 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:58:45,319 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:58:45,874 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:58:45,910 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:58:45,910 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:58:46,462 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:58:46,462 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:58:46,462 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  81%|########1 | 81/100 [01:56<00:27,  1.43s/it, loss=0.055] Epoch 1/1 [Val]:  82%|########2 | 82/100 [01:56<00:25,  1.43s/it, loss=0.055]2025-03-30 22:58:46,697 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:58:46,736 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:58:46,736 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:58:47,295 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:58:47,331 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:58:47,331 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:58:47,882 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:58:47,882 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:58:47,882 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  82%|########2 | 82/100 [01:58<00:25,  1.43s/it, loss=0.0431]Epoch 1/1 [Val]:  83%|########2 | 83/100 [01:58<00:24,  1.42s/it, loss=0.0431]2025-03-30 22:58:48,117 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:58:48,163 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:58:48,163 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:58:48,717 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:58:48,754 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:58:48,754 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:58:49,305 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:58:49,305 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:58:49,305 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  83%|########2 | 83/100 [01:59<00:24,  1.42s/it, loss=0.0684]Epoch 1/1 [Val]:  84%|########4 | 84/100 [01:59<00:22,  1.42s/it, loss=0.0684]2025-03-30 22:58:49,541 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:58:49,581 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:58:49,581 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:58:50,138 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:58:50,174 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:58:50,174 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:58:50,727 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:58:50,728 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:58:50,728 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  84%|########4 | 84/100 [02:01<00:22,  1.42s/it, loss=0.067] Epoch 1/1 [Val]:  85%|########5 | 85/100 [02:01<00:21,  1.42s/it, loss=0.067]2025-03-30 22:58:50,976 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:58:51,039 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:58:51,039 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:58:51,575 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:58:51,614 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:58:51,614 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:58:52,164 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:58:52,164 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:58:52,164 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  85%|########5 | 85/100 [02:02<00:21,  1.42s/it, loss=0.0615]Epoch 1/1 [Val]:  86%|########6 | 86/100 [02:02<00:19,  1.43s/it, loss=0.0615]2025-03-30 22:58:52,398 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:58:52,443 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:58:52,443 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:58:52,997 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:58:53,034 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:58:53,034 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:58:53,586 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:58:53,586 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:58:53,586 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  86%|########6 | 86/100 [02:04<00:19,  1.43s/it, loss=0.0675]Epoch 1/1 [Val]:  87%|########7 | 87/100 [02:04<00:18,  1.43s/it, loss=0.0675]2025-03-30 22:58:53,820 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:58:53,864 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:58:53,864 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:58:54,421 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:58:54,464 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:58:54,465 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:58:55,008 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:58:55,008 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:58:55,008 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  87%|########7 | 87/100 [02:05<00:18,  1.43s/it, loss=0.0534]Epoch 1/1 [Val]:  88%|########8 | 88/100 [02:05<00:17,  1.42s/it, loss=0.0534]2025-03-30 22:58:55,245 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:58:55,288 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:58:55,288 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:58:55,842 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:58:55,878 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:58:55,878 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:58:56,430 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:58:56,430 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:58:56,430 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  88%|########8 | 88/100 [02:06<00:17,  1.42s/it, loss=0.0562]Epoch 1/1 [Val]:  89%|########9 | 89/100 [02:06<00:15,  1.42s/it, loss=0.0562]2025-03-30 22:58:56,670 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:58:56,724 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:58:56,724 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:58:57,269 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:58:57,306 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:58:57,306 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:58:57,857 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:58:57,857 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:58:57,858 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  89%|########9 | 89/100 [02:08<00:15,  1.42s/it, loss=0.0397]Epoch 1/1 [Val]:  90%|######### | 90/100 [02:08<00:14,  1.42s/it, loss=0.0397]2025-03-30 22:58:58,106 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:58:58,163 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:58:58,164 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:58:58,704 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:58:58,740 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:58:58,740 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:58:59,292 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:58:59,292 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:58:59,292 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  90%|######### | 90/100 [02:09<00:14,  1.42s/it, loss=0.0508]Epoch 1/1 [Val]:  91%|#########1| 91/100 [02:09<00:12,  1.43s/it, loss=0.0508]2025-03-30 22:58:59,534 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:58:59,578 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:58:59,578 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:59:00,131 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:59:00,167 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:59:00,167 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:59:00,719 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:59:00,719 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:59:00,719 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  91%|#########1| 91/100 [02:11<00:12,  1.43s/it, loss=0.0495]Epoch 1/1 [Val]:  92%|#########2| 92/100 [02:11<00:11,  1.43s/it, loss=0.0495]2025-03-30 22:59:00,954 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:59:00,996 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:59:00,996 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:59:01,553 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:59:01,590 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:59:01,590 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:59:02,141 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:59:02,141 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:59:02,141 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  92%|#########2| 92/100 [02:12<00:11,  1.43s/it, loss=0.0451]Epoch 1/1 [Val]:  93%|#########3| 93/100 [02:12<00:09,  1.43s/it, loss=0.0451]2025-03-30 22:59:02,376 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:59:02,417 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:59:02,418 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:59:02,974 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:59:03,010 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:59:03,010 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:59:03,562 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:59:03,563 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:59:03,563 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  93%|#########3| 93/100 [02:13<00:09,  1.43s/it, loss=0.0486]Epoch 1/1 [Val]:  94%|#########3| 94/100 [02:13<00:08,  1.42s/it, loss=0.0486]2025-03-30 22:59:03,798 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:59:03,839 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:59:03,839 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:59:04,397 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:59:04,433 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:59:04,434 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:59:04,984 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:59:04,984 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:59:04,984 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  94%|#########3| 94/100 [02:15<00:08,  1.42s/it, loss=0.057] Epoch 1/1 [Val]:  95%|#########5| 95/100 [02:15<00:07,  1.42s/it, loss=0.057]2025-03-30 22:59:05,228 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:59:05,293 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:59:05,293 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:59:05,829 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:59:05,866 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:59:05,866 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:59:06,397 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:59:06,397 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:59:06,398 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  95%|#########5| 95/100 [02:16<00:07,  1.42s/it, loss=0.0494]Epoch 1/1 [Val]:  96%|#########6| 96/100 [02:16<00:05,  1.42s/it, loss=0.0494]2025-03-30 22:59:06,629 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:59:06,672 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:59:06,672 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:59:07,212 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:59:07,248 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:59:07,248 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:59:07,800 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:59:07,801 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:59:07,801 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  96%|#########6| 96/100 [02:18<00:05,  1.42s/it, loss=0.0706]Epoch 1/1 [Val]:  97%|#########7| 97/100 [02:18<00:04,  1.42s/it, loss=0.0706]2025-03-30 22:59:08,041 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:59:08,088 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:59:08,088 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:59:08,646 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:59:08,682 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:59:08,683 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:59:09,233 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:59:09,233 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:59:09,233 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  97%|#########7| 97/100 [02:19<00:04,  1.42s/it, loss=0.0458]Epoch 1/1 [Val]:  98%|#########8| 98/100 [02:19<00:02,  1.42s/it, loss=0.0458]2025-03-30 22:59:09,469 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:59:09,509 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:59:09,509 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:59:10,067 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:59:10,103 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:59:10,103 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:59:10,656 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:59:10,656 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:59:10,656 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  98%|#########8| 98/100 [02:21<00:02,  1.42s/it, loss=0.054] Epoch 1/1 [Val]:  99%|#########9| 99/100 [02:21<00:01,  1.42s/it, loss=0.054]2025-03-30 22:59:10,892 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_0.wav
2025-03-30 22:59:10,934 - __main__ - INFO - Original separated_tensor shape for item 0: torch.Size([1, 80000, 2])
2025-03-30 22:59:10,934 - __main__ - INFO - Processed separated_sources shape for item 0: torch.Size([2, 80000])
2025-03-30 22:59:11,492 - speech_enhancement.sepformer - INFO - Separating sources from tmp\tmp_mixture_1.wav
2025-03-30 22:59:11,529 - __main__ - INFO - Original separated_tensor shape for item 1: torch.Size([1, 80000, 2])
2025-03-30 22:59:11,529 - __main__ - INFO - Processed separated_sources shape for item 1: torch.Size([2, 80000])
2025-03-30 22:59:12,081 - __main__ - INFO - Shapes of collected separated sources: [torch.Size([2, 80000]), torch.Size([2, 80000])]
2025-03-30 22:59:12,082 - __main__ - INFO - Using num_sources = 2
2025-03-30 22:59:12,082 - __main__ - INFO - Min audio length: 80000
Epoch 1/1 [Val]:  99%|#########9| 99/100 [02:22<00:01,  1.42s/it, loss=0.0491]Epoch 1/1 [Val]: 100%|##########| 100/100 [02:22<00:00,  1.42s/it, loss=0.0491]Epoch 1/1 [Val]: 100%|##########| 100/100 [02:22<00:00,  1.43s/it, loss=0.0491]
2025-03-30 22:59:12,297 - __main__ - INFO - Epoch 1/1 - Val Loss: 0.053680
2025-03-30 22:59:12,909 - __main__ - INFO - Saved best model with val_loss: 0.053680
2025-03-30 22:59:14,538 - __main__ - INFO - Model training complete. Best model saved to models/combined_pipeline/best_model.pt
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
Resampling the audio from 16000 Hz to 8000 Hz
